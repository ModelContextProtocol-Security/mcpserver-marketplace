{
  "name": "MCP.so",
  "marketplace_url": "https://mcp.so",
  "source_url": "https://github.com/chatmcp/mcpso",
  "audited_at": "2025-12-13T04:45:16.821375Z",
  "checks_run": [
    "domain",
    "web",
    "source_repo"
  ],
  "errors": [],
  "domain": {
    "hostname": "mcp.so",
    "registrable_domain": "mcp.so",
    "dns": {
      "a": [
        "104.21.40.140",
        "172.67.186.229"
      ],
      "aaaa": [
        "2606:4700:3031::6815:288c",
        "2606:4700:3033::ac43:bae5"
      ],
      "cname": [],
      "ns": [
        "ullis.ns.cloudflare.com",
        "graham.ns.cloudflare.com"
      ],
      "mx": [
        "mx2.feishu.cn",
        "mx1.feishu.cn",
        "mx3.feishu.cn"
      ],
      "txt": [
        "google-site-verification=GBasukejAO-ZRSCybWLG7j3JziDjl7quuys9HF3P0OE",
        "v=spf1 +include:_netblocks.m.feishu.cn -all",
        "verification-code-site-App_feishu=qzkjAnxlebU7zRQgwGvp"
      ]
    },
    "tls": {
      "ok": true,
      "issuer": "C=US, O=Google Trust Services, CN=WE1",
      "subject": "CN=mcp.so",
      "not_before": "Nov 29 09:38:06 2025 GMT",
      "not_after": "Feb 27 10:38:02 2026 GMT",
      "sha256_fingerprint": null,
      "san": [
        "mcp.so"
      ],
      "error": null
    },
    "provider_hints": [
      "Cloudflare (NS)"
    ],
    "reverse_dns": {
      "104.21.40.140": "",
      "172.67.186.229": ""
    },
    "errors": []
  },
  "web": {
    "url": "https://mcp.so",
    "http": {
      "ok": true,
      "final_url": "https://mcp.so",
      "status_code": 200,
      "status_chain": [
        "HTTP/2 200"
      ],
      "redirect_chain": [],
      "headers": {
        "date": "Sat, 13 Dec 2025 04:45:27 GMT",
        "content-type": "text/html; charset=utf-8",
        "cache-control": "public, s-maxage=1800, stale-while-revalidate=7200",
        "link": "<https://mcp.so/>; rel=\"alternate\"; hreflang=\"en\", <https://mcp.so/zh>; rel=\"alternate\"; hreflang=\"zh\", <https://mcp.so/ja>; rel=\"alternate\"; hreflang=\"ja\", <https://mcp.so/>; rel=\"alternate\"; hreflang=\"x-default\"",
        "set-cookie": "NEXT_LOCALE=en; Path=/; SameSite=lax",
        "vary": "Accept-Encoding, Accept-Language",
        "cdn-cache-control": "public, s-maxage=1800, stale-while-revalidate=7200",
        "cloudflare-cdn-cache-control": "public, s-maxage=1800, stale-while-revalidate=7200",
        "x-robots-tag": "index, follow, max-image-preview:large, max-snippet:-1, max-video-preview:-1",
        "report-to": "{\"group\":\"cf-nel\",\"max_age\":604800,\"endpoints\":[{\"url\":\"https://a.nel.cloudflare.com/report/v4?s=JshB4ebeQOn5cb%2Byn74%2BE3F%2FITxzJhqM3pfDm8mzkKM7sZXj1P8VCCD6WoRrCR8ERrUN%2BeDFzFCYE2uXtfCkjEJolmI%3D\"}]}",
        "nel": "{\"report_to\":\"cf-nel\",\"success_fraction\":0.0,\"max_age\":604800}",
        "server": "cloudflare",
        "cf-ray": "9ad2cfcf8b1dcb87-YVR",
        "alt-svc": "h3=\":443\"; ma=86400"
      },
      "response_time_ms": 3977,
      "error": null
    },
    "security_headers": {
      "strict_transport_security": null,
      "content_security_policy": null,
      "x_frame_options": null,
      "x_content_type_options": null,
      "referrer_policy": null,
      "permissions_policy": null,
      "cross_origin_opener_policy": null,
      "cross_origin_resource_policy": null,
      "cross_origin_embedder_policy": null,
      "_present": [],
      "_missing": [
        "strict_transport_security",
        "content_security_policy",
        "x_frame_options",
        "x_content_type_options",
        "referrer_policy",
        "permissions_policy",
        "cross_origin_opener_policy",
        "cross_origin_resource_policy",
        "cross_origin_embedder_policy"
      ]
    },
    "paths": {
      "/privacy": {
        "path": "/privacy",
        "status_code": 404,
        "redirect_to": null
      },
      "/privacy-policy": {
        "path": "/privacy-policy",
        "status_code": 200,
        "redirect_to": null
      },
      "/terms": {
        "path": "/terms",
        "status_code": 404,
        "redirect_to": null
      },
      "/tos": {
        "path": "/tos",
        "status_code": 404,
        "redirect_to": null
      },
      "/terms-of-service": {
        "path": "/terms-of-service",
        "status_code": 200,
        "redirect_to": null
      },
      "/security": {
        "path": "/security",
        "status_code": 404,
        "redirect_to": null
      },
      "/security.txt": {
        "path": "/security.txt",
        "status_code": 200,
        "redirect_to": null
      },
      "/.well-known/security.txt": {
        "path": "/.well-known/security.txt",
        "status_code": 404,
        "redirect_to": null
      },
      "/legal": {
        "path": "/legal",
        "status_code": 404,
        "redirect_to": null
      },
      "/about": {
        "path": "/about",
        "status_code": 404,
        "redirect_to": null
      },
      "/contact": {
        "path": "/contact",
        "status_code": 404,
        "redirect_to": null
      },
      "/robots.txt": {
        "path": "/robots.txt",
        "status_code": 200,
        "redirect_to": null
      },
      "/sitemap.xml": {
        "path": "/sitemap.xml",
        "status_code": 200,
        "redirect_to": null
      },
      "/status": {
        "path": "/status",
        "status_code": 404,
        "redirect_to": null
      },
      "/health": {
        "path": "/health",
        "status_code": 404,
        "redirect_to": null
      },
      "/api": {
        "path": "/api",
        "status_code": 404,
        "redirect_to": null
      },
      "/docs": {
        "path": "/docs",
        "status_code": 404,
        "redirect_to": null
      },
      "/api-docs": {
        "path": "/api-docs",
        "status_code": 404,
        "redirect_to": null
      },
      "/documentation": {
        "path": "/documentation",
        "status_code": 404,
        "redirect_to": null
      },
      "/swagger": {
        "path": "/swagger",
        "status_code": 404,
        "redirect_to": null
      },
      "/swagger.json": {
        "path": "/swagger.json",
        "status_code": 200,
        "redirect_to": null
      },
      "/swagger.yaml": {
        "path": "/swagger.yaml",
        "status_code": 200,
        "redirect_to": null
      },
      "/openapi.json": {
        "path": "/openapi.json",
        "status_code": 200,
        "redirect_to": null
      },
      "/openapi.yaml": {
        "path": "/openapi.yaml",
        "status_code": 200,
        "redirect_to": null
      },
      "/graphql": {
        "path": "/graphql",
        "status_code": 404,
        "redirect_to": null
      }
    },
    "mixed_content": {
      "http_links_count": 29,
      "http_subresources_count": 0,
      "samples": [
        "http://myproxy:3128\\",
        "http://edgeone-pages-svc.chatmcp:9593/rest\\",
        "http://time-svc.chatmcp:9593/rest\\",
        "http://mcpadvisor-svc.chatmcp:9593/rest\\",
        "http://howtocook-svc.chatmcp:9593/rest\\"
      ]
    },
    "trackers": [
      {
        "name": "Google Analytics",
        "type": "analytics",
        "evidence": "gtag"
      },
      {
        "name": "Google Tag Manager",
        "type": "analytics",
        "evidence": "googletagmanager.com"
      },
      {
        "name": "Google AdSense",
        "type": "advertising",
        "evidence": "googlesyndication.com"
      },
      {
        "name": "LinkedIn Insight",
        "type": "advertising",
        "evidence": "linkedin.com/in/nanbing\\\" target=\\\"_blank\\\"\\u003e\\u003cimg src=\\\"https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white\\u0026logoColor=fff\\\" alt=\\\"follow on LinkedIn\\\"\\u003e\\u003c/a\\u003e\\n    \\u003cimg src=\\\"https://img.shields.io/badge/PRs-welcome-brightgreen.svg\\\"/\\u003e\\n     \\u003ca href=\\\"https://github.com/nanbingxyz/5ire/graphs/commit-activity\\\" target=\\\"_blank\\\"\\u003e\\n        \\u003cimg alt=\\\"Commits last month\\\" src=\\\"https://img.shields.io/github/commit-activity/m/nanbingxyz/5ire?labelColor=%20%2332b583\\u0026color=%20%2312b76a\\\"\\u003e\\u003c/a\\u003e\\n     \\u003ca href=\\\"https://github.com/nanbingxyz/5ire/issues\\\" target=\\\"_blank\\\"\\u003e\\n        \\u003cimg alt=\\\"Issues closed\\\" src=\\\"https://img.shields.io/github/issues-search?query=repo%3Ananbingxyz%2F5ire%20is%3Aclosed\\u0026label=issues%20closed\\u0026labelColor=%20%237d89b0\\u0026color=%20%235d6b98\\\"\\u003e\\u003c/a\\u003e\\n     \\u003ca href=\\\"https://mseep.ai/app/92bbc79d-4b4d-4707-8d43-2d3d8ebb4fa8\\\" target=\\\"_blank\\\"\\u003e\\u003cimg src=\\\"https://mseep.ai/badge.svg\\\" alt=\\\"Verified on MseeP\\\"/\\u003e\\u003c/a\\u003e\\n  \\u003c/div\\u003e\\n   \\u003cbr /\\u003e\\n  \\u003cimg src=\\\"https://github.com/user-attachments/assets/e622e1da-09b9-4212-b71c-ad9d39bf3cd5\\\" width=\\\"100%\\\"/\\u003e\\n  \\u003cbr /\\u003e\\n  \\u003cp\\u003e\\n    \\u003cbr /\\u003e\\n    \\u003cdiv style=\\\"display:flex;justify-content:space-around;align-items:center;gap:6px;flex-wrap:wrap;margin-bottom:15px;\\\"\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003eOpenAI\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Azure\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Anthropic\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Google\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Baidu\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Mistral\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Moonshot\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Doubao\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Grok\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ DeepSeek\\u003c/span\\u003e\\n    \\u003cspan style=\\\"font-size:12px;\\\"\\u003e/ Ollama\\u003c/span\\u003e\\n  \\u003c/div\\u003e\\n    \\u003cbr /\\u003e\\n    \\u003ca href=\\\"https://x.com/intent/follow?screen_name=1ronben\\\"\\u003eTwitter\\u003c/a\\u003e\\n    \u00b7\\n    \\u003ca href=\\\"https://github.com/nanbingxyz/5ire/releases/latest\\\"\\u003eReleases\\u003c/a\\u003e\\n     \u00b7\\n    \\u003ca href=\\\"https://5ireai.com\\\"\\u003e\u4e2d\u6587\u5b98\u7f51\\u003c/a\\u003e\\n  \\u003c/p\\u003e\\n  \\u003cdiv\\u003e\\u003ca href=\\\"https://buymeacoffee.com/ironben\\\"\\u003e\\u003cimg src=\\\"https://github.com/user-attachments/assets/2265e2d6-2a17-4a48-b779-52a925261135\\\" style=\\\"width:200px\\\"/\\u003e\\u003c/a\\u003e\\u003c/div\\u003e\\n   \\u003cbr /\\u003e\\n\\u003cvideo src=\\\"https://github.com/user-attachments/assets/741b23d3-31df-4749-bde4-103e2d415953.mp4\\\"\\u003e\\u003c/video\\u003e\\n\\u003c/div\\u003e\\n\\u003cbr /\\u003e\\n\\n### Before to activating tools feature, ensure the following components are installed:\\n\\n- Python\\n- Node.js\\n- uv (Python package manager)\\n\\nThese components are required as they constitute the runtime environment for the MCP Server. If you don't anticipate using the tools feature immediately, you may choose to skip this installation step and complete it later when the need arises.\\n\\nFor detailed installation instructions, please see our [Installation Guide](INSTALLATION.md).\\n\\n### Getting involved\\n\\nIf you want to contribute code to 5ire or develop your own apps based on 5ire, start with the [Development Setup Guide](DEVELOPMENT.md).\\n\\nVisit [Wiki](https://deepwiki.com/nanbingxyz/5ire) for more details.\\n\\n**\ud83d\ude80 To integrate 5ire\u2019s one-click server installation into your website, see the** [One-Click Server Installation Integration Guide](https://github.com/nanbingxyz/5ire/wiki/One%E2%80%\"])</script><script>self.__next_f.push([1,\"90Click-Server-Installation-Integration-Guide).\\n\\n\\u003cbr /\\u003e\\n\\n# Features\\n\\n## \u2692\ufe0f Support Tools via MCP Servers\\n\\nMCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP provides a standardized way to connect AI models to different data sources and tools.\\n\\nWith tools, you can access the file system, obtain system information, interact with databases, access remote data, and more, rather than just having a simple conversation.\\n\\nhttps://github.com/user-attachments/assets/5aa98f2b-c26d-435e-8196-73fa414066eb\\n\\nWe have created an open [marketplace for MCP Servers](https://github.com/nanbingxyz/mcpsvr). it empowers users to discover exceptional tools while offering a streamlined process for sharing their own MCP server creations.\\n\\nhttps://github.com/user-attachments/assets/be66c30e-bb29-4dfe-9f25-8d396470ed60\\n\\n## \ud83d\udca1 Local Knowledge Base\\n\\nWe have integrated the bge-m3 as our local embedding model, which excels in multilingual vectorization. 5ire now supports parsing and vectorization of docx, xlsx, pptx, pdf, txt, and csv documents, enabling storage of these vectors to power robust Retrieval-Augmented Generation (RAG) capabilities locally.\\n\\n![Local Knowledge Base Screenshot](https://5ire.app/knowledge.png)\\n\\n## \ud83d\udcc8 Usage Analytics\\n\\nBy keeping track of your API usage and spending, you can gain a better understanding of how much you're spending on the API and make informed decisions to optimize your use of the service.\\n\\n![Usage Analytics Screenshot](https://5ire.app/analytics.png)\\n\\n## \u2728 Prompts Library\\n\\nThe prompt library provides an effective way to create and organize your own prompts. These prompts are highly versatile, thanks to their support for variables.\\n\\n![Prompts Library Screenshot](https://5ire.app/prompts.png)\\n\\n## \ud83d\udd16 Bookmarks\\n\\nYou can bookmark each conversation, and even if the original messages are deleted, the saved bookmarked content remains unaffected.\\n![Bookmarks Screenshot](https://5ire.app/bookmarks.png)\\n\\n## \ud83d\udd0d Quick Search\\n\\nYou can perform keyword searches across all conversations, quickly pinpointing the information you need.\\n![Search Screenshot](https://5ire.app/search.png)\\n\\n\\u003e [!TIP]\\n\\u003e Since 5ire uses native dependencies, it needs to be packaged on the corresponding platform. If it is on Mac OS, you may also need to configure APPLE_TEAM_ID, APPLE_ID, and APPLE_ID_PASS for notarization to avoid security alerts.\\n\\n\\u003chr/\\u003e\\n\\n## Discover Exceptional MCP Servers\\n\\n[MCPSvr](https://github.com/nanbingxyz/mcpsvr), a community-driven directory of MCP servers, empowers developers to discover exceptional tools while offering a streamlined process for sharing their own MCP server creations.4e:T5cd,## What is 5ire? \\n5ire is a cross-platform desktop AI assistant and MCP client that integrates with major service providers and supports a local knowledge base through model context protocol servers.\\n\\n## How to use 5ire? \\nTo use 5ire, download and install the application from its [GitHub repository](https://github.com/nanbingxyz/5ire). Configure the MCP servers as needed and start interacting with the AI assistant.\\n\\n## Key features of 5ire? \\n- Support for tools via MCP servers for enhanced functionality.\\n- Local knowledge base with multilingual vectorization capabilities.\\n- Usage analytics to track API usage and spending.\\n- A versatile prompts library for creating and organizing prompts.\\n- Bookmarking feature to save important conversations.\\n- Quick search functionality across all conversations.\\n\\n## Use cases of 5ire? \\n1. Assisting users in managing and retrieving information from various data sources.\\n2. Enhancing productivity through efficient prompt management and conversation bookmarking.\\n3. Analyzing API usage to optimize costs and improve service utilization.\\n\\n## FAQ from 5ire? \\n- Is 5ire compatible with all major service providers?  \\n\\u003e Yes! 5ire is designed to work with various service providers including OpenAI, Azure, and Google.\\n\\n-\"])</script><script>self.__next_f.push([1,\" Can I customize the MCP servers?  \\n\\u003e Yes! You can modify the configuration file to add custom MCP servers.\\n\\n- Is 5ire free to use?  \\n\\u003e Yes! 5ire is open-source and free to use under the GNU General Public License version 3.4f:T13d6,# y-cli \ud83d\ude80\\n\\nA tiny command-line interface chat application that brings AI conversations to your terminal.\\n\\nCheck out [y-gui](https://github.com/luohy15/y-gui) for a web-based version of y-cli.\\n\\n## \u2728 Features\\n\\n- \ud83d\udcdd Flexible storage options:\\n  - Local JSONL files for easy access and sync\\n  - Cloudflare KV and R2 for cloud storage and backup\\n- \ud83d\udcac Interactive chat interface with tool execution visualization\\n- \ud83e\udd16 Support for multiple bot configurations (any base_url/api_key/model combination). Supported api format type:\\n  - [OpenAI chat completion streaming format](https://platform.openai.com/docs/api-reference/chat/streaming)\\n  - [Dify chat-messages streaming format](https://docs.dify.ai/guides/application-publishing/developing-with-apis)\\n- \ud83e\udd14 Support for reasoning model\\n  - [Deepseek-r1 reasoning_content](https://api-docs.deepseek.com/guides/reasoning_model) output print\\n  - [OpenAI o3-mini reasoning_effort](https://platform.openai.com/docs/guides/reasoning) configuration \\n- \ud83d\udd17 MCP (Model Context Protocol) integration:\\n  - Client support with multiple server configurations (stdio/SSE)\\n  - Persistent daemon\\n  - Custom prompt configurations\\n- \ud83e\uddd0 Simple \\\"Deep Research\\\" mode by prompt configuration\\n  - [Demo](https://cdn.luohy15.com/chat/660831.html)\\n\\n## Demo\\n\\n![demo](.github/visuals/demo.png)\\n\\n![demo](.github/visuals/demo.gif)\\n\\n[asciicast](https://asciinema.org/a/709735)\\n\\n### Multiple bot configurations\\n```\\n\u279c  ~ y-cli bot list\\nName         API Key      API Type    Base URL                             Model                                Print Speed    Description    OpenRouter Config    MCP Servers    Reasoning Effort\\n-----------  -----------  ----------  -----------------------------------  -----------------------------------  -------------  -------------  -------------------  -------------  ------------------\\ndefault      sk-or-v1...  N/A         https://gateway.ai.cloudflare.co...  google/gemini-2.0-flash-001          None            N/A            Yes                  No             N/A\\nclaude       sk-or-v1...  N/A         https://gateway.ai.cloudflare.co...  anthropic/claude-3.7-sonnet:beta     None             N/A            Yes                  todo           N/A\\no3-mini      sk-or-v1...  N/A         https://gateway.ai.cloudflare.co...  openai/o3-mini                       None             N/A            Yes                  No             low\\nds-chat        sk-or-v1...  N/A         https://gateway.ai.cloudflare.co...  deepseek/deepseek-chat-v3-0324:free                 None            N/A            Yes                  tavily         N/A\\ndify-bot     app-2drF...  dify        https://api.dify.ai/v1                                                    None             N/A            No                   No             N/A\\n```\\n\\n### Multiple MCP servers\\n```\\n\u279c  ~ y-cli mcp list\\nName            Type    Command/URL          Arguments/Token    Environment     Auto-Confirm\\n--------------  ------  -------------------  -----------------  --------------  --------------\\nbrave-search    sse     https://router.m...                                     brave_web_s...\\ntodo            stdio   uvx                  mcp-todo\\nexa-mcp-server  stdio   npx                  exa-mcp-server     EXA_API_KEY...\\n```\\n\\n## \u26a1 Quick Start\\n\\n### Prerequisites\\n\\nRequired:\\n1. uv\\n2. OpenRouter API key\\n\\nSetup Instructions:\\n1. **uv**\\n   - Follow the [official installation guide](https://docs.astral.sh/uv/getting-started/installation/)\\n   - uv will automatically manage Python installation\\n\\n2. **OpenRouter API key**\\n   - Visit [OpenRouter Settings](https://openrouter.ai/settings/keys)\\n   - Create a new API key\\n   - Save it for the initialization step\\n\\n### Run without Installation\\n```bash\\nuvx y-cli\\n```\\n\\n### Install with uv tool\\n```bash\\nuv tool install y-cli\\n```\\n\\n### Initialize\\n```bash\\ny-cli init\\n```\\n\\n### Start Chat\\n\"])</script><script>self.__next_f.push([1,\"```bash\\ny-cli chat\\n```\\n\\n## \ud83d\udee0\ufe0f Usage\\n\\n```bash\\ny-cli [OPTIONS] COMMAND [ARGS]...\\n```\\n\\n### Commands\\n- `chat`   Start a new chat conversation or continue an existing one\\n- `list`   List chat conversations with optional filtering\\n- `share`  Share a chat conversation by generating a shareable link\\n- `bot`    Manage bot configurations:\\n  - `add`     Add a new bot configuration\\n  - `list`    List all configured bots\\n  - `delete`  Delete a bot configuration\\n- `mcp`    Manage MCP server configurations:\\n  - `add`     Add a new MCP server configuration\\n  - `list`    List all configured MCP servers\\n  - `delete`  Delete an MCP server configuration\\n- `daemon`  Manage the MCP daemon:\\n  - `start`    Start the MCP daemon\\n  - `stop`     Stop the MCP daemon\\n  - `status`   Check daemon status\\n  - `log`      View daemon logs\\n  - `restart`  Restart the daemon\\n- `prompt` Manage prompt configurations:\\n  - `add`     Add a new prompt configuration\\n  - `list`    List all configured prompts\\n  - `delete`  Delete a prompt configuration\\n\\n### Options\\n- `--help`  Show help message and exit\\n\\n## \ud83d\udcda Documentation\\n\\nVisit the [deepwiki page](https://deepwiki.com/luohy15/y-cli) for comprehensive project documentation and guides.50:T516,## what is y-cli? \\n y-cli is a tiny command-line interface chat application that allows users to engage in AI conversations directly from their terminal.\\n\\n## how to use y-cli? \\n To use y-cli, you need to install the required tools and initialize the application. You can start a chat by running the command `y-cli chat` after installation.\\n\\n## key features of y-cli? \\n - All chat data is stored in single JSONL files for easy access and synchronization.\\n - Interactive chat interface for seamless conversations.\\n - Support for multiple bot configurations with various API types.\\n - Reasoning model support for enhanced conversation capabilities.\\n - MCP (Model Context Protocol) client support for multiple server configurations.\\n\\n## use cases of y-cli? \\n 1. Engaging in AI-driven conversations for research or entertainment.\\n 2. Managing multiple AI bots for different tasks or queries.\\n 3. Storing and sharing chat conversations easily.\\n\\n## FAQ from y-cli? \\n - Can y-cli support multiple AI models?  \\n \\u003e Yes! y-cli supports various AI models and configurations through its bot management feature.\\n\\n - Is y-cli easy to set up?  \\n \\u003e Yes! y-cli can be set up quickly with the required prerequisites and simple commands.\\n\\n - What programming language is y-cli built with?  \\n \\u003e y-cli is built using Python.51:T3131,\\u003cdiv align=\\\"center\\\"\\u003e\\u003csub\\u003e\\nEnglish | \\u003ca href=\\\"https://github.com/cline/cline/blob/main/locales/es/README.md\\\" target=\\\"_blank\\\"\\u003eEspa\u00f1ol\\u003c/a\\u003e | \\u003ca href=\\\"https://github.com/cline/cline/blob/main/locales/de/README.md\\\" target=\\\"_blank\\\"\\u003eDeutsch\\u003c/a\\u003e | \\u003ca href=\\\"https://github.com/cline/cline/blob/main/locales/ja/README.md\\\" target=\\\"_blank\\\"\\u003e\u65e5\u672c\u8a9e\\u003c/a\\u003e | \\u003ca href=\\\"https://github.com/cline/cline/blob/main/locales/zh-cn/README.md\\\" target=\\\"_blank\\\"\\u003e\u7b80\u4f53\u4e2d\u6587\\u003c/a\\u003e | \\u003ca href=\\\"https://github.com/cline/cline/blob/main/locales/zh-tw/README.md\\\" target=\\\"_blank\\\"\\u003e\u7e41\u9ad4\u4e2d\u6587\\u003c/a\\u003e | \\u003ca href=\\\"https://github.com/cline/cline/blob/main/locales/ko/README.md\\\" target=\\\"_blank\\\"\\u003e\ud55c\uad6d\uc5b4\\u003c/a\\u003e\\n\\u003c/sub\\u003e\\u003c/div\\u003e\\n\\n# Cline \u2013 \\\\#1 on OpenRouter\\n\\n\\u003cp align=\\\"center\\\"\\u003e\\n  \\u003cimg src=\\\"https://media.githubusercontent.com/media/cline/cline/main/assets/docs/demo.gif\\\" width=\\\"100%\\\" /\\u003e\\n\\u003c/p\\u003e\\n\\n\\u003cdiv align=\\\"center\\\"\\u003e\\n\\u003ctable\\u003e\\n\\u003ctbody\\u003e\\n\\u003ctd align=\\\"center\\\"\\u003e\\n\\u003ca href=\\\"https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev\\\" target=\\\"_blank\\\"\\u003e\\u003cstrong\\u003eDownload on VS Marketplace\\u003c/strong\\u003e\\u003c/a\\u003e\\n\\u003c/td\\u003e\\n\\u003ctd align=\\\"center\\\"\\u003e\\n\\u003ca href=\\\"https://discord.gg/cline\\\" target=\\\"_blank\\\"\\u003e\\u003cstrong\\u003eDiscord\\u003c/strong\\u003e\\u003c/a\\u003e\\n\\u003c/td\\u003e\\n\\u003ctd align=\\\"center\\\"\\u003e\\n\\u003ca href=\\\"https://www.reddit.com/r/cline/\\\" target=\\\"_blank\\\"\\u003e\\u003cstrong\\u003er/cline\\u003c/strong\\u003e\\u003c/a\\u003e\\n\\u003c/td\\u003e\\n\\u003ctd align=\\\"center\\\"\\u003e\\n\\u003ca href=\\\"https://github.com/cline/cline/discussions/categories/feature-requests?discussions_q=is%3Aopen+category%3A%22Feature+Requests%22+sort%3Atop\\\" target=\\\"_blank\\\"\\u003e\\u003cstrong\\u003eFeature Requests\\u003c/strong\\u003e\\u003c/a\\u003e\\n\\u003c/td\\u003e\\n\\u003ctd align=\\\"center\\\"\\u003e\\n\\u003ca href=\\\"https://docs.cline.bot/get\"])</script><script>self.__next_f.push([1,\"ting-started/for-new-coders\\\" target=\\\"_blank\\\"\\u003e\\u003cstrong\\u003eGetting Started\\u003c/strong\\u003e\\u003c/a\\u003e\\n\\u003c/td\\u003e\\n\\u003c/tbody\\u003e\\n\\u003c/table\\u003e\\n\\u003c/div\\u003e\\n\\nMeet Cline, an AI assistant that can use your **CLI** a**N**d **E**ditor.\\n\\nThanks to\u00a0[Claude 3.7 Sonnet's agentic coding capabilities](https://www.anthropic.com/claude/sonnet),\u00a0Cline can handle complex software development tasks step-by-step. With tools that let him create \\u0026 edit files, explore large projects, use the browser, and execute terminal commands (after you grant permission), he can assist you in ways that go beyond code completion or tech support. Cline can even use the Model Context Protocol (MCP) to create new tools and extend his own capabilities. While autonomous AI scripts traditionally run in sandboxed environments, this extension provides a human-in-the-loop GUI to approve every file change and terminal command, providing a safe and accessible way to explore the potential of agentic AI.\\n\\n1. Enter your task and add images to convert mockups into functional apps or fix bugs with screenshots.\\n2. Cline starts by analyzing your file structure \\u0026 source code ASTs, running regex searches, and reading relevant files to get up to speed in existing projects. By carefully managing what information is added to context, Cline can provide valuable assistance even for large, complex projects without overwhelming the context window.\\n3. Once Cline has the information he needs, he can:\\n    - Create and edit files + monitor linter/compiler errors along the way, letting him proactively fix issues like missing imports and syntax errors on his own.\\n    - Execute commands directly in your terminal and monitor their output as he works, letting him e.g., react to dev server issues after editing a file.\\n    - For web development tasks, Cline can launch the site in a headless browser, click, type, scroll, and capture screenshots + console logs, allowing him to fix runtime errors and visual bugs.\\n4. When a task is completed, Cline will present the result to you with a terminal command like\u00a0`open -a \\\"Google Chrome\\\" index.html`, which you run with a click of a button.\\n\\n\\u003e [!TIP]\\n\\u003e Use the\u00a0`CMD/CTRL + Shift + P`\u00a0shortcut to open the command palette and type\u00a0\\\"Cline: Open In New Tab\\\"\u00a0to open the extension as a tab in your editor. This lets you use Cline side-by-side with your file explorer, and see how he changes your workspace more clearly.\\n\\n---\\n\\n\\u003cimg align=\\\"right\\\" width=\\\"340\\\" src=\\\"https://github.com/user-attachments/assets/3cf21e04-7ce9-4d22-a7b9-ba2c595e88a4\\\"\\u003e\\n\\n### Use any API and Model\\n\\nCline supports API providers like OpenRouter, Anthropic, OpenAI, Google Gemini, AWS Bedrock, Azure, GCP Vertex, and Cerebras. You can also configure any OpenAI compatible API, or use a local model through LM Studio/Ollama. If you're using OpenRouter, the extension fetches their latest model list, allowing you to use the newest models as soon as they're available.\\n\\nThe extension also keeps track of total tokens and API usage cost for the entire task loop and individual requests, keeping you informed of spend every step of the way.\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n\\u003cimg align=\\\"left\\\" width=\\\"370\\\" src=\\\"https://github.com/user-attachments/assets/81be79a8-1fdb-4028-9129-5fe055e01e76\\\"\\u003e\\n\\n### Run Commands in Terminal\\n\\nThanks to the new [shell integration updates in VSCode v1.93](https://code.visualstudio.com/updates/v1_93#_terminal-shell-integration-api), Cline can execute commands directly in your terminal and receive the output. This allows him to perform a wide range of tasks, from installing packages and running build scripts to deploying applications, managing databases, and executing tests, all while adapting to your dev environment \\u0026 toolchain to get the job done right.\\n\\nFor long running processes like dev servers, use the \\\"Proceed While Running\\\" button to let Cline continue in the task while the command runs in the background. As Cline works he\u2019ll be notified of any new termina\"])</script><script>self.__next_f.push([1,\"l output along the way, letting him react to issues that may come up, such as compile-time errors when editing files.\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n\\u003cimg align=\\\"right\\\" width=\\\"400\\\" src=\\\"https://github.com/user-attachments/assets/c5977833-d9b8-491e-90f9-05f9cd38c588\\\"\\u003e\\n\\n### Create and Edit Files\\n\\nCline can create and edit files directly in your editor, presenting you a diff view of the changes. You can edit or revert Cline's changes directly in the diff view editor, or provide feedback in chat until you're satisfied with the result. Cline also monitors linter/compiler errors (missing imports, syntax errors, etc.) so he can fix issues that come up along the way on his own.\\n\\nAll changes made by Cline are recorded in your file's Timeline, providing an easy way to track and revert modifications if needed.\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n\\u003cimg align=\\\"left\\\" width=\\\"370\\\" src=\\\"https://github.com/user-attachments/assets/bc2e85ba-dfeb-4fe6-9942-7cfc4703cbe5\\\"\\u003e\\n\\n### Use the Browser\\n\\nWith Claude 3.5 Sonnet's new [Computer Use](https://www.anthropic.com/news/3-5-models-and-computer-use) capability, Cline can launch a browser, click elements, type text, and scroll, capturing screenshots and console logs at each step. This allows for interactive debugging, end-to-end testing, and even general web use! This gives him autonomy to fixing visual bugs and runtime issues without you needing to handhold and copy-pasting error logs yourself.\\n\\nTry asking Cline to \\\"test the app\\\", and watch as he runs a command like `npm run dev`, launches your locally running dev server in a browser, and performs a series of tests to confirm that everything works. [See a demo here.](https://x.com/sdrzn/status/1850880547825823989)\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n\\u003cimg align=\\\"right\\\" width=\\\"350\\\" src=\\\"https://github.com/user-attachments/assets/ac0efa14-5c1f-4c26-a42d-9d7c56f5fadd\\\"\\u003e\\n\\n### \\\"add a tool that...\\\"\\n\\nThanks to the [Model Context Protocol](https://github.com/modelcontextprotocol), Cline can extend his capabilities through custom tools. While you can use [community-made servers](https://github.com/modelcontextprotocol/servers), Cline can instead create and install tools tailored to your specific workflow. Just ask Cline to \\\"add a tool\\\" and he will handle everything, from creating a new MCP server to installing it into the extension. These custom tools then become part of Cline's toolkit, ready to use in future tasks.\\n\\n-   \\\"add a tool that fetches Jira tickets\\\": Retrieve ticket ACs and put Cline to work\\n-   \\\"add a tool that manages AWS EC2s\\\": Check server metrics and scale instances up or down\\n-   \\\"add a tool that pulls the latest PagerDuty incidents\\\": Fetch details and ask Cline to fix bugs\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n\\u003cimg align=\\\"left\\\" width=\\\"360\\\" src=\\\"https://github.com/user-attachments/assets/7fdf41e6-281a-4b4b-ac19-020b838b6970\\\"\\u003e\\n\\n### Add Context\\n\\n**`@url`:**\u00a0Paste in a URL for the extension to fetch and convert to markdown, useful when you want to give Cline the latest docs\\n\\n**`@problems`:**\u00a0Add workspace errors and warnings ('Problems' panel) for Cline to fix\\n\\n**`@file`:**\u00a0Adds a file's contents so you don't have to waste API requests approving read file (+ type to search files)\\n\\n**`@folder`:**\u00a0Adds folder's files all at once to speed up your workflow even more\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-\"])</script><script>self.__next_f.push([1,\"9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n\\u003cimg align=\\\"right\\\" width=\\\"350\\\" src=\\\"https://github.com/user-attachments/assets/140c8606-d3bf-41b9-9a1f-4dbf0d4c90cb\\\"\\u003e\\n\\n### Checkpoints: Compare and Restore\\n\\nAs Cline works through a task, the extension takes a snapshot of your workspace at each step. You can use the 'Compare' button to see a diff between the snapshot and your current workspace, and the 'Restore' button to roll back to that point.\\n\\nFor example, when working with a local web server, you can use 'Restore Workspace Only' to quickly test different versions of your app, then use 'Restore Task and Workspace' when you find the version you want to continue building from. This lets you safely explore different approaches without losing progress.\\n\\n\\u003c!-- Transparent pixel to create line break after floating image --\\u003e\\n\\n\\u003cimg width=\\\"2000\\\" height=\\\"0\\\" src=\\\"https://github.com/user-attachments/assets/ee14e6f7-20b8-4391-9091-8e8e25561929\\\"\\u003e\\u003cbr\\u003e\\n\\n## Contributing\\n\\nTo contribute to the project, start with our [Contributing Guide](CONTRIBUTING.md) to learn the basics. You can also join our [Discord](https://discord.gg/cline) to chat with other contributors in the `#contributors` channel. If you're looking for full-time work, check out our open positions on our [careers page](https://cline.bot/join-us)!\\n\\n\\u003cdetails\\u003e\\n\\u003csummary\\u003eLocal Development Instructions\\u003c/summary\\u003e\\n\\n1. Clone the repository _(Requires [git-lfs](https://git-lfs.com/))_:\\n    ```bash\\n    git clone https://github.com/cline/cline.git\\n    ```\\n2. Open the project in VSCode:\\n    ```bash\\n    code cline\\n    ```\\n3. Install the necessary dependencies for the extension and webview-gui:\\n    ```bash\\n    npm run install:all\\n    ```\\n4. Launch by pressing `F5` (or `Run`-\\u003e`Start Debugging`) to open a new VSCode window with the extension loaded. (You may need to install the [esbuild problem matchers extension](https://marketplace.visualstudio.com/items?itemName=connor4312.esbuild-problem-matchers) if you run into issues building the project.)\\n\\n\\u003c/details\\u003e\\n\\n\\u003cdetails\\u003e\\n\\u003csummary\\u003eCreating a Pull Request\\u003c/summary\\u003e\\n\\n1. Before creating a PR, generate a changeset entry:\\n    ```bash\\n    npm run changeset\\n    ```\\n   This will prompt you for:\\n   - Type of change (major, minor, patch)\\n     - `major` \u2192 breaking changes (1.0.0 \u2192 2.0.0)\\n     - `minor` \u2192 new features (1.0.0 \u2192 1.1.0)\\n     - `patch` \u2192 bug fixes (1.0.0 \u2192 1.0.1)\\n   - Description of your changes\\n\\n2. Commit your changes and the generated `.changeset` file\\n\\n3. Push your branch and create a PR on GitHub. Our CI will:\\n   - Run tests and checks\\n   - Changesetbot will create a comment showing the version impact\\n   - When merged to main, changesetbot will create a Version Packages PR\\n   - When the Version Packages PR is merged, a new release will be published\\n\\n\\u003c/details\\u003e\\n\\n\\n## License\\n\\n[Apache 2.0 \u00a9 2025 Cline Bot Inc.](./LICENSE)52:T4d8,## What is Cline? \\nCline is an autonomous coding agent integrated into your IDE, designed to assist with software development tasks by creating and editing files, executing commands, and using the browser with user permission.\\n\\n## How to use Cline? \\nTo use Cline, install the extension from the VS Marketplace, enter your coding tasks, and allow Cline to analyze your project and execute commands as needed.\\n\\n## Key features of Cline? \\n- Autonomous file creation and editing\\n- Command execution in the terminal\\n- Browser automation for testing and debugging\\n- Integration with various API providers\\n- Custom tool creation through Model Context Protocol\\n\\n## Use cases of Cline? \\n1. Automating repetitive coding tasks\\n2. Debugging web applications interactively\\n3. Managing project files and dependencies\\n4. Extending functionality with custom tools\\n\\n## FAQ from Cline? \\n- Can Cline work with any programming language?  \\n\\u003e Yes! Cline is designed to assist with various programming languages and frameworks.\\n\\n- Is Cline safe to use?  \\n\\u003e Yes! Cline requires user permission for actions, ensuring a safe coding environment.\\n\\n- How can I contribute to Cline?  \\n\\u003e You can contribute by following the guidelines in the Contributing Guide on GitHub.53:T4e7,#\"])</script><script>self.__next_f.push([1,\"# what is Cursor? \\nCursor is an AI-powered code editor designed to enhance productivity by assisting developers in writing and editing code efficiently.\\n\\n## how to use Cursor? \\nTo use Cursor, simply install the application and start coding. You can input natural language instructions to edit code, and Cursor will predict your next edits based on your coding patterns.\\n\\n## key features of Cursor? \\n- Predictive editing that anticipates your next code changes.\\n- Ability to reference your codebase and documentation easily.\\n- Natural language processing to allow coding through simple instructions.\\n\\n## use cases of Cursor? \\n1. Rapidly editing large codebases with minimal keystrokes.\\n2. Writing complex functions or classes using plain language prompts.\\n3. Accessing documentation and code references seamlessly while coding.\\n\\n## FAQ from Cursor? \\n- Can Cursor help with all programming languages?\\n\\u003e Yes! Cursor is designed to support multiple programming languages and frameworks.\\n\\n- Is Cursor free to use?\\n\\u003e Cursor offers a free version with basic features, while advanced features may require a subscription.\\n\\n- How does Cursor predict my edits?\\n\\u003e Cursor uses machine learning algorithms to analyze your coding patterns and suggest edits accordingly.54:T438,## what is ChatWise? \\nChatWise is an advanced AI chatbot designed to provide quick and efficient responses, making it one of the fastest chatbots available.\\n\\n## how to use ChatWise? \\nTo use ChatWise, simply visit the website [ChatWise](https://chatwise.app/) and start chatting with the AI by typing your questions or prompts.\\n\\n## key features of ChatWise? \\n- Fast response times for user queries\\n- User-friendly interface for seamless interaction\\n- Capable of handling a wide range of topics and questions\\n\\n## use cases of ChatWise? \\n1. Customer support for businesses\\n2. Personal assistant for scheduling and reminders\\n3. Educational tool for answering student queries\\n\\n## FAQ from ChatWise? \\n- What makes ChatWise the second fastest AI chatbot?\\n\\u003e ChatWise utilizes advanced algorithms and optimized processing to ensure rapid response times.\\n\\n- Is ChatWise free to use?\\n\\u003e Yes! ChatWise is free for users to access and interact with.\\n\\n- Can ChatWise handle complex queries?\\n\\u003e Yes! ChatWise is designed to understand and respond to a variety of questions, including complex ones.55:T4a6,## what is Windsurf? \\nWindsurf is a purpose-built Integrated Development Environment (IDE) designed to enhance coding experiences by leveraging AI capabilities.\\n\\n## how to use Windsurf? \\nTo use Windsurf, simply download the IDE from the official website, install it, and start coding with its intelligent features that anticipate your coding needs.\\n\\n## key features of Windsurf? \\n- AI-driven code suggestions and completions\\n- Customizable interface tailored to individual developer preferences\\n- Integrated tools for seamless project management\\n\\n## use cases of Windsurf? \\n1. Streamlining the coding process for software developers.\\n2. Enhancing productivity through intelligent code suggestions.\\n3. Facilitating collaboration among development teams with integrated project management tools.\\n\\n## FAQ from Windsurf? \\n- Is Windsurf suitable for beginners?\\n\\u003e Yes! Windsurf is designed to assist developers of all skill levels, including beginners.\\n\\n- Can I customize the interface?\\n\\u003e Absolutely! Windsurf allows extensive customization to fit your workflow.\\n\\n- Is there a community or support available?\\n\\u003e Yes, Windsurf has an active community and support resources available on its website.56:Tb21,# Spec Oxide\\r\\n\\r\\n\\u003e Spec-driven development for humans and AI - optimized for Claude Code with built-in MCP\\r\\n\\r\\nSpec Oxide is a comprehensive workflow and toolset that enables spec-driven development for AI-assisted coding. You\\r\\nagree on *what* to build before any code is written.\\r\\n\\r\\n# What do you get?\\r\\n\\r\\n## \ud83d\udccb Spec Driven Workflow with three simple commands\\r\\n\\r\\n**Core principle:** Specs are the source of truth. Changes are proposals that modify that truth.\\r\\n\\r\\n* `/spox:propose` - Propose a change and lock your intent\\r\\n* `/spox:implement` - Impl\"])</script><script>self.__next_f.push([1,\"ement the defined task list with comprehensive verification\\r\\n* `/spox:archive` - Keep the accepted specs in sync by merging the change proposal\\r\\nThe built-in Spox MCP server provides tools for spec and change management. **Always use for spec operations**\u2014never\\r\\nuse CLI commands or direct file manipulation when working through an AI agent.\\r\\n\\r\\n## Get started in minutes\u2014no extra API keys required\\r\\n\\r\\nFor setup and update instructions read the [Setup Guide](https://marconae.github.io/spec-oxide/#/setup). Setup takes\\r\\njust a couple of minutes. Besides Claude Code, there are no additional API keys required.\\r\\n\\r\\n```bash\\r\\n# Setup\\r\\ncargo install spec-oxide\\r\\n\\r\\n# Initialize a new project\\r\\nspox init\\r\\n\\r\\n# Run the setup script to configure MCP servers (Serena, Context7)\\r\\n.spox/setup.sh\\r\\n\\r\\n# Run Claude Code\\r\\nclaude\\r\\n\\r\\n# Get started with /spox:setup\\r\\n```\\r\\n\\r\\n## User Guide\\r\\n\\r\\n[Spec Oxide User Guide](https://marconae.github.io/spec-oxide/#/mcp)\\r\\n\\r\\n## Workflow with the built-in MCP server\\r\\n\\r\\n```\\r\\nExplore \u2192 list_specs, list_changes, search_specs\\r\\nUnderstand \u2192 get_spec_requirements, get_scenario, get_change\\r\\nValidate \u2192 validate_spec, validate_change\\r\\n```\\r\\n\\r\\n## Example Usage\\r\\n\\r\\n```\\r\\n# List all specs\\r\\nmcp__spox__list_specs\\r\\n\\r\\n# Search for authentication-related specs\\r\\nmcp__spox__search_specs query=\\\"authentication\\\"\\r\\n\\r\\n# Get requirements for a specific spec\\r\\nmcp__spox__get_spec_requirements spec_id=\\\"auth\\\"\\r\\n\\r\\n# Validate a change proposal\\r\\nmcp__spox__validate_change change_id=\\\"add-two-factor-auth\\\"\\r\\n```\\r\\n\\r\\n## Tool Reference\\r\\n\\r\\n| Tool                   | Description                                    |\\r\\n|------------------------|------------------------------------------------|\\r\\n| `list_specs`           | List all capability specs in the project       |\\r\\n| `get_spec_requirements`| Retrieve requirements from a specific spec     |\\r\\n| `get_scenario`         | Get details of a specific scenario             |\\r\\n| `list_changes`         | List all active change proposals               |\\r\\n| `get_change`           | Retrieve full details of a change proposal     |\\r\\n| `search_specs`         | Full-text search across all specs and changes  |\\r\\n| `validate_spec`        | Validate a spec file for correctness           |\\r\\n| `validate_change`      | Validate a change proposal before approval     |57:T12f8,# Time MCP Server\\r\\n\\r\\nA Model Context Protocol server that provides time and timezone conversion capabilities. This server enables LLMs to get current time information and perform timezone conversions using IANA timezone names, with automatic system timezone detection.\\r\\n\\r\\n### Available Tools\\r\\n\\r\\n- `get_current_time` - Get current time in a specific timezone or system timezone.\\r\\n  - Required arguments:\\r\\n    - `timezone` (string): IANA timezone name (e.g., 'America/New_York', 'Europe/London')\\r\\n\\r\\n- `convert_time` - Convert time between timezones.\\r\\n  - Required arguments:\\r\\n    - `source_timezone` (string): Source IANA timezone name\\r\\n    - `time` (string): Time in 24-hour format (HH:MM)\\r\\n    - `target_timezone` (string): Target IANA timezone name\\r\\n\\r\\n## Installation\\r\\n\\r\\n### Using uv (recommended)\\r\\n\\r\\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\\r\\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *mcp-server-time*.\\r\\n\\r\\n### Using PIP\\r\\n\\r\\nAlternatively you can install `mcp-server-time` via pip:\\r\\n\\r\\n```bash\\r\\npip install mcp-server-time\\r\\n```\\r\\n\\r\\nAfter installation, you can run it as a script using:\\r\\n\\r\\n```bash\\r\\npython -m mcp_server_time\\r\\n```\\r\\n\\r\\n## Configuration\\r\\n\\r\\n### Configure for Claude.app\\r\\n\\r\\nAdd to your Claude settings:\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing uvx\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"time\\\": {\\r\\n    \\\"command\\\": \\\"uvx\\\",\\r\\n    \\\"args\\\": [\\\"mcp-server-time\\\"]\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing docker\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"time\\\": {\\r\\n    \\\"command\\\": \\\"docker\\\",\\r\\n    \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"mcp/time\\\"]\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing pip installation\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"time\\\": {\\r\\n    \\\"command\\\": \\\"python\\\",\\r\\n    \\\"args\\\": [\\\"-m\\\", \\\"mcp_s\"])</script><script>self.__next_f.push([1,\"erver_time\\\"]\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n### Configure for Zed\\r\\n\\r\\nAdd to your Zed settings.json:\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing uvx\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"context_servers\\\": [\\r\\n  \\\"mcp-server-time\\\": {\\r\\n    \\\"command\\\": \\\"uvx\\\",\\r\\n    \\\"args\\\": [\\\"mcp-server-time\\\"]\\r\\n  }\\r\\n],\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing pip installation\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"context_servers\\\": {\\r\\n  \\\"mcp-server-time\\\": {\\r\\n    \\\"command\\\": \\\"python\\\",\\r\\n    \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_time\\\"]\\r\\n  }\\r\\n},\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n### Customization - System Timezone\\r\\n\\r\\nBy default, the server automatically detects your system's timezone. You can override this by adding the argument `--local-timezone` to the `args` list in the configuration.\\r\\n\\r\\nExample:\\r\\n```json\\r\\n{\\r\\n  \\\"command\\\": \\\"python\\\",\\r\\n  \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_time\\\", \\\"--local-timezone=America/New_York\\\"]\\r\\n}\\r\\n```\\r\\n\\r\\n## Example Interactions\\r\\n\\r\\n1. Get current time:\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"get_current_time\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"timezone\\\": \\\"Europe/Warsaw\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\nResponse:\\r\\n```json\\r\\n{\\r\\n  \\\"timezone\\\": \\\"Europe/Warsaw\\\",\\r\\n  \\\"datetime\\\": \\\"2024-01-01T13:00:00+01:00\\\",\\r\\n  \\\"is_dst\\\": false\\r\\n}\\r\\n```\\r\\n\\r\\n2. Convert time between timezones:\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"convert_time\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"source_timezone\\\": \\\"America/New_York\\\",\\r\\n    \\\"time\\\": \\\"16:30\\\",\\r\\n    \\\"target_timezone\\\": \\\"Asia/Tokyo\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\nResponse:\\r\\n```json\\r\\n{\\r\\n  \\\"source\\\": {\\r\\n    \\\"timezone\\\": \\\"America/New_York\\\",\\r\\n    \\\"datetime\\\": \\\"2024-01-01T12:30:00-05:00\\\",\\r\\n    \\\"is_dst\\\": false\\r\\n  },\\r\\n  \\\"target\\\": {\\r\\n    \\\"timezone\\\": \\\"Asia/Tokyo\\\",\\r\\n    \\\"datetime\\\": \\\"2024-01-01T12:30:00+09:00\\\",\\r\\n    \\\"is_dst\\\": false\\r\\n  },\\r\\n  \\\"time_difference\\\": \\\"+13.0h\\\",\\r\\n}\\r\\n```\\r\\n\\r\\n## Debugging\\r\\n\\r\\nYou can use the MCP inspector to debug the server. For uvx installations:\\r\\n\\r\\n```bash\\r\\nnpx @modelcontextprotocol/inspector uvx mcp-server-time\\r\\n```\\r\\n\\r\\nOr if you've installed the package in a specific directory or are developing on it:\\r\\n\\r\\n```bash\\r\\ncd path/to/servers/src/time\\r\\nnpx @modelcontextprotocol/inspector uv run mcp-server-time\\r\\n```\\r\\n\\r\\n## Examples of Questions for Claude\\r\\n\\r\\n1. \\\"What time is it now?\\\" (will use system timezone)\\r\\n2. \\\"What time is it in Tokyo?\\\"\\r\\n3. \\\"When it's 4 PM in New York, what time is it in London?\\\"\\r\\n4. \\\"Convert 9:30 AM Tokyo time to New York time\\\"\\r\\n\\r\\n## Build\\r\\n\\r\\nDocker build:\\r\\n\\r\\n```bash\\r\\ncd src/time\\r\\ndocker build -t mcp/time .\\r\\n```\\r\\n\\r\\n## Contributing\\r\\n\\r\\nWe encourage contributions to help expand and improve mcp-server-time. Whether you want to add new time-related tools, enhance existing functionality, or improve documentation, your input is valuable.\\r\\n\\r\\nFor examples of other MCP servers and implementation patterns, see:\\r\\nhttps://github.com/modelcontextprotocol/servers\\r\\n\\r\\nPull requests are welcome! Feel free to contribute new ideas, bug fixes, or enhancements to make mcp-server-time even more powerful and useful.\\r\\n\\r\\n## License\\r\\n\\r\\nmcp-server-time is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\\r\\n58:T638,## what is Time MCP Server?\\nTime MCP Server is a Model Context Protocol server that provides time and timezone conversion capabilities. It enables LLMs to get current time information and perform timezone conversions using IANA timezone names, with automatic system timezone detection.\\n\\n## how to use Time MCP Server?\\nTo use Time MCP Server, you can install it via pip or use uvx for direct execution. After installation, configure it in your Claude or Zed settings. The server provides tools like `get_current_time` and `convert_time` to fetch current time in a specific timezone and convert time between timezones, respectively.\\n\\n## key features of Time MCP Server?\\n- Provides current time information in any IANA timezone.\\n- Converts time between different timezones.\\n- Automatic system timezone detection with the option to override.\\n- Easy integration with Claude and Zed through configuration settings.\\n\\n## use cases of Time MCP Server?\\n1. Getting the current time in a specific timezone.\\n2. Converting time betw\"])</script><script>self.__next_f.push([1,\"een different timezones for scheduling and coordination.\\n3. Automating time-related queries in applications and services.\\n\\n## FAQ from Time MCP Server?\\n- Can Time MCP Server handle all IANA timezones?\\n\\u003e Yes, Time MCP Server supports all IANA timezones for time and timezone conversion.\\n\\n- Is Time MCP Server free to use?\\n\\u003e Yes, Time MCP Server is open-source and free to use under the MIT License.\\n\\n- How accurate is the time provided by Time MCP Server?\\n\\u003e The time provided by Time MCP Server is highly accurate, relying on system time and IANA timezone data for precision.59:Tcaf,# EdgeOne Pages MCP\\n\\nAn MCP service for deploying HTML content, folder, and zip file to EdgeOne Pages and obtaining a publicly accessible URL.\\n\\n\\u003ca href=\\\"https://glama.ai/mcp/servers/@TencentEdgeOne/edgeone-pages-mcp\\\"\\u003e\\n  \\u003cimg width=\\\"380\\\" height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/@TencentEdgeOne/edgeone-pages-mcp/badge\\\" alt=\\\"EdgeOne Pages MCP server\\\" /\\u003e\\n\\u003c/a\\u003e\\n\\n## Demo\\n\\n### Deploy HTML\\n\\n![](https://cdnstatic.tencentcs.com/edgeone/pages/assets/U_GpJ-1746519327306.gif)\\n\\n### Deploy Folder\\n\\n![](https://cdnstatic.tencentcs.com/edgeone/pages/assets/kR_Kk-1746519251292.gif)\\n\\n## Requirements\\n\\n- Node.js 18 or higher\\n\\n## Configure MCP\\n\\n### stdio MCP Server\\n\\nSuitable for most MCP applications\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"edgeone-pages-mcp-server\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"edgeone-pages-mcp\\\"],\\n      \\\"env\\\": {\\n        // Optional. If deploying a folder or zip file to an EdgeOne Pages project\\n        // provide your EdgeOne Pages API token.\\n        // How to obtain your API token: https://edgeone.ai/document/177158578324279296\\n        \\\"EDGEONE_PAGES_API_TOKEN\\\": \\\"\\\",\\n        // Optional. Leave empty to create a new EdgeOne Pages project.\\n        // Provide a project name to update an existing project.\\n        \\\"EDGEONE_PAGES_PROJECT_NAME\\\": \\\"\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Streamable HTTP MCP Server\\n\\nAvailable in applications supporting Streamable HTTP MCP Server\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"edgeone-pages-mcp-server\\\": {\\n      \\\"url\\\": \\\"https://mcp-on-edge.edgeone.site/mcp-server\\\"\\n    }\\n  }\\n}\\n```\\n\\n## Architecture\\n\\n![EdgeOne Pages MCP Architecture](./assets/architecture.svg)\\n\\nThe architecture diagram illustrates the workflow:\\n\\n1. Large Language Model generates HTML content\\n2. Content is sent to the EdgeOne Pages MCP Server\\n3. MCP Server deploys the content to EdgeOne Pages Edge Functions\\n4. Content is stored in EdgeOne KV Store for fast edge access\\n5. MCP Server returns a public URL\\n6. Users can access the deployed content via browser with fast edge delivery\\n\\n## Features\\n\\n- MCP protocol for rapid deployment of HTML content to EdgeOne Pages\\n- Automatic generation of publicly accessible URLs\\n\\n## Implementation\\n\\nThis MCP service integrates with EdgeOne Pages Functions to deploy static HTML content. The implementation uses:\\n\\n1. **EdgeOne Pages Functions** - A serverless computing platform that allows execution of JavaScript/TypeScript code at the edge.\\n\\n2. **Key Implementation Details** :\\n\\n   - Uses EdgeOne Pages KV store to store and serve the HTML content\\n   - Automatically generates a public URL for each deployment\\n   - Handles API errors with appropriate error messages\\n\\n3. **How it works** :\\n\\n   - The MCP server accepts HTML content through the `deploy_html` tool\\n   - It connects to EdgeOne Pages API to get the base URL\\n   - Deploys the HTML content using the EdgeOne Pages KV API\\n   - Returns a publicly accessible URL to the deployed content\\n\\n4. **Usage Example** :\\n   - Provide HTML content to the MCP service\\n   - Receive a public URL that can be accessed immediately\\n\\nFor more information, see the [EdgeOne Pages Functions documentation](https://edgeone.ai/document/162227908259442688) and [EdgeOne Pages KV Storage Guide](https://edgeone.ai/document/162227803822321664).\\n\\n## License\\n\\nMIT5a:T4f5,## What is EdgeOne Pages MCP? \\nEdgeOne Pages MCP is a service designed for deploying HTML content to EdgeOne Pages, allowing users to obtain a publicly accessible URL for their content.\\n\\n## How to use EdgeOne Pages MCP? \\nTo use EdgeOne Pages MCP, provide your\"])</script><script>self.__next_f.push([1,\" HTML content to the MCP service, and it will deploy the content, returning a public URL that can be accessed immediately.\\n\\n## Key features of EdgeOne Pages MCP? \\n- Rapid deployment of HTML content using the MCP protocol.\\n- Automatic generation of publicly accessible URLs for deployed content.\\n\\n## Use cases of EdgeOne Pages MCP? \\n1. Deploying static HTML websites quickly.\\n2. Sharing HTML content with a public URL for easy access.\\n3. Integrating with EdgeOne Pages Functions for serverless applications.\\n\\n## FAQ from EdgeOne Pages MCP? \\n- What is the MCP protocol?  \\n\\u003e The MCP protocol is a method for quickly deploying content to EdgeOne Pages, ensuring fast access and delivery.\\n\\n- Is there a limit to the HTML content I can deploy?  \\n\\u003e There may be limitations based on the EdgeOne Pages service policies, so it's best to refer to the documentation for specifics.\\n\\n- How do I access the deployed content?  \\n\\u003e After deployment, the service will provide a public URL that can be accessed via a web browser.5b:T337b,# MCP Advisor\\n\\n[![Model Context Protocol](https://img.shields.io/badge/Model%20Context%20Protocol-purple)](https://modelcontextprotocol.org)\\n[![npm version](https://img.shields.io/npm/v/@xiaohui-wang/mcpadvisor.svg)](https://www.npmjs.com/package/@xiaohui-wang/mcpadvisor)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-istarwyh%2Fmcpadvisor-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/istarwyh/mcpadvisor)\\n\\u003c!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ --\\u003e\\n\\n\\u003ca href=\\\"https://glama.ai/mcp/servers/@istarwyh/mcpadvisor\\\"\\u003e\\n  \\u003cimg width=\\\"380\\\" height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/@istarwyh/mcpadvisor/badge\\\" alt=\\\"Advisor MCP server\\\" /\\u003e\\n\\u003c/a\\u003e\\n\\n\\n\\n[English](./README.md) | [\u7b80\u4f53\u4e2d\u6587](./README_zh.md) \\n\\n## Introduction\\n\\nMCP Advisor is a discovery and recommendation service that helps AI assistants explore Model Context Protocol (MCP) servers using natural language queries. It makes it easier for users to find and leverage MCP tools suitable for specific tasks.\\n\\n## Features\\n\\n- **Natural Language Search**: Find MCP services using conversational queries\\n- **Rich Metadata**: Get detailed information about each service\\n- **Real-time Updates**: Always in sync with the latest MCP services [![MCP Servers](https://img.shields.io/badge/MCP-Servers-red?logo=github)](https://github.com/modelcontextprotocol/servers)\\n- **Easy Integration**: Simple configuration for any MCP-compatible AI assistant\\n- **Hybrid Search Engine**: Advanced search capabilities combining vector search and text matching\\n- **Multi-provider Support**: Support for multiple search providers executing in parallel\\n\\n## Documentation Navigation\\n\\n- [Installation Guide](docs/INSTALLATION.md) - Detailed installation and configuration\"])</script><script>self.__next_f.push([1,\" instructions\\n- [User Guide](docs/USER_GUIDE.md) - How to use MCP Advisor\\n- [Architecture Documentation](docs/ARCHITECTURE.md) - System architecture details\\n- [Technical Details](docs/TECHNICAL_DETAILS.md) - Advanced technical features\\n- [Developer Guide](docs/DEVELOPER_GUIDE.md) - Development environment setup and code contribution\\n- [Best Practices](docs/BEST_PRACTICES.md) - Coding standards and best practices for contributors\\n- [Troubleshooting](docs/TROUBLESHOOTING.md) - Common issues and solutions\\n- [Search Providers](docs/SEARCH_PROVIDERS.md) - Search provider details\\n- [API Reference](docs/API_REFERENCE.md) - API documentation\\n- [Roadmap](ROADMAP.md) - Future development plans\\n- [Contribution Guidelines](CONTRIBUTING.md) - How to contribute code\\n\\n## Quick Start\\n\\n### Installation\\n\\nThe fastest way is to integrate MCP Advisor through MCP configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcpadvisor\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"@xiaohui-wang/mcpadvisor\\\"]\\n    }\\n  }\\n}\\n```\\n\\nAdd this configuration to your AI assistant's MCP settings file:\\n\\n- MacOS/Linux: `~/Library/Application Support/Claude/claude_desktop_config.json`\\n- Windows: `%AppData%\\\\Claude\\\\claude_desktop_config.json`\\n\\nFor more installation methods, see the [Installation Guide](docs/INSTALLATION.md).\\n\\n### Demo\\n\\n\\u003cdiv align=\\\"center\\\"\\u003e\\n  \\u003ca href=\\\"https://www.bilibili.com/video/BV17tJuz9Eci\\\"\\u003e\\n    \\u003cimg src=\\\"https://xiaohui-zhangjiakou.oss-cn-zhangjiakou.aliyuncs.com/image/202505181400161.png\\\" alt=\\\"MCP Advisor Demo\\\" width=\\\"640\\\"\\u003e\\n  \\u003c/a\\u003e\\n  \\u003cp\\u003eClick the image to watch the demo video\\u003c/p\\u003e\\n\\u003c/div\\u003e\\n\\n## Developer Guide\\n\\n### Architecture Overview\\n\\nMCP Advisor adopts a modular architecture with clear separation of concerns and functional programming principles:\\n\\n```mermaid\\ngraph TD\\n    Client[\\\"Client Application\\\"] --\\u003e |\\\"MCP Protocol\\\"| Transport[\\\"Transport Layer\\\"]\\n    \\n    subgraph \\\"MCP Advisor Server\\\"\\n        Transport --\\u003e |\\\"Request\\\"| SearchService[\\\"Search Service\\\"]\\n        SearchService --\\u003e |\\\"Query\\\"| Providers[\\\"Search Providers\\\"]\\n        \\n        subgraph \\\"Search Providers\\\"\\n            Providers --\\u003e MeilisearchProvider[\\\"Meilisearch Provider\\\"]\\n            Providers --\\u003e GetMcpProvider[\\\"GetMCP Provider\\\"]\\n            Providers --\\u003e CompassProvider[\\\"Compass Provider\\\"]\\n            Providers --\\u003e OfflineProvider[\\\"Offline Provider\\\"]\\n        end\\n        \\n        OfflineProvider --\\u003e |\\\"Hybrid Search\\\"| HybridSearch[\\\"Hybrid Search Engine\\\"]\\n        HybridSearch --\\u003e TextMatching[\\\"Text Matching\\\"]\\n        HybridSearch --\\u003e VectorSearch[\\\"Vector Search\\\"]\\n        \\n        SearchService --\\u003e |\\\"Merge \\u0026 Filter\\\"| ResultProcessor[\\\"Result Processor\\\"]\\n        \\n        SearchService --\\u003e Logger[\\\"Logging System\\\"]\\n    end\\n```\\n\\n### Core Components\\n\\n1. **Search Service Layer**\\n   - Unified search interface and provider aggregation\\n   - Support for multiple search providers executing in parallel\\n   - Configurable search options (limit, minSimilarity)\\n\\n2. **Search Providers**\\n   - **Meilisearch Provider**: Vector search using Meilisearch\\n   - **GetMCP Provider**: API search from the GetMCP registry\\n   - **Compass Provider**: API search from the Compass registry\\n   - **Offline Provider**: Hybrid search combining text and vectors\\n\\n3. **Hybrid Search Strategy**\\n   - Intelligent combination of text matching and vector search\\n   - Configurable weight balancing\\n   - Smart adaptive filtering mechanisms\\n\\n4. **Transport Layer**\\n   - Stdio (CLI default)\\n   - SSE (Web integration)\\n   - REST API endpoints\\n\\nFor more detailed architecture documentation, see [ARCHITECTURE.md](docs/ARCHITECTURE.md).\\n\\n## Technical Highlights\\n\\n### Advanced Search Techniques\\n\\n1. **Vector Normalization**\\n   - All vectors are normalized to unit length (magnitude = 1)\\n   - Ensures consistent cosine similarity calculations\\n   - Improves search precision by focusing on direction rather than magnitude\\n\\n2. **Parallel Search Execution**\\n   - Vector search and text search run in parallel\\n   - Leverages Promise.all for optimal performance\\n   - Fallback mechanisms enabled if either search fails\\n\\n3. **Weighted Result Merging**\\n   - Configurable wei\"])</script><script>self.__next_f.push([1,\"ghts between vector and text results\\n   - Default: vector similarity (70%), text matching (30%)\\n\\n### Error Handling and Logging System\\n\\nMCP Advisor implements robust error handling and logging systems:\\n\\n1. **Contextual Error Formatting**\\n   - Standardized error object enrichment\\n   - Stack trace preservation and formatting\\n   - Error type categorization and standardization\\n\\n2. **Graceful Degradation**\\n   - Multi-provider fallback strategies\\n   - Partial result processing\\n   - Default responses for critical failures\\n\\nFor more technical details, see [TECHNICAL_DETAILS.md](docs/TECHNICAL_DETAILS.md).\\n\\n## Developer Quick Start\\n\\n### Development Environment Setup\\n\\n1. Clone the repository\\n2. Install dependencies:\\n   ```bash\\n   npm install\\n   ```\\n3. Configure environment variables (see [INSTALLATION.md](docs/INSTALLATION.md))\\n\\n### Library Usage\\n\\n```typescript\\nimport { SearchService } from '@xiaohui-wang/mcpadvisor';\\n\\n// Initialize search service\\nconst searchService = new SearchService();\\n\\n// Search for MCP servers\\nconst results = await searchService.search('vector database integration');\\nconsole.log(results);\\n```\\n\\n### Transport Options\\n\\nMCP Advisor supports multiple transport methods:\\n\\n1. **Stdio Transport** (default) - Suitable for command-line tools\\n2. **SSE Transport** - Suitable for web integration\\n3. **REST Transport** - Provides REST API endpoints\\n\\nFor more development details, see [DEVELOPER_GUIDE.md](docs/DEVELOPER_GUIDE.md).\\n\\n## Contribution Guidelines\\n\\n1. Follow commit message conventions:\\n   - Use lowercase types (feat, fix, docs, etc.)\\n   - Write descriptive messages in sentence format\\n\\n2. Ensure code quality:\\n   - Run tests: `npm test`\\n   - Check types: `npm run type-check`\\n   - Lint code: `npm run lint`\\n\\nFor detailed contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n## Usage Examples\\n\\n### Example Queries\\n\\nHere are some example queries you can use with MCP Advisor:\\n\\n```\\n\\\"Find MCP servers for natural language processing\\\"\\n\\\"MCP servers for financial data analysis\\\"\\n\\\"E-commerce recommendation engine MCP servers\\\"\\n\\\"MCP servers with image recognition capabilities\\\"\\n\\\"Weather data processing MCP servers\\\"\\n\\\"Document summarization MCP servers\\\"\\n```\\n\\n### Example Response\\n\\n```json\\n[\\n  {\\n    \\\"title\\\": \\\"NLP Toolkit\\\",\\n    \\\"description\\\": \\\"Comprehensive natural language processing toolkit with sentiment analysis, entity recognition, and text summarization capabilities.\\\",\\n    \\\"github_url\\\": \\\"https://github.com/example/nlp-toolkit\\\",\\n    \\\"similarity\\\": 0.92\\n  },\\n  {\\n    \\\"title\\\": \\\"Text Processor\\\",\\n    \\\"description\\\": \\\"Efficient text processing MCP server with multi-language support.\\\",\\n    \\\"github_url\\\": \\\"https://github.com/example/text-processor\\\",\\n    \\\"similarity\\\": 0.85\\n  }\\n]\\n```\\n\\nFor more examples, see [EXAMPLES.md](docs/EXAMPLES.md).\\n\\n## Troubleshooting\\n\\n### Common Issues\\n\\n1. **Connection Refused**\\n   - Ensure the server is running on the specified port\\n   - Check firewall settings\\n\\n2. **No Results Returned**\\n   - Try a more general query\\n   - Check network connection to registry APIs\\n\\n3. **Performance Issues**\\n   - Consider adding more specific search terms\\n   - Check server resources (CPU/memory)\\n\\nFor more troubleshooting information, see [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md).\\n\\n## Search Providers\\n\\nMCP Advisor supports multiple search providers that can be used simultaneously:\\n\\n1. **Compass Search Provider**: Retrieves MCP server information using the Compass API\\n2. **GetMCP Search Provider**: Uses the GetMCP API and vector search for semantic matching\\n3. **Meilisearch Search Provider**: Uses Meilisearch for fast, fault-tolerant text search\\n\\nFor detailed information about search providers, see [SEARCH_PROVIDERS.md](docs/SEARCH_PROVIDERS.md).\\n\\n## API Documentation\\n\\nFor detailed API documentation, see [API_REFERENCE.md](docs/API_REFERENCE.md).\\n\\n## Roadmap\\n\\nMCP Advisor is evolving from a simple recommendation system to an intelligent agent orchestration platform. Our vision is to create a system that not only recommends the right MCP servers but also learns from interactions and helps agents dynamically plan and execute c\"])</script><script>self.__next_f.push([1,\"omplex tasks.\\n\\n```mermaid\\ngantt\\n    title MCP Advisor Evolution Roadmap\\n    dateFormat  YYYY-MM-DD\\n    axisFormat  %Y-%m\\n    \\n    section Foundation\\n    Enhanced Search \\u0026 Recommendation \u2713       :done, 2025-01-01, 90d\\n    Hybrid Search Engine \u2713                   :done, 2025-01-01, 90d\\n    Provider Priority System \u2713               :done, 2025-04-01, 60d\\n    \\n    section Intelligence Layer\\n    Feedback Collection System               :active, 2025-04-01, 90d\\n    Agent Interaction Analytics             :2025-07-01, 120d\\n    Usage Pattern Recognition               :2025-07-01, 90d\\n    \\n    section Learning Systems\\n    Reinforcement Learning Framework         :2025-10-01, 180d\\n    Contextual Bandit Implementation         :2025-10-01, 120d\\n    Multi-Agent Reward Modeling             :2026-01-01, 90d\\n    \\n    section Advanced Features\\n    Task Decomposition Engine               :2026-01-01, 120d\\n    Dynamic Planning System                 :2026-04-01, 150d\\n    Adaptive MCP Orchestration              :2026-04-01, 120d\\n    \\n    section Ecosystem\\n    Developer SDK \\u0026 API                     :2026-07-01, 90d\\n    Custom MCP Training Tools               :2026-07-01, 120d\\n    Enterprise Integration Framework        :2026-10-01, 150d\\n```\\n\\n### Major Development Phases\\n\\n1. **Recommendation Capability Optimization** (2025 Q2-Q3)\\n   - Accept user feedback\\n   - Refine recommendation effectiveness\\n   - Introduce more indices\\n\\nFor a detailed roadmap, see [ROADMAP.md](ROADMAP.md).\\n\\nTo Implement the above features, we need to:\\n\\n- [ ] Full-Text Index Search\\n- [ ] Utilize Professional Rerank Module like https://github.com/PrithivirajDamodaran/FlashRank \\n\\n## Testing\\n\\nUse [inspector](https://github.com/modelcontextprotocol/inspector) for testing:\\n\\n```bash \\nnpx @modelcontextprotocol/inspector\\n```\\n\\n\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.5c:T66f,## What is MCP Advisor? \\nMCP Advisor is a discovery and recommendation service designed to help users explore Model Context Protocol (MCP) servers. It acts as a smart guide for AI assistants, enabling them to find and understand available MCP services through natural language queries.\\n\\n## How to use MCP Advisor? \\nTo use MCP Advisor, clone the repository or utilize `npx`. Configure your AI assistant to integrate with MCP Advisor by editing the appropriate configuration files based on your operating system.\\n\\n## Key features of MCP Advisor? \\n- **Smart Search**: Allows users to find MCP services using natural language queries.\\n- **Rich Metadata**: Provides detailed information about each service.\\n- **Real-time Updates**: Ensures users have access to the latest MCP services.\\n- **Easy Integration**: Simple integration with any MCP-compatible AI assistant.\\n\\n## Use cases of MCP Advisor? \\n1. Discovering MCP servers for natural language processing tasks.\\n2. Finding MCP servers for financial data analysis.\\n3. Identifying recommendation engine MCP servers for e-commerce applications.\\n4. Locating MCP servers with image recognition capabilities.\\n\\n## FAQ from MCP Advisor? \\n- **What is the purpose of MCP Advisor?**  \\n\\u003e MCP Advisor helps users discover and utilize the right MCP services for their specific tasks through natural language queries.\\n\\n- **Is MCP Advisor free to use?**  \\n\\u003e Yes! MCP Advisor is open-source and free to use.\\n\\n- **How can I troubleshoot common issues?**  \\n\\u003e Common issues include connection problems, no results returned, and performance issues. Refer to the troubleshooting section in the documentation for solutions.5d:T727,[{\\\"name\\\":\\\"recommend-mcp-servers\\\",\\\"description\\\":\\\"\\\\n              \u6b64\u5de5\u5177\u7528\u4e8e\u5bfb\u627e\u5408\u9002\u4e14\u4e13\u4e1aMCP\u670d\u52a1\u5668\u3002\\\\n              \u57fa\u4e8e\u60a8\u7684\u5177\u4f53\u9700\u6c42\uff0c\u4ece\u4e92\u8054\u7f51\u8d44\u6e90\u5e93\u4ee5\u53ca\u5185\u90e8MCP\u5e93\u4e2d\u7b5b\u9009\u5e76\u63a8\u8350\u6700\u9002\u5408\u7684MCP\u670d\u52a1\u5668\u89e3\u51b3\u65b9\u6848\u3002\\\\n              \u8fd4\u56de\u7ed3\u679c\u5305\u542b\u670d\u52a1\u5668\u540d\u79f0\u3001\u529f\u80fd\u63cf\u8ff0\u3001\u6240\u5c5e\u7c7b\u522b\uff0c\u4e3a\u60a8\u7684\u4e1a\u52a1\u6210\u529f\u63d0\u4f9b\u7cbe\u51c6\u6280\u672f\u652f\u6301\u3002\\\\n              \\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"query\\\":{\\\"description\\\":\\\"\\\\n                    \u8bf7\u63d0\u4f9b\u6240\u9700MCP\u670d\u52a1\u5668\u7684\"])</script><script>self.__next_f.push([1,\"\u7cbe\u786e\u63cf\u8ff0\u3002\\\\n                    \\\\n                    \u6709\u6548\u67e5\u8be2\u793a\u4f8b\uff1a\\\\n                    - '\u7528\u4e8e\u98ce\u63a7\u7b56\u7565\u90e8\u7f72\u7684MCP\u670d\u52a1\u5668'\\\\n                    - '\u4fdd\u9669\u4ea7\u54c1\u7cbe\u7b97\u5b9a\u4ef7\u7684MCP\u670d\u52a1\u5668'\\\\n                    \\\\n                    \u65e0\u6548\u67e5\u8be2\u793a\u4f8b\uff1a\\\\n                    - '\u4fdd\u9669MCP\u670d\u52a1\u5668'\uff08\u8fc7\u4e8e\u5bbd\u6cdb\uff09\\\\n                    - '\u98ce\u63a7\u7cfb\u7edf'\uff08\u7f3a\u4e4f\u5177\u4f53\u4fdd\u9669\u573a\u666f\uff09\\\\n                    - '\u7cbe\u7b97\u5de5\u5177'\uff08\u672a\u6307\u660e\u5177\u4f53\u529f\u80fd\u9700\u6c42\uff09\\\\n                    \\\\n                    \u67e5\u8be2\u5e94\u660e\u786e\u6307\u5b9a\uff1a\\\\n                    1. \u4e1a\u52a1\u6d41\u7a0b\uff08\u5982\u4ea7\u54c1\u5b9a\u4ef7\u3001\u6838\u4fdd\u3001\u7406\u8d54\u3001\u51c6\u5907\u91d1\u8ba1\u7b97\u7b49\uff09\\\\n                    2. \u5177\u4f53\u529f\u80fd\u9700\u6c42\uff08\u5982\u98ce\u9669\u5206\u6790\u3001\u7b56\u7565\u90e8\u7f72\u3001\u7b56\u7565\u7814\u53d1\u3001\u7279\u5f81\u7814\u53d1\u7b49\uff09\\\\n                    \\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"install-mcp-server\\\",\\\"description\\\":\\\"\\\\n              \u6b64\u5de5\u5177\u7528\u4e8e\u5b89\u88c5MCP\u670d\u52a1\u5668\u3002\\\\n              \u8bf7\u544a\u8bc9\u6211\u60a8\u60f3\u8981\u5b89\u88c5\u54ea\u4e2a MCP \u4ee5\u53ca\u5176 githubUrl,\u6211\u5c06\u4f1a\u544a\u8bc9\u60a8\u5982\u4f55\u5b89\u88c5\u5bf9\u5e94\u7684 MCP\\\\n              \\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"githubUrl\\\":{\\\"description\\\":\\\"\u8bf7\u8f93\u5165\u60a8\u60f3\u8981\u5b89\u88c5\u7684MCP\u7684githubUrl\u3002\\\",\\\"type\\\":\\\"string\\\"},\\\"mcpName\\\":{\\\"description\\\":\\\"\u8bf7\u8f93\u5165\u60a8\u60f3\u8981\u5b89\u88c5\u7684MCP\u540d\u79f0\u3002\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"mcpName\\\",\\\"githubUrl\\\"]}}]5e:Td07,# Jina AI MCP Tools\\r\\n\\r\\nA Model Context Protocol (MCP) server that integrates with [Jina AI Search Foundation APIs](https://docs.jina.ai/).\\r\\n\\r\\n## Features\\r\\n\\r\\nThis MCP server provides access to the following Jina AI APIs:\\r\\n\\r\\n- **Web Reader** - Extract content from web pages using r.jina.ai\\r\\n- **Web Search** - Search the web using s.jina.ai\\r\\n- **Fact-Check** - Verify factual statements using g.jina.ai\\r\\n\\r\\n## Prerequisites\\r\\n\\r\\n1. **Jina AI API Key** - Get a free API key from [https://jina.ai/?sui=apikey](https://jina.ai/?sui=apikey)\\r\\n2. **Node.js** - Version 16 or higher\\r\\n\\r\\n## Cursor Editor Configuration\\r\\n\\r\\nYou can integrate this MCP server with Cursor to enhance your coding experience.\\r\\n\\r\\n### Configuration File Setup\\r\\n\\r\\nCreate a `.cursor/mcp.json` file in your project or in your home directory (`~/.cursor/mcp.json` for global access) with the following structure:\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"jina-mcp-tools\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\\"jina-mcp-tools\\\"],\\r\\n      \\\"env\\\": {\\r\\n        \\\"JINA_API_KEY\\\": \\\"your_jina_api_key_here\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### Using the Tools\\r\\n\\r\\nOnce configured, Cursor's Agent will automatically use the Jina AI tools when appropriate. You can also explicitly instruct Agent to use specific tools:\\r\\n\\r\\n- \\\"Search the web for quantum computing using Jina tools\\\"\\r\\n- \\\"Extract content from https://example.com using the jina_reader tool\\\"\\r\\n- \\\"Use jina_fact_check to verify if the Earth is flat\\\"\\r\\n\\r\\nWhen a tool is called, Cursor will display the response in the chat. By default, you'll need to approve each tool usage.\\r\\n\\r\\nFor unattended operation, you can enable Yolo mode in Cursor settings, which allows tools to run without approval (similar to terminal commands).\\r\\n\\r\\n## Available Tools\\r\\n\\r\\n### jina_reader\\r\\n\\r\\nExtract content from a webpage in a format optimized for LLMs.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"jina_reader\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"url\\\": \\\"https://example.com\\\",\\r\\n    \\\"format\\\": \\\"Markdown\\\",\\r\\n    \\\"withLinks\\\": false,\\r\\n    \\\"withImages\\\": false\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nOptions for `format` include: \\\"Default\\\", \\\"Markdown\\\", \\\"HTML\\\", \\\"Text\\\", \\\"Screenshot\\\", \\\"Pageshot\\\"\\r\\n\\r\\n### jina_search\\r\\n\\r\\nSearch the web for information.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"jina_search\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"query\\\": \\\"How does quantum computing work?\\\",\\r\\n    \\\"count\\\": 5,\\r\\n    \\\"returnFormat\\\": \\\"markdown\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nOptions for `returnFormat` include: \\\"markdown\\\", \\\"text\\\", \\\"html\\\"\\r\\n\\r\\n### jina_fact_check\\r\\n\\r\\nVerify factual statements.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"jina_fact_check\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"statement\\\": \\\"The Earth is flat\\\",\\r\\n    \\\"deepdive\\\": false\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Prompt Templates\\r\\n\\r\\n### jina_web_search\\r\\n\\r\\nA prompt template for searching the web.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"jina_web_search\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"query\\\": \\\"Recent advances in f\"])</script><script>self.__next_f.push([1,\"usion energy\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### jina_research\\r\\n\\r\\nA prompt template for conducting research.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"jina_research\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"topic\\\": \\\"Climate change solutions\\\",\\r\\n    \\\"depth\\\": \\\"detailed\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nOptions for `depth` include: \\\"basic\\\", \\\"detailed\\\", \\\"comprehensive\\\"\\r\\n\\r\\n## License\\r\\n\\r\\nMIT\\r\\n\\r\\n## Links\\r\\n\\r\\n- GitHub: [https://github.com/PsychArch/jina-mcp-tools](https://github.com/PsychArch/jina-mcp-tools)\\r\\n- Issues: [https://github.com/PsychArch/jina-mcp-tools/issues](https://github.com/PsychArch/jina-mcp-tools/issues)5f:T4ac,## what is Jina AI MCP Tools? \\nJina AI MCP Tools is a Model Context Protocol (MCP) server that integrates with Jina AI Search Foundation APIs, enabling users to access various AI-driven tools for web reading, searching, and fact-checking.\\n\\n## how to use Jina AI MCP Tools? \\nTo use Jina AI MCP Tools, you need to set up a configuration file for Cursor and provide your Jina API key. Once configured, you can instruct Cursor to use the Jina tools for various tasks.\\n\\n## key features of Jina AI MCP Tools? \\n- **Web Reader**: Extracts content from web pages.\\n- **Web Search**: Searches the web for information.\\n- **Fact-Check**: Verifies factual statements.\\n\\n## use cases of Jina AI MCP Tools? \\n1. Extracting content from a specific webpage for analysis.\\n2. Searching for information on complex topics like quantum computing.\\n3. Verifying claims or statements for accuracy.\\n\\n## FAQ from Jina AI MCP Tools? \\n- How do I get a Jina API key?  \\n\\u003e You can obtain a free API key from the Jina AI website.\\n\\n- What programming language is Jina AI MCP Tools built with?  \\n\\u003e Jina AI MCP Tools is built using JavaScript.\\n\\n- Is there a license for Jina AI MCP Tools?  \\n\\u003e Yes, it is licensed under the MIT license.60:T62c,[{\\\"name\\\":\\\"jina_reader\\\",\\\"description\\\":\\\"Read and extract content from web pages using Jina AI's powerful web reader\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"format\\\":{\\\"default\\\":\\\"Markdown\\\",\\\"description\\\":\\\"Output format for the extracted content\\\",\\\"enum\\\":[\\\"Default\\\",\\\"Markdown\\\",\\\"HTML\\\",\\\"Text\\\",\\\"Screenshot\\\",\\\"Pageshot\\\"],\\\"type\\\":\\\"string\\\"},\\\"url\\\":{\\\"description\\\":\\\"URL of the webpage to read and extract content from\\\",\\\"format\\\":\\\"uri\\\",\\\"type\\\":\\\"string\\\"},\\\"withImages\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Include images in the extracted content\\\",\\\"type\\\":\\\"boolean\\\"},\\\"withLinks\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Include links in the extracted content\\\",\\\"type\\\":\\\"boolean\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"jina_search\\\",\\\"description\\\":\\\"Search the web for information using Jina AI's semantic search engine\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"count\\\":{\\\"default\\\":5,\\\"description\\\":\\\"Number of search results to return\\\",\\\"type\\\":\\\"number\\\"},\\\"query\\\":{\\\"description\\\":\\\"Search query to find information on the web\\\",\\\"minLength\\\":1,\\\"type\\\":\\\"string\\\"},\\\"returnFormat\\\":{\\\"default\\\":\\\"markdown\\\",\\\"description\\\":\\\"Format of the returned search results\\\",\\\"enum\\\":[\\\"markdown\\\",\\\"text\\\",\\\"html\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"jina_fact_check\\\",\\\"description\\\":\\\"Verify the factuality of statements using Jina AI's fact-checking capability\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"deepdive\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Enable deep analysis with more comprehensive research\\\",\\\"type\\\":\\\"boolean\\\"},\\\"statement\\\":{\\\"description\\\":\\\"Statement to fact-check for accuracy\\\",\\\"minLength\\\":1,\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"statement\\\"]}}]61:T62e,[{\\\"name\\\":\\\"mcp_howtocook_getAllRecipes\\\",\\\"description\\\":\\\"\u83b7\u53d6\u6240\u6709\u83dc\u8c31\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"no_param\\\":{\\\"description\\\":\\\"\u65e0\u53c2\u6570\\\",\\\"type\\\":\\\"string\\\"}}}},{\\\"name\\\":\\\"mcp_howtocook_getRecipesByCategory\\\",\\\"description\\\":\\\"\u6839\u636e\u5206\u7c7b\u67e5\u8be2\u83dc\u8c31\uff0c\u53ef\u9009\u5206\u7c7b\u6709: \u6c34\u4ea7, \u65e9\u9910, \u8c03\u5473\u6599, \u751c\u54c1, \u996e\u54c1, \u8364\u83dc, \u534a\u6210\u54c1, \u6c64\u7fb9, \u4e3b\u98df, \u7d20\u83dc\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"category\\\":{\\\"description\\\":\\\"\u83dc\u8c31\u5206\u7c7b\u540d\u79f0\uff0c\u5982\u6c34\u4ea7\u3001\u65e9\u9910\u3001\u8364\u83dc\u3001\u4e3b\u98df\u7b49\\\",\\\"enum\\\":[\\\"\u6c34\u4ea7\\\",\\\"\u65e9\u9910\\\",\\\"\u8c03\u5473\u6599\\\",\\\"\u751c\u54c1\\\",\\\"\u996e\u54c1\\\",\\\"\u8364\u83dc\\\",\\\"\u534a\u6210\u54c1\\\",\\\"\u6c64\u7fb9\\\",\\\"\u4e3b\u98df\\\",\\\"\u7d20\u83dc\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"category\\\"]}},{\\\"name\\\":\\\"mcp_howtocook_recommendMeals\\\",\\\"description\\\":\\\"\u6839\u636e\u7528\u6237\u7684\u5fcc\u53e3\u3001\u8fc7\u654f\u539f\u3001\"])</script><script>self.__next_f.push([1,\"\u4eba\u6570\u667a\u80fd\u63a8\u8350\u83dc\u8c31\uff0c\u521b\u5efa\u4e00\u5468\u7684\u81b3\u98df\u8ba1\u5212\u4ee5\u53ca\u5927\u81f4\u7684\u8d2d\u7269\u6e05\u5355\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"allergies\\\":{\\\"description\\\":\\\"\u8fc7\u654f\u539f\u5217\u8868\uff0c\u5982[\\\\\\\"\u5927\u849c\\\\\\\", \\\\\\\"\u867e\\\\\\\"]\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"avoidItems\\\":{\\\"description\\\":\\\"\u5fcc\u53e3\u98df\u6750\u5217\u8868\uff0c\u5982[\\\\\\\"\u8471\\\\\\\", \\\\\\\"\u59dc\\\\\\\"]\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"peopleCount\\\":{\\\"description\\\":\\\"\u7528\u9910\u4eba\u6570\uff0c1-10\u4e4b\u95f4\u7684\u6574\u6570\\\",\\\"maximum\\\":10,\\\"minimum\\\":1,\\\"type\\\":\\\"integer\\\"}},\\\"required\\\":[\\\"peopleCount\\\"]}},{\\\"name\\\":\\\"mcp_howtocook_whatToEat\\\",\\\"description\\\":\\\"\u4e0d\u77e5\u9053\u5403\u4ec0\u4e48\uff1f\u6839\u636e\u4eba\u6570\u76f4\u63a5\u63a8\u8350\u9002\u5408\u7684\u83dc\u54c1\u7ec4\u5408\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"peopleCount\\\":{\\\"description\\\":\\\"\u7528\u9910\u4eba\u6570\uff0c1-10\u4e4b\u95f4\u7684\u6574\u6570\uff0c\u4f1a\u6839\u636e\u4eba\u6570\u63a8\u8350\u5408\u9002\u6570\u91cf\u7684\u83dc\u54c1\\\",\\\"maximum\\\":10,\\\"minimum\\\":1,\\\"type\\\":\\\"integer\\\"}},\\\"required\\\":[\\\"peopleCount\\\"]}}]62:T2bce,![export](https://github.com/MiniMax-AI/MiniMax-01/raw/main/figures/MiniMaxLogo-Light.png)\\n\\n\\u003cdiv align=\\\"center\\\" style=\\\"line-height: 1;\\\"\\u003e\\n  \\u003ca href=\\\"https://www.minimax.io\\\" target=\\\"_blank\\\" style=\\\"margin: 2px; color: var(--fgColor-default);\\\"\\u003e\\n    \\u003cimg alt=\\\"Homepage\\\" src=\\\"https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-square\\u0026labelColor=2C3E50\\u0026logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+\\u0026logoWidth=20\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n  \\u003ca href=\\\"https://arxiv.org/abs/2501.08313\\\" target=\\\"_blank\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"Paper\\\" src=\\\"https://img.shields.io/badge/\ud83d\udcd6_Paper-MiniMax--01-FF4040?style=flat-square\\u0026labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n   \\u003ca href=\\\"https://chat.minimax.io/\\\" target=\\\"_blank\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"Chat\\\" src=\\\"https://img.shields.io/badge/_MiniMax_Chat-FF4040?style=flat-square\\u0026labelColor=2C3E50\\u0026logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1Q\"])</script><script>self.__next_f.push([1,\"TQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+\\u0026logoWidth=20\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n  \\u003ca href=\\\"https://www.minimax.io/platform\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"API\\\" src=\\\"https://img.shields.io/badge/\u26a1_API-Platform-FF4040?style=flat-square\\u0026labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e  \\n\\u003c/div\\u003e\\n\\u003cdiv align=\\\"center\\\" style=\\\"line-height: 1;\\\"\\u003e\\n  \\u003ca href=\\\"https://huggingface.co/MiniMaxAI\\\" target=\\\"_blank\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"Hugging Face\\\" src=\\\"https://img.shields.io/badge/\ud83e\udd17_Hugging_Face-MiniMax-FF4040?style=flat-square\\u0026labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n  \\u003ca href=\\\"https://github.com/MiniMax-AI/MiniMax-01/blob/main/figures/wechat-qrcode.jpeg\\\" target=\\\"_blank\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"WeChat\\\" src=\\\"https://img.shields.io/badge/_WeChat-MiniMax-FF4040?style=flat-square\\u0026labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n  \\u003ca href=\\\"https://www.modelscope.cn/organization/MiniMax\\\" target=\\\"_blank\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"ModelScope\\\" src=\\\"https://img.shields.io/badge/_ModelScope-MiniMax-FF4040?style=flat-square\\u0026labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n\\u003c/div\\u003e\\n\\u003cdiv align=\\\"center\\\" style=\\\"line-height: 1;\\\"\\u003e\\n   \\u003ca href=\\\"https://github.com/MiniMax-AI/MiniMax-MCP/blob/main/LICENSE\\\" style=\\\"margin: 2px;\\\"\\u003e\\n    \\u003cimg alt=\\\"Code License\\\" src=\\\"https://img.shields.io/badge/_Code_License-MIT-FF4040?style=flat-square\\u0026labelColor=2C3E50\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n  \\u003c/a\\u003e\\n\\u003c/div\\u003e\\n\\n\\u003cp align=\\\"center\\\"\\u003e\\n  Official MiniMax Model Context Protocol (MCP) server that enables interaction with powerful Text to Speech and video/image generation APIs. This server allows MCP clients like \\u003ca href=\\\"https://www.anthropic.com/claude\\\"\\u003eClaude Desktop\\u003c/a\\u003e, \\u003ca href=\\\"https://www.cursor.so\\\"\\u003eCursor\\u003c/a\\u003e, \\u003ca href=\\\"https://codeium.com/windsurf\\\"\\u003eWindsurf\\u003c/a\\u003e, \\u003ca href=\\\"https://github.com/openai/openai-agents-python\\\"\\u003eOpenAI Agents\\u003c/a\\u003e and others to generate speech, clone voices, generate video, generate image and more.\\n\\u003c/p\\u003e\\n\\n## Documentation\\n- [\u4e2d\u6587\u6587\u6863](README-CN.md)\\n- [MiniMax-MCP-JS](https://github.com/MiniMax-AI/MiniMax-MCP-JS) - Official JavaScript implementation of MiniMax MCP\\n\\n## Quickstart with MCP Client\\n1. Get your API key from [MiniMax](https://www.minimax.io/platform/user-center/basic-information/interface-key). \\n2. Install `uv` (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh` or see the `uv` [repo](https://github.com/astral-sh/uv) for additional install methods.\\n3. **Important**: The API host and key vary by region and must match; otherwise, you'll encounter an `Invalid API key` error.\\n\\n|Region| Global  | Mainland  |\\n|:--|:-----|:-----|\\n|MINIMAX_API_KEY| go get from [MiniMax Global](https://www.minimax.io/platform/user-center/basic-information/interface-key) | go get from [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interface-key) |\\n|MINIMAX_API_HOST| https://api.minimaxi.chat (note the extra **\\\"i\\\"**) | https://api.minimax.chat |\\n\\n\\n### Claude Desktop\\nGo to `Claude \\u003e Settings \\u003e Developer \\u003e Edit Config \\u003e claude_desktop_config.json` to include the following:\\n\\n```\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"MiniMax\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\": [\\n        \\\"minimax-mcp\\\",\\n        \\\"-y\\\"\\n      ],\\n      \\\"env\\\": {\\n        \\\"MINIMAX_API_KEY\\\": \\\"insert-your-api-key-here\\\",\\n        \\\"MINIMAX_MCP_BASE_PATH\\\": \\\"local-output-dir-path, such as /User/xxx/Desktop\\\",\\n        \\\"MINIMAX_API_HOST\\\": \\\"api host, https://api.minimaxi.chat|https://api.minimax.chat\\\",\\n        \\\"MINIMAX_API_RESOURCE_MODE\\\": \\\"optional, [url|local], url is default, audio/image/video are downloaded locally or provided in URL format\\\"\\n      }\\n    }\\n  }\\n}\\n\\n```\\n\u26a0\ufe0f Warning: The API key needs to match the host. If an error \\\"API Error: invalid api key\\\" occurs, please check your api host:\\n- Global Host\uff1a`https://api.minimaxi.chat` (note the extra \\\"i\\\")\\n- Mainland Host\uff1a`https://api.minimax.chat`\\n\\nIf you'\"])</script><script>self.__next_f.push([1,\"re using Windows, you will have to enable \\\"Developer Mode\\\" in Claude Desktop to use the MCP server. Click \\\"Help\\\" in the hamburger menu in the top left and select \\\"Enable Developer Mode\\\".\\n\\n\\n### Cursor\\nGo to `Cursor -\\u003e Preferences -\\u003e Cursor Settings -\\u003e MCP -\\u003e Add new global MCP Server` to add above config.\\n\\nThat's it. Your MCP client can now interact with MiniMax through these tools:\\n\\n## Transport\\nWe support two transport types: stdio and sse.\\n| stdio  | SSE  |\\n|:-----|:-----|\\n| Run locally | Can be deployed locally or in the cloud |\\n| Communication through `stdout` | Communication through `network` |\\n| Input: Supports processing `local files` or valid `URL` resources | Input: When deployed in the cloud, it is recommended to use `URL` for input |\\n\\n## Available Tools\\n| tool  | description  |\\n|-|-|\\n|`text_to_audio`|Convert text to audio with a given voice|\\n|`list_voices`|List all voices available|\\n|`voice_clone`|Clone a voice using provided audio files|\\n|`generate_video`|Generate a video from a prompt|\\n|`text_to_image`|Generate a image from a prompt|\\n|`query_video_generation`|Query the result of video generation task|\\n\\n## FAQ\\n### 1. invalid api key\\nPlease ensure your API key and API host are regionally aligned\\n|Region| Global  | Mainland  |\\n|:--|:-----|:-----|\\n|MINIMAX_API_KEY| go get from [MiniMax Global](https://www.minimax.io/platform/user-center/basic-information/interface-key) | go get from [MiniMax](https://platform.minimaxi.com/user-center/basic-information/interface-key) |\\n|MINIMAX_API_HOST| https://api.minimaxi.chat (note the extra **\\\"i\\\"**) | https://api.minimax.chat |\\n\\n### 2. spawn uvx ENOENT\\nPlease confirm its absolute path by running this command in your terminal:\\n```sh\\nwhich uvx\\n```\\nOnce you obtain the absolute path (e.g., /usr/local/bin/uvx), update your configuration to use that path (e.g., \\\"command\\\": \\\"/usr/local/bin/uvx\\\"). \\n\\n### 3. How to use `generate_video` in async-mode\\nDefine completion rules before starting:\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_rule2.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\nAlternatively, these rules can be configured in your IDE settings (e.g., Cursor):\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/cursor_video_rule.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n\\n\\n## Example usage\\n\\n\u26a0\ufe0f Warning: Using these tools may incur costs.\\n\\n### 1. broadcast a segment of the evening news\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_20-07-53.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n\\n### 2. clone a voice\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-45-13.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n\\n### 3. generate a video\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-58-52.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/Snipaste_2025-04-09_19-59-43.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle; \\\"/\\u003e\\n\\n### 4. generate images\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle;\\\"/\\u003e\\n\\u003cimg src=\\\"https://public-cdn-video-data-algeng.oss-cn-wulanchabu.aliyuncs.com/gen_image1.png?x-oss-process=image/resize,p_50/format,webp\\\" style=\\\"display: inline-block; vertical-align: middle; \\\"/\\u003e63:T51f,## What is MiniMax MCP? \\nMiniMax MCP is an official server for the MiniMax Model Context Protocol that facilitates interaction with advanced Text to Speech and video/image generation APIs.\\n\\n## How to use MiniMax MCP?\"])</script><script>self.__next_f.push([1,\" \\nTo use MiniMax MCP, obtain your API key from MiniMax, install the required Python package manager `uv`, and configure your MCP client (like Claude Desktop or Cursor) to connect to the MiniMax server.\\n\\n## Key features of MiniMax MCP? \\n- Enables Text to Speech capabilities\\n- Supports video and image generation\\n- Allows voice cloning\\n- Integrates with various MCP clients like Claude Desktop and Cursor\\n\\n## Use cases of MiniMax MCP? \\n1. Broadcasting segments of news with generated speech.\\n2. Cloning voices for personalized audio content.\\n3. Generating videos for educational or entertainment purposes.\\n4. Creating images based on textual descriptions.\\n\\n## FAQ from MiniMax MCP? \\n- **What clients can use MiniMax MCP?**  \\n\\u003e MiniMax MCP can be used with clients like Claude Desktop, Cursor, and others that support MCP.\\n\\n- **Is there a cost associated with using MiniMax MCP?**  \\n\\u003e Yes, using these tools may incur costs depending on the API usage.\\n\\n- **How do I configure my client to use MiniMax MCP?**  \\n\\u003e Follow the setup instructions provided in the documentation for your specific client.64:T1ab5,[{\\\"name\\\":\\\"text_to_audio\\\",\\\"description\\\":\\\"Convert text to audio with a given voice and save the output audio file to a given directory. If no directory is provided, the file will be saved to desktop. If no voice ID is provided, the default voice will be used.\\\\n\\\\nNote: This tool calls MiniMax API and may incur costs. Use only when explicitly requested by the user.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"bitrate\\\":{\\\"default\\\":128000,\\\"description\\\":\\\"Bitrate (bps), values: [64000, 96000, 128000, 160000, 192000, 224000, 256000, 320000]\\\",\\\"type\\\":\\\"number\\\"},\\\"channel\\\":{\\\"default\\\":1,\\\"description\\\":\\\"Audio channels, values: [1, 2]\\\",\\\"type\\\":\\\"number\\\"},\\\"emotion\\\":{\\\"default\\\":\\\"happy\\\",\\\"description\\\":\\\"Speech emotion, values: [\\\\\\\"happy\\\\\\\", \\\\\\\"sad\\\\\\\", \\\\\\\"angry\\\\\\\", \\\\\\\"fearful\\\\\\\", \\\\\\\"disgusted\\\\\\\", \\\\\\\"surprised\\\\\\\", \\\\\\\"neutral\\\\\\\"]\\\",\\\"type\\\":\\\"string\\\"},\\\"format\\\":{\\\"default\\\":\\\"mp3\\\",\\\"description\\\":\\\"Audio format, values: [\\\\\\\"pcm\\\\\\\", \\\\\\\"mp3\\\\\\\",\\\\\\\"flac\\\\\\\", \\\\\\\"wav\\\\\\\"]\\\",\\\"type\\\":\\\"string\\\"},\\\"languageBoost\\\":{\\\"default\\\":\\\"auto\\\",\\\"description\\\":\\\"Language boost\\\",\\\"type\\\":\\\"string\\\"},\\\"model\\\":{\\\"default\\\":\\\"speech-02-hd\\\",\\\"description\\\":\\\"Model to use\\\",\\\"type\\\":\\\"string\\\"},\\\"outputDirectory\\\":{\\\"description\\\":\\\"Directory to save the output file\\\",\\\"type\\\":\\\"string\\\"},\\\"outputFile\\\":{\\\"description\\\":\\\"Path to save the generated audio file, automatically generated if not provided\\\",\\\"type\\\":\\\"string\\\"},\\\"pitch\\\":{\\\"default\\\":0,\\\"description\\\":\\\"Speech pitch\\\",\\\"maximum\\\":12,\\\"minimum\\\":-12,\\\"type\\\":\\\"number\\\"},\\\"sampleRate\\\":{\\\"default\\\":32000,\\\"description\\\":\\\"Sample rate (Hz), values: [8000, 16000, 22050, 24000, 32000, 44100]\\\",\\\"type\\\":\\\"number\\\"},\\\"speed\\\":{\\\"default\\\":1,\\\"description\\\":\\\"Speech speed\\\",\\\"maximum\\\":2,\\\"minimum\\\":0.5,\\\"type\\\":\\\"number\\\"},\\\"text\\\":{\\\"description\\\":\\\"Text to convert to audio\\\",\\\"type\\\":\\\"string\\\"},\\\"voiceId\\\":{\\\"default\\\":\\\"male-qn-qingse\\\",\\\"description\\\":\\\"Voice ID to use, e.g. \\\\\\\"female-shaonv\\\\\\\"\\\",\\\"type\\\":\\\"string\\\"},\\\"vol\\\":{\\\"default\\\":1,\\\"description\\\":\\\"Speech volume\\\",\\\"maximum\\\":10,\\\"minimum\\\":0.1,\\\"type\\\":\\\"number\\\"}},\\\"required\\\":[\\\"text\\\"]}},{\\\"name\\\":\\\"list_voices\\\",\\\"description\\\":\\\"List all available voices. Only supported when api_host is https://api.minimax.chat.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"voiceType\\\":{\\\"default\\\":\\\"all\\\",\\\"description\\\":\\\"Type of voices to list, values: [\\\\\\\"all\\\\\\\", \\\\\\\"system\\\\\\\", \\\\\\\"voice_cloning\\\\\\\"]\\\",\\\"type\\\":\\\"string\\\"}}}},{\\\"name\\\":\\\"play_audio\\\",\\\"description\\\":\\\"Play an audio file. Supports WAV and MP3 formats. Does not support video.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"inputFilePath\\\":{\\\"description\\\":\\\"Path to the audio file to play\\\",\\\"type\\\":\\\"string\\\"},\\\"isUrl\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Whether the audio file is a URL\\\",\\\"type\\\":\\\"boolean\\\"}},\\\"required\\\":[\\\"inputFilePath\\\"]}},{\\\"name\\\":\\\"voice_clone\\\",\\\"description\\\":\\\"Clone a voice using the provided audio file. New voices will incur costs when first used.\\\\n\\\\nNote: This tool calls MiniMax API and may incur costs. Use only when explicitly requested by the user.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"audioFile\\\":{\\\"description\\\":\\\"Path to the audio file\\\",\\\"type\\\":\\\"string\\\"},\\\"isUrl\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Whether the audio\"])</script><script>self.__next_f.push([1,\" file is a URL\\\",\\\"type\\\":\\\"boolean\\\"},\\\"outputDirectory\\\":{\\\"description\\\":\\\"Directory to save the output file\\\",\\\"type\\\":\\\"string\\\"},\\\"text\\\":{\\\"description\\\":\\\"Text for the demo audio\\\",\\\"type\\\":\\\"string\\\"},\\\"voiceId\\\":{\\\"description\\\":\\\"Voice ID to use\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"voiceId\\\",\\\"audioFile\\\"]}},{\\\"name\\\":\\\"text_to_image\\\",\\\"description\\\":\\\"Generate images based on text prompts.\\\\n\\\\nNote: This tool calls MiniMax API and may incur costs. Use only when explicitly requested by the user.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"aspectRatio\\\":{\\\"default\\\":\\\"1:1\\\",\\\"description\\\":\\\"Image aspect ratio, values: [\\\\\\\"1:1\\\\\\\", \\\\\\\"16:9\\\\\\\",\\\\\\\"4:3\\\\\\\", \\\\\\\"3:2\\\\\\\", \\\\\\\"2:3\\\\\\\", \\\\\\\"3:4\\\\\\\", \\\\\\\"9:16\\\\\\\", \\\\\\\"21:9\\\\\\\"]\\\",\\\"type\\\":\\\"string\\\"},\\\"model\\\":{\\\"default\\\":\\\"image-01\\\",\\\"description\\\":\\\"Model to use\\\",\\\"type\\\":\\\"string\\\"},\\\"n\\\":{\\\"default\\\":1,\\\"description\\\":\\\"Number of images to generate\\\",\\\"maximum\\\":9,\\\"minimum\\\":1,\\\"type\\\":\\\"number\\\"},\\\"outputDirectory\\\":{\\\"description\\\":\\\"Directory to save the output file\\\",\\\"type\\\":\\\"string\\\"},\\\"outputFile\\\":{\\\"description\\\":\\\"Path to save the generated image file, automatically generated if not provided\\\",\\\"type\\\":\\\"string\\\"},\\\"prompt\\\":{\\\"description\\\":\\\"Text prompt for image generation\\\",\\\"type\\\":\\\"string\\\"},\\\"promptOptimizer\\\":{\\\"default\\\":true,\\\"description\\\":\\\"Whether to optimize the prompt\\\",\\\"type\\\":\\\"boolean\\\"}},\\\"required\\\":[\\\"prompt\\\"]}},{\\\"name\\\":\\\"generate_video\\\",\\\"description\\\":\\\"Generate a video based on text prompts.\\\\n\\\\nNote: This tool calls MiniMax API and may incur costs. Use only when explicitly requested by the user.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"asyncMode\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result.\\\",\\\"type\\\":\\\"boolean\\\"},\\\"firstFrameImage\\\":{\\\"description\\\":\\\"First frame image\\\",\\\"type\\\":\\\"string\\\"},\\\"model\\\":{\\\"default\\\":\\\"T2V-01\\\",\\\"description\\\":\\\"Model to use, values: [\\\\\\\"T2V-01\\\\\\\", \\\\\\\"T2V-01-Director\\\\\\\", \\\\\\\"I2V-01\\\\\\\", \\\\\\\"I2V-01-Director\\\\\\\", \\\\\\\"I2V-01-live\\\\\\\"]\\\",\\\"type\\\":\\\"string\\\"},\\\"outputDirectory\\\":{\\\"description\\\":\\\"Directory to save the output file\\\",\\\"type\\\":\\\"string\\\"},\\\"outputFile\\\":{\\\"description\\\":\\\"Path to save the generated video file, automatically generated if not provided\\\",\\\"type\\\":\\\"string\\\"},\\\"prompt\\\":{\\\"description\\\":\\\"Text prompt for video generation\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"prompt\\\"]}},{\\\"name\\\":\\\"image_to_video\\\",\\\"description\\\":\\\"Generate a video based on an image.\\\\n\\\\nNote: This tool calls MiniMax API and may incur costs. Use only when explicitly requested by the user.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"asyncMode\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result.\\\",\\\"type\\\":\\\"boolean\\\"},\\\"firstFrameImage\\\":{\\\"description\\\":\\\"Path to the first frame image\\\",\\\"type\\\":\\\"string\\\"},\\\"model\\\":{\\\"default\\\":\\\"I2V-01\\\",\\\"description\\\":\\\"Model to use, values: [\\\\\\\"I2V-01\\\\\\\", \\\\\\\"I2V-01-Director\\\\\\\", \\\\\\\"I2V-01-live\\\\\\\"]\\\",\\\"type\\\":\\\"string\\\"},\\\"outputDirectory\\\":{\\\"description\\\":\\\"Directory to save the output file\\\",\\\"type\\\":\\\"string\\\"},\\\"outputFile\\\":{\\\"description\\\":\\\"Path to save the generated video file, automatically generated if not provided\\\",\\\"type\\\":\\\"string\\\"},\\\"prompt\\\":{\\\"description\\\":\\\"Text prompt for video generation\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"prompt\\\",\\\"firstFrameImage\\\"]}},{\\\"name\\\":\\\"query_video_generation\\\",\\\"description\\\":\\\"Query the status of a video generation task.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"outputDirectory\\\":{\\\"description\\\":\\\"The directory to save the video to\\\",\\\"type\\\":\\\"string\\\"},\\\"taskId\\\":{\\\"description\\\":\\\"The Task ID to query. Should be the task_id returned by `generate_video` tool if `async_mode` is True.\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"taskId\\\"]}}]65:T4fd,# mcp-server-flomo MCP Server\\n\\nwrite notes to Flomo.\\n\\nThis is a TypeScript-based MCP server help you write notes to Flomo.\\n\\n![preview](./preview.png)\\n\\n## Features\\n\\n### Tools\\n\\n- `write_note` - Write text notes to Flomo\\n  - Takes content as requ\"])</script><script>self.__next_f.push([1,\"ired parameters\\n\\n## Development\\n\\nInstall dependencies:\\n\\n```bash\\nnpm install\\n```\\n\\nBuild the server:\\n\\n```bash\\nnpm run build\\n```\\n\\nFor development with auto-rebuild:\\n\\n```bash\\nnpm run watch\\n```\\n\\n## Installation\\n\\nTo use with Claude Desktop, add the server config:\\n\\nOn MacOS: `~/Library/Application Support/Claude/claude_desktop_config.json`\\nOn Windows: `%APPDATA%/Claude/claude_desktop_config.json`\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-server-flomo\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"@chatmcp/mcp-server-flomo\\\"],\\n      \\\"env\\\": {\\n        \\\"FLOMO_API_URL\\\": \\\"https://flomoapp.com/iwh/xxx/xxx/\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nFind Your Flomo_API_URL [here](https://v.flomoapp.com/mine?source=incoming_webhook)\\n\\n### Debugging\\n\\nSince MCP servers communicate over stdio, debugging can be challenging. We recommend using the [MCP Inspector](https://github.com/modelcontextprotocol/inspector), which is available as a package script:\\n\\n```bash\\nnpm run inspector\\n```\\n\\nThe Inspector will provide a URL to access debugging tools in your browser.66:T4bd,## What is MCP Server Flomo? \\nMCP Server Flomo is a TypeScript-based server that allows users to write notes directly to Flomo, a note-taking application.\\n\\n## How to use MCP Server Flomo? \\nTo use MCP Server Flomo, you need to install the server and configure it with your Flomo API URL. You can run the server using the command line with the appropriate configurations.\\n\\n## Key features of MCP Server Flomo? \\n- Write text notes to Flomo using the `write_note` tool.\\n- Easy installation and configuration for different operating systems.\\n- Debugging support through MCP Inspector for easier troubleshooting.\\n\\n## Use cases of MCP Server Flomo? \\n1. Quickly jotting down notes from various applications to Flomo.\\n2. Automating note-taking processes for developers and researchers.\\n3. Integrating with other tools to enhance productivity.\\n\\n## FAQ from MCP Server Flomo? \\n- How do I find my Flomo API URL?  \\n\\u003e You can find your Flomo API URL by visiting [this link](https://v.flomoapp.com/mine?source=incoming_webhook).\\n\\n- Is MCP Server Flomo free to use?  \\n\\u003e Yes! MCP Server Flomo is free to use for everyone.\\n\\n- What programming language is MCP Server Flomo built with?  \\n\\u003e MCP Server Flomo is built using TypeScript.67:T711,# EverArt MCP Server\\r\\n\\r\\nImage generation server for Claude Desktop using EverArt's API.\\r\\n\\r\\n## Install\\r\\n```bash\\r\\nnpm install\\r\\nexport EVERART_API_KEY=your_key_here\\r\\n```\\r\\n\\r\\n## Config\\r\\nAdd to Claude Desktop config:\\r\\n\\r\\n### Docker\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"everart\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"-e\\\", \\\"EVERART_API_KEY\\\", \\\"mcp/everart\\\"],\\r\\n      \\\"env\\\": {\\r\\n        \\\"EVERART_API_KEY\\\": \\\"your_key_here\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"everart\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\\"-y\\\", \\\"@modelcontextprotocol/server-everart\\\"],\\r\\n      \\\"env\\\": {\\r\\n        \\\"EVERART_API_KEY\\\": \\\"your_key_here\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Tools\\r\\n\\r\\n### generate_image\\r\\nGenerates images with multiple model options. Opens result in browser and returns URL.\\r\\n\\r\\nParameters:\\r\\n```typescript\\r\\n{\\r\\n  prompt: string,       // Image description\\r\\n  model?: string,       // Model ID (default: \\\"207910310772879360\\\")\\r\\n  image_count?: number  // Number of images (default: 1)\\r\\n}\\r\\n```\\r\\n\\r\\nModels:\\r\\n- 5000: FLUX1.1 (standard)\\r\\n- 9000: FLUX1.1-ultra\\r\\n- 6000: SD3.5\\r\\n- 7000: Recraft-Real\\r\\n- 8000: Recraft-Vector\\r\\n\\r\\nAll images generated at 1024x1024.\\r\\n\\r\\nSample usage:\\r\\n```javascript\\r\\nconst result = await client.callTool({\\r\\n  name: \\\"generate_image\\\",\\r\\n  arguments: {\\r\\n    prompt: \\\"A cat sitting elegantly\\\",\\r\\n    model: \\\"7000\\\",\\r\\n    image_count: 1\\r\\n  }\\r\\n});\\r\\n```\\r\\n\\r\\nResponse format:\\r\\n```\\r\\nImage generated successfully!\\r\\nThe image has been opened in your default browser.\\r\\n\\r\\nGeneration details:\\r\\n- Model: 7000\\r\\n- Prompt: \\\"A cat sitting elegantly\\\"\\r\\n- Image URL: https://storage.googleapis.com/...\\r\\n\\r\\nYou can also click the URL above to view the image again.\\r\\n```\\r\\n\\r\\n## Building w/ Docker\\r\\n\\r\\n```sh\\r\\ndocker build -t mcp/everart -f src/everart/Dockerfile . \\r\\n```68:T4c3,## What is EverA\"])</script><script>self.__next_f.push([1,\"rt? \\nEverArt is an AI image generation tool that allows users to create images using various models through an API. \\n\\n## How to use EverArt? \\nTo use EverArt, install the necessary dependencies, set up your API key, and configure Claude Desktop to utilize EverArt for image generation. Use the provided commands to generate images based on prompts. \\n\\n## Key features of EverArt? \\n- Generates images using multiple AI models \\n- Returns generated image URLs for easy access \\n- Configurable image generation parameters (prompt, model, image count) \\n\\n## Use cases of EverArt? \\n1. Creating unique art pieces based on descriptive prompts \\n2. Generating visual content for marketing and social media \\n3. Prototyping design concepts using AI-generated visuals \\n\\n## FAQ from EverArt? \\n- What image models does EverArt support? \\n\\u003e EverArt supports multiple models such as FLUX1.1, SD3.5, and Recraft, offering various styles and qualities. \\n\\n- Can I customize the number of images generated? \\n\\u003e Yes! You can specify the number of images you want in your requests. \\n\\n- Is there a limitation on the image prompt length? \\n\\u003e The prompt can be of reasonable length, but it's best to keep it concise for optimal results.69:Te9c,# Perplexity Ask MCP Server\\r\\n\\r\\nAn MCP server implementation that integrates the Sonar API to provide Claude with unparalleled real-time, web-wide research.\\r\\n\\r\\n![Demo](perplexity-ask/assets/demo_screenshot.png)\\r\\n\\r\\n\\r\\n## Tools\\r\\n\\r\\n- **perplexity_ask**\\r\\n  - Engage in a conversation with the Sonar API for live web searches.\\r\\n  - **Inputs:**\\r\\n    - `messages` (array): An array of conversation messages.\\r\\n      - Each message must include:\\r\\n        - `role` (string): The role of the message (e.g., `system`, `user`, `assistant`).\\r\\n        - `content` (string): The content of the message.\\r\\n\\r\\n## Configuration\\r\\n\\r\\n### Step 1: \\r\\n\\r\\nClone the MCP repository:\\r\\n\\r\\n```bash\\r\\ngit@github.com:modelcontextprotocol/servers.git\\r\\n```\\r\\n\\r\\nNavigate to the `perplexity-ask` directory and install the necessary dependencies:\\r\\n\\r\\n```bash\\r\\ncd servers/src/perplexity-ask \\u0026\\u0026 npm install\\r\\n```\\r\\n\\r\\n### Step 2: Get a Sonar API Key\\r\\n\\r\\n1. Sign up for a [Sonar API account](https://docs.perplexity.ai/guides/getting-started).\\r\\n2. Follow the account setup instructions and generate your API key from the developer dashboard.\\r\\n3. Set the API key in your environment as `PERPLEXITY_API_KEY`.\\r\\n\\r\\n### Step 3: Configure Claude Desktop\\r\\n\\r\\n1. Download Claude desktop [here](https://claude.ai/download). \\r\\n\\r\\n2. Add this to your `claude_desktop_config.json`:\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"perplexity-ask\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"run\\\",\\r\\n        \\\"-i\\\",\\r\\n        \\\"--rm\\\",\\r\\n        \\\"-e\\\",\\r\\n        \\\"PERPLEXITY_API_KEY\\\",\\r\\n        \\\"mcp/perplexity-ask\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"PERPLEXITY_API_KEY\\\": \\\"YOUR_API_KEY_HERE\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"perplexity-ask\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-perplexity-ask\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"PERPLEXITY_API_KEY\\\": \\\"YOUR_API_KEY_HERE\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nYou can access the file using:\\r\\n\\r\\n```bash\\r\\nvim ~/Library/Application\\\\ Support/Claude/claude_desktop_config.json\\r\\n```\\r\\n\\r\\n### Step 4: Build the Docker Image\\r\\n\\r\\nDocker build:\\r\\n\\r\\n```bash\\r\\ndocker build -t mcp/perplexity-ask:latest -f src/perplexity-ask/Dockerfile .\\r\\n```\\r\\n\\r\\n### Step 5: Testing\\r\\n\\r\\nLet\u2019s make sure Claude for Desktop is picking up the two tools we\u2019ve exposed in our `perplexity-ask` server. You can do this by looking for the hammer icon:\\r\\n\\r\\n![Claude Visual Tools](perplexity-ask/assets/visual-indicator-mcp-tools.png)\\r\\n\\r\\nAfter clicking on the hammer icon, you should see the tools that come with the Filesystem MCP Server:\\r\\n\\r\\n![Available Integration](perplexity-ask/assets/available_tools.png)\\r\\n\\r\\nIf you see both of these this means that the integration is active. Congratulations! This means Claude can now ask Perplexity. You can then simply use it as you would use the Perplexity web app.  \\r\\n\\r\\n### Step 6: Advanced parameters\\r\\n\\r\\nCu\"])</script><script>self.__next_f.push([1,\"rrently, the search parameters used are the default ones. You can modify any search parameter in the API call directly in the `index.ts` script. For this, please refer to the official [API documentation](https://docs.perplexity.ai/api-reference/chat-completions).\\r\\n\\r\\n### Troubleshooting \\r\\n\\r\\nThe Claude documentation provides an excellent [troubleshooting guide](https://modelcontextprotocol.io/docs/tools/debugging) you can refer to. However, you can still reach out to us at api@perplexity.ai for any additional support or [file a bug](https://github.com/ppl-ai/api-discussion/issues). \\r\\n\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.6a:T519,## what is Perplexity Ask MCP Server? \\nPerplexity Ask MCP Server is a Model Context Protocol Server connector for the Perplexity API, enabling web search capabilities within the MCP ecosystem.\\n\\n## how to use Perplexity Ask MCP Server? \\nTo use the server, clone the MCP repository, install dependencies, obtain a Sonar API key, configure the Claude desktop, build the Docker image, and test the integration.\\n\\n## key features of Perplexity Ask MCP Server? \\n- Real-time web search integration with the Sonar API.\\n- Easy configuration and setup for users.\\n- Support for advanced search parameters.\\n\\n## use cases of Perplexity Ask MCP Server? \\n1. Conducting live web searches without leaving the MCP environment.\\n2. Enhancing research capabilities for users of the Claude desktop.\\n3. Integrating web search functionalities into applications using the Perplexity API.\\n\\n## FAQ from Perplexity Ask MCP Server? \\n- How do I get a Sonar API key?  \\n\\u003e Sign up for a Sonar API account and generate your API key from the developer dashboard.\\n\\n- Is there a troubleshooting guide available?  \\n\\u003e Yes, the Claude documentation provides a troubleshooting guide for common issues.\\n\\n- What license is the MCP server under?  \\n\\u003e The MCP server is licensed under the MIT License, allowing free use, modification, and distribution.6b:T70e,[{\\\"name\\\":\\\"perplexity_ask\\\",\\\"description\\\":\\\"Engages in a conversation using the Sonar API. Accepts an array of messages (each with a role and content) and returns a ask completion response from the Perplexity model.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"messages\\\":{\\\"description\\\":\\\"Array of conversation messages\\\",\\\"items\\\":{\\\"properties\\\":{\\\"content\\\":{\\\"description\\\":\\\"The content of the message\\\",\\\"type\\\":\\\"string\\\"},\\\"role\\\":{\\\"description\\\":\\\"Role of the message (e.g., system, user, assistant)\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"role\\\",\\\"content\\\"],\\\"type\\\":\\\"object\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"messages\\\"]}},{\\\"name\\\":\\\"perplexity_research\\\",\\\"description\\\":\\\"Performs deep research using the Perplexity API. Accepts an array of messages (each with a role and content) and returns a comprehensive research response with citations.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"messages\\\":{\\\"description\\\":\\\"Array of conversation messages\\\",\\\"items\\\":{\\\"properties\\\":{\\\"content\\\":{\\\"description\\\":\\\"The content of the message\\\",\\\"type\\\":\\\"string\\\"},\\\"role\\\":{\\\"description\\\":\\\"Role of the message (e.g., system, user, assistant)\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"role\\\",\\\"content\\\"],\\\"type\\\":\\\"object\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"messages\\\"]}},{\\\"name\\\":\\\"perplexity_reason\\\",\\\"description\\\":\\\"Performs reasoning tasks using the Perplexity API. Accepts an array of messages (each with a role and content) and returns a well-reasoned response using the sonar-reasoning-pro model.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"messages\\\":{\\\"description\\\":\\\"Array of conversation messages\\\",\\\"items\\\":{\\\"properties\\\":{\\\"content\\\":{\\\"description\\\":\\\"The content of the message\\\",\\\"type\\\":\\\"string\\\"},\\\"role\\\":{\\\"description\\\":\\\"Role of the message (e.g., system, user, assistant)\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"role\\\",\\\"content\\\"],\\\"type\\\":\\\"object\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"messages\\\"]}}]6c:T58b,## What is Amap Maps? \\nAmap Maps is a server that supports any MCP protocol client, allowing users to easi\"])</script><script>self.__next_f.push([1,\"ly utilize the Amap Maps MCP server for various location-based services.\\n\\n## How to use Amap Maps? \\nTo use Amap Maps, configure it in a compatible client like Cursor by copying your API key and setting up the server command as specified in the documentation.\\n\\n## Key features of Amap Maps? \\n- Supports multiple location services including geocoding, weather, and distance measurement.\\n- Provides APIs for various transportation modes including walking, driving, and public transit.\\n- Allows for detailed searches of points of interest (POIs) based on keywords or location.\\n\\n## Use cases of Amap Maps? \\n1. Converting geographic coordinates to administrative addresses.\\n2. Planning routes for cycling, walking, or driving.\\n3. Searching for nearby points of interest based on user-defined criteria.\\n\\n## FAQ from Amap Maps? \\n- What types of location services does Amap Maps provide?  \\n\\u003e Amap Maps provides geocoding, weather information, distance measurement, and route planning for various transportation modes.\\n\\n- Is there a limit to the number of requests I can make?  \\n\\u003e The usage limits depend on the API key and the specific service being used. Please refer to the Amap documentation for details.\\n\\n- How do I obtain an API key?  \\n\\u003e You can obtain an API key by creating a project on the Amap developer platform.6d:T1363,[{\\\"name\\\":\\\"maps_regeocode\\\",\\\"description\\\":\\\"\u5c06\u4e00\u4e2a\u9ad8\u5fb7\u7ecf\u7eac\u5ea6\u5750\u6807\u8f6c\u6362\u4e3a\u884c\u653f\u533a\u5212\u5730\u5740\u4fe1\u606f\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"location\\\":{\\\"description\\\":\\\"\u7ecf\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"location\\\"]}},{\\\"name\\\":\\\"maps_geo\\\",\\\"description\\\":\\\"\u5c06\u8be6\u7ec6\u7684\u7ed3\u6784\u5316\u5730\u5740\u8f6c\u6362\u4e3a\u7ecf\u7eac\u5ea6\u5750\u6807\u3002\u652f\u6301\u5bf9\u5730\u6807\u6027\u540d\u80dc\u666f\u533a\u3001\u5efa\u7b51\u7269\u540d\u79f0\u89e3\u6790\u4e3a\u7ecf\u7eac\u5ea6\u5750\u6807\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"address\\\":{\\\"description\\\":\\\"\u5f85\u89e3\u6790\u7684\u7ed3\u6784\u5316\u5730\u5740\u4fe1\u606f\\\",\\\"type\\\":\\\"string\\\"},\\\"city\\\":{\\\"description\\\":\\\"\u6307\u5b9a\u67e5\u8be2\u7684\u57ce\u5e02\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"address\\\"]}},{\\\"name\\\":\\\"maps_ip_location\\\",\\\"description\\\":\\\"IP \u5b9a\u4f4d\u6839\u636e\u7528\u6237\u8f93\u5165\u7684 IP \u5730\u5740\uff0c\u5b9a\u4f4d IP \u7684\u6240\u5728\u4f4d\u7f6e\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"ip\\\":{\\\"description\\\":\\\"IP\u5730\u5740\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"ip\\\"]}},{\\\"name\\\":\\\"maps_weather\\\",\\\"description\\\":\\\"\u6839\u636e\u57ce\u5e02\u540d\u79f0\u6216\u8005\u6807\u51c6adcode\u67e5\u8be2\u6307\u5b9a\u57ce\u5e02\u7684\u5929\u6c14\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"city\\\":{\\\"description\\\":\\\"\u57ce\u5e02\u540d\u79f0\u6216\u8005adcode\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"city\\\"]}},{\\\"name\\\":\\\"maps_search_detail\\\",\\\"description\\\":\\\"\u67e5\u8be2\u5173\u952e\u8bcd\u641c\u6216\u8005\u5468\u8fb9\u641c\u83b7\u53d6\u5230\u7684POI ID\u7684\u8be6\u7ec6\u4fe1\u606f\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"id\\\":{\\\"description\\\":\\\"\u5173\u952e\u8bcd\u641c\u6216\u8005\u5468\u8fb9\u641c\u83b7\u53d6\u5230\u7684POI ID\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"id\\\"]}},{\\\"name\\\":\\\"maps_bicycling\\\",\\\"description\\\":\\\"\u9a91\u884c\u8def\u5f84\u89c4\u5212\u7528\u4e8e\u89c4\u5212\u9a91\u884c\u901a\u52e4\u65b9\u6848\uff0c\u89c4\u5212\u65f6\u4f1a\u8003\u8651\u5929\u6865\u3001\u5355\u884c\u7ebf\u3001\u5c01\u8def\u7b49\u60c5\u51b5\u3002\u6700\u5927\u652f\u6301 500km \u7684\u9a91\u884c\u8def\u7ebf\u89c4\u5212\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"destination\\\":{\\\"description\\\":\\\"\u76ee\u7684\u5730\u7ecf\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"origin\\\":{\\\"description\\\":\\\"\u51fa\u53d1\u70b9\u7ecf\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"origin\\\",\\\"destination\\\"]}},{\\\"name\\\":\\\"maps_direction_walking\\\",\\\"description\\\":\\\"\u6b65\u884c\u8def\u5f84\u89c4\u5212 API \u53ef\u4ee5\u6839\u636e\u8f93\u5165\u8d77\u70b9\u7ec8\u70b9\u7ecf\u7eac\u5ea6\u5750\u6807\u89c4\u5212100km \u4ee5\u5185\u7684\u6b65\u884c\u901a\u52e4\u65b9\u6848\uff0c\u5e76\u4e14\u8fd4\u56de\u901a\u52e4\u65b9\u6848\u7684\u6570\u636e\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"destination\\\":{\\\"description\\\":\\\"\u76ee\u7684\u5730\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"origin\\\":{\\\"description\\\":\\\"\u51fa\u53d1\u70b9\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"origin\\\",\\\"destination\\\"]}},{\\\"name\\\":\\\"maps_direction_driving\\\",\\\"description\\\":\\\"\u9a7e\u8f66\u8def\u5f84\u89c4\u5212 API \u53ef\u4ee5\u6839\u636e\u7528\u6237\u8d77\u7ec8\u70b9\u7ecf\u7eac\u5ea6\u5750\u6807\u89c4\u5212\u4ee5\u5c0f\u5ba2\u8f66\u3001\u8f7f\u8f66\u901a\u52e4\u51fa\u884c\u7684\u65b9\u6848\uff0c\u5e76\u4e14\u8fd4\u56de\u901a\u52e4\u65b9\u6848\u7684\u6570\u636e\u3002\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"destination\\\":{\\\"description\\\":\\\"\u76ee\u7684\u5730\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"origin\\\":{\\\"description\\\":\\\"\u51fa\u53d1\u70b9\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"or\"])</script><script>self.__next_f.push([1,\"igin\\\",\\\"destination\\\"]}},{\\\"name\\\":\\\"maps_direction_transit_integrated\\\",\\\"description\\\":\\\"\u516c\u4ea4\u8def\u5f84\u89c4\u5212 API \u53ef\u4ee5\u6839\u636e\u7528\u6237\u8d77\u7ec8\u70b9\u7ecf\u7eac\u5ea6\u5750\u6807\u89c4\u5212\u7efc\u5408\u5404\u7c7b\u516c\u5171\uff08\u706b\u8f66\u3001\u516c\u4ea4\u3001\u5730\u94c1\uff09\u4ea4\u901a\u65b9\u5f0f\u7684\u901a\u52e4\u65b9\u6848\uff0c\u5e76\u4e14\u8fd4\u56de\u901a\u52e4\u65b9\u6848\u7684\u6570\u636e\uff0c\u8de8\u57ce\u573a\u666f\u4e0b\u5fc5\u987b\u4f20\u8d77\u70b9\u57ce\u5e02\u4e0e\u7ec8\u70b9\u57ce\u5e02\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"city\\\":{\\\"description\\\":\\\"\u516c\u5171\u4ea4\u901a\u89c4\u5212\u8d77\u70b9\u57ce\u5e02\\\",\\\"type\\\":\\\"string\\\"},\\\"cityd\\\":{\\\"description\\\":\\\"\u516c\u5171\u4ea4\u901a\u89c4\u5212\u7ec8\u70b9\u57ce\u5e02\\\",\\\"type\\\":\\\"string\\\"},\\\"destination\\\":{\\\"description\\\":\\\"\u76ee\u7684\u5730\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"origin\\\":{\\\"description\\\":\\\"\u51fa\u53d1\u70b9\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"origin\\\",\\\"destination\\\",\\\"city\\\",\\\"cityd\\\"]}},{\\\"name\\\":\\\"maps_distance\\\",\\\"description\\\":\\\"\u8ddd\u79bb\u6d4b\u91cf API \u53ef\u4ee5\u6d4b\u91cf\u4e24\u4e2a\u7ecf\u7eac\u5ea6\u5750\u6807\u4e4b\u95f4\u7684\u8ddd\u79bb,\u652f\u6301\u9a7e\u8f66\u3001\u6b65\u884c\u4ee5\u53ca\u7403\u9762\u8ddd\u79bb\u6d4b\u91cf\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"destination\\\":{\\\"description\\\":\\\"\u7ec8\u70b9\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"origins\\\":{\\\"description\\\":\\\"\u8d77\u70b9\u7ecf\u5ea6\uff0c\u7eac\u5ea6\uff0c\u53ef\u4ee5\u4f20\u591a\u4e2a\u5750\u6807\uff0c\u4f7f\u7528\u5206\u53f7\u9694\u79bb\uff0c\u6bd4\u5982120,30;120,31\uff0c\u5750\u6807\u683c\u5f0f\u4e3a\uff1a\u7ecf\u5ea6\uff0c\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"type\\\":{\\\"description\\\":\\\"\u8ddd\u79bb\u6d4b\u91cf\u7c7b\u578b,1\u4ee3\u8868\u9a7e\u8f66\u8ddd\u79bb\u6d4b\u91cf\uff0c0\u4ee3\u8868\u76f4\u7ebf\u8ddd\u79bb\u6d4b\u91cf\uff0c3\u6b65\u884c\u8ddd\u79bb\u6d4b\u91cf\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"origins\\\",\\\"destination\\\"]}},{\\\"name\\\":\\\"maps_text_search\\\",\\\"description\\\":\\\"\u5173\u952e\u8bcd\u641c\uff0c\u6839\u636e\u7528\u6237\u4f20\u5165\u5173\u952e\u8bcd\uff0c\u641c\u7d22\u51fa\u76f8\u5173\u7684POI\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"city\\\":{\\\"description\\\":\\\"\u67e5\u8be2\u57ce\u5e02\\\",\\\"type\\\":\\\"string\\\"},\\\"keywords\\\":{\\\"description\\\":\\\"\u641c\u7d22\u5173\u952e\u8bcd\\\",\\\"type\\\":\\\"string\\\"},\\\"types\\\":{\\\"description\\\":\\\"POI\u7c7b\u578b\uff0c\u6bd4\u5982\u52a0\u6cb9\u7ad9\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"keywords\\\"]}},{\\\"name\\\":\\\"maps_around_search\\\",\\\"description\\\":\\\"\u5468\u8fb9\u641c\uff0c\u6839\u636e\u7528\u6237\u4f20\u5165\u5173\u952e\u8bcd\u4ee5\u53ca\u5750\u6807location\uff0c\u641c\u7d22\u51faradius\u534a\u5f84\u8303\u56f4\u7684POI\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"keywords\\\":{\\\"description\\\":\\\"\u641c\u7d22\u5173\u952e\u8bcd\\\",\\\"type\\\":\\\"string\\\"},\\\"location\\\":{\\\"description\\\":\\\"\u4e2d\u5fc3\u70b9\u7ecf\u5ea6\u7eac\u5ea6\\\",\\\"type\\\":\\\"string\\\"},\\\"radius\\\":{\\\"description\\\":\\\"\u641c\u7d22\u534a\u5f84\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"location\\\"]}}]6e:T2770,# Search1API MCP Server\\r\\n\\r\\n[\u4e2d\u6587\u6587\u6863](./README_zh.md)\\r\\n\\r\\nA Model Context Protocol (MCP) server that provides search and crawl functionality using Search1API.\\r\\n\\r\\n## Prerequisites\\r\\n\\r\\n- Node.js \\u003e= 18.0.0\\r\\n- A valid Search1API API key (See **Setup Guide** below on how to obtain and configure)\\r\\n\\r\\n## Installation (Standalone / General)\\r\\n\\r\\n1.  **Clone the repository:**\\r\\n    ```bash\\r\\n    git clone https://github.com/fatwang2/search1api-mcp.git\\r\\n    cd search1api-mcp\\r\\n    ```\\r\\n\\r\\n2.  **Configure API Key:** Before building, you need to provide your Search1API key. See the **Setup Guide** section below for different methods (e.g., using a `.env` file or environment variables).\\r\\n\\r\\n3.  **Install dependencies and build:**\\r\\n    ```bash\\r\\n    npm install\\r\\n    npm run build\\r\\n    ```\\r\\n    *Note: If using the project's `.env` file method for the API key, ensure it exists before this step.*\\r\\n\\r\\n## Usage (Standalone / General)\\r\\n\\r\\nEnsure your API key is configured (see **Setup Guide**).\\r\\n\\r\\nStart the server:\\r\\n```bash\\r\\nnpm start\\r\\n```\\r\\n\\r\\nThe server will then be ready to accept connections from MCP clients.\\r\\n\\r\\n## Setup Guide\\r\\n\\r\\n### 1. Get Search1API Key\\r\\n\\r\\n1.  Register at [Search1API](https://www.search1api.com/?utm_source=mcp)\\r\\n2.  Get your API key from your dashboard.\\r\\n\\r\\n### 2. Configure API Key\\r\\n\\r\\nYou need to make your API key available to the server. Choose **one** of the following methods:\\r\\n\\r\\n**Method A: Project `.env` File (Recommended for Standalone or LibreChat)**\\r\\n\\r\\nThis method is required if integrating with the current version of LibreChat (see specific section below).\\r\\n\\r\\n1.  In the `search1api-mcp` project root directory, create a file named `.env`:\\r\\n    ```bash\\r\\n    # In the search1api-mcp directory\\r\\n    echo \\\"SEARCH1API_KEY=your_api_key_here\\\" \\u003e .env\\r\\n    ```\\r\\n2.  Replace `your_api_key_here` with your actual key.\\r\\n3.  Make sure this file exists **before** running `npm install \\u0026\"])</script><script>self.__next_f.push([1,\"\\u0026 npm run build`.\\r\\n\\r\\n**Method B: Environment Variable (Standalone Only)**\\r\\n\\r\\nSet the `SEARCH1API_KEY` environment variable before starting the server.\\r\\n\\r\\n```bash\\r\\nexport SEARCH1API_KEY=\\\"your_api_key_here\\\"\\r\\nnpm start\\r\\n```\\r\\n\\r\\n**Method C: MCP Client Configuration (Advanced)**\\r\\n\\r\\nSome MCP clients allow specifying environment variables directly in their configuration. This is useful for clients like Cursor, VS Code extensions, etc.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"search1api\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"search1api-mcp\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"SEARCH1API_KEY\\\": \\\"YOUR_SEARCH1API_KEY\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n**Note for LibreChat Users:** Due to current limitations in LibreChat, Method A (Project `.env` File) is the **required** method. See the dedicated integration section below for full instructions.\\r\\n\\r\\n## Integration with LibreChat (Docker)\\r\\n\\r\\nThis section details the required steps for integrating with LibreChat via Docker.\\r\\n\\r\\n**Overview:**\\r\\n\\r\\n1.  Clone this server's repository into a location accessible by your LibreChat `docker-compose.yml`.\\r\\n2.  Configure the required API key using the **Project `.env` File method** within this server's directory.\\r\\n3.  Build this server.\\r\\n4.  Tell LibreChat how to run this server by editing `librechat.yaml`.\\r\\n5.  Make sure the built server code is available inside the LibreChat container via a Docker volume bind.\\r\\n6.  Restart LibreChat.\\r\\n\\r\\n**Step-by-Step:**\\r\\n\\r\\n1.  **Clone the Repository:**\\r\\n    Navigate to the directory on your host machine where you manage external services for LibreChat (this is often alongside your `docker-compose.yml`). A common location is a dedicated `mcp-server` directory.\\r\\n    ```bash\\r\\n    # Example: Navigate to where docker-compose.yml lives, then into mcp-server\\r\\n    cd /path/to/your/librechat/setup/mcp-server\\r\\n    git clone https://github.com/fatwang2/search1api-mcp.git\\r\\n    ```\\r\\n\\r\\n2.  **Navigate into the Server Directory:**\\r\\n    ```bash\\r\\n    cd search1api-mcp\\r\\n    ```\\r\\n\\r\\n3.  **Configure API Key (Project `.env` File Method - Required for LibreChat):**\\r\\n    ```bash\\r\\n    # Create the .env file\\r\\n    echo \\\"SEARCH1API_KEY=your_api_key_here\\\" \\u003e .env\\r\\n    # IMPORTANT: Replace 'your_api_key_here' with your actual Search1API key\\r\\n    ```\\r\\n\\r\\n4.  **Install Dependencies and Build:**\\r\\n    This step compiles the server code into the `build` directory.\\r\\n    ```bash\\r\\n    npm install\\r\\n    npm run build\\r\\n    ```\\r\\n\\r\\n5.  **Configure `librechat.yaml`:**\\r\\n    Edit your main `librechat.yaml` file to tell LibreChat how to execute this MCP server. Add an entry under `mcp_servers`:\\r\\n    ```yaml\\r\\n    # In your main librechat.yaml\\r\\n    mcp_servers:\\r\\n      # You can add other MCP servers here too\\r\\n      search1api:\\r\\n        # Optional: Display name for the server in LibreChat UI\\r\\n        # name: Search1API Tools\\r\\n\\r\\n        # Command tells LibreChat to use 'node'\\r\\n        command: node\\r\\n\\r\\n        # Args specify the script for 'node' to run *inside the container*\\r\\n        args:\\r\\n          - /app/mcp-server/search1api-mcp/build/index.js\\r\\n    ```\\r\\n    *   The `args` path (`/app/...`) is the location *inside* the LibreChat API container where the built server will be accessed (thanks to the volume bind in the next step).\\r\\n\\r\\n6.  **Configure Docker Volume Bind:**\\r\\n    Edit your `docker-compose.yml` (or more likely, your `docker-compose.override.yml`) to map the `search1api-mcp` directory from your host machine into the LibreChat API container. Find the `volumes:` section for the `api:` service:\\r\\n    ```yaml\\r\\n    # In your docker-compose.yml or docker-compose.override.yml\\r\\n    services:\\r\\n      api:\\r\\n        # ... other service config ...\\r\\n        volumes:\\r\\n          # ... other volumes likely exist here ...\\r\\n\\r\\n          # Add this volume bind:\\r\\n          - ./mcp-server/search1api-mcp:/app/mcp-server/search1api-mcp\\r\\n    ```\\r\\n    *   **Host Path (`./mcp-server/search1api-mcp`):** This is the path on your host machine *relative* to where your `docker-compose.yml` file is located. Adjust it if you cloned the repo elsewhere.\\r\\n    *   **Co\"])</script><script>self.__next_f.push([1,\"ntainer Path (`:/app/mcp-server/search1api-mcp`):** This is the path *inside* the container. It **must match** the directory structure used in the `librechat.yaml` `args` path.\\r\\n\\r\\n7.  **Restart LibreChat:**\\r\\n    Apply the changes by rebuilding (if you modified `docker-compose.yml`) and restarting your LibreChat stack.\\r\\n    ```bash\\r\\n    docker compose down \\u0026\\u0026 docker compose up -d --build\\r\\n    # Or: docker compose restart api (if only librechat.yaml changed)\\r\\n    ```\\r\\n\\r\\nNow, the Search1API server should be available as a tool provider within LibreChat.\\r\\n\\r\\n## Features\\r\\n\\r\\n- Web search functionality\\r\\n- News search functionality\\r\\n- Web page content extraction\\r\\n- Website sitemap extraction\\r\\n- Deep thinking and complex problem solving with DeepSeek R1\\r\\n- Seamless integration with Claude Desktop, Cursor, Windsurf, Cline and other MCP clients\\r\\n\\r\\n## Tools\\r\\n\\r\\n### 1. Search Tool\\r\\n- Name: `search`\\r\\n- Description: Search the web using Search1API\\r\\n- Parameters:\\r\\n  * `query` (required): Search query in natural language. Be specific and concise for better results\\r\\n  * `max_results` (optional, default: 10): Number of results to return\\r\\n  * `search_service` (optional, default: \\\"google\\\"): Search service to use (google, bing, duckduckgo, yahoo, x, reddit, github, youtube, arxiv, wechat, bilibili, imdb, wikipedia)\\r\\n  * `crawl_results` (optional, default: 0): Number of results to crawl for full webpage content\\r\\n  * `include_sites` (optional): List of sites to include in search\\r\\n  * `exclude_sites` (optional): List of sites to exclude from search\\r\\n  * `time_range` (optional): Time range for search results (\\\"day\\\", \\\"month\\\", \\\"year\\\")\\r\\n\\r\\n### 2. News Tool\\r\\n- Name: `news`\\r\\n- Description: Search for news articles using Search1API\\r\\n- Parameters:\\r\\n  * `query` (required): Search query in natural language. Be specific and concise for better results\\r\\n  * `max_results` (optional, default: 10): Number of results to return\\r\\n  * `search_service` (optional, default: \\\"bing\\\"): Search service to use (google, bing, duckduckgo, yahoo, hackernews)\\r\\n  * `crawl_results` (optional, default: 0): Number of results to crawl for full webpage content\\r\\n  * `include_sites` (optional): List of sites to include in search\\r\\n  * `exclude_sites` (optional): List of sites to exclude from search\\r\\n  * `time_range` (optional): Time range for search results (\\\"day\\\", \\\"month\\\", \\\"year\\\")\\r\\n\\r\\n### 3. Crawl Tool\\r\\n- Name: `crawl`\\r\\n- Description: Extract content from a URL using Search1API\\r\\n- Parameters:\\r\\n  * `url` (required): URL to crawl\\r\\n\\r\\n### 4. Sitemap Tool\\r\\n- Name: `sitemap`\\r\\n- Description: Get all related links from a URL\\r\\n- Parameters:\\r\\n  * `url` (required): URL to get sitemap\\r\\n\\r\\n### 5. Reasoning Tool\\r\\n- Name: `reasoning`\\r\\n- Description: A tool for deep thinking and complex problem solving with fast deepseek r1 model and web search ability(You can change to any other model in search1api website but the speed is not guaranteed)\\r\\n- Parameters:\\r\\n  * `content` (required): The question or problem that needs deep thinking\\r\\n\\r\\n### 6. Trending Tool\\r\\n- Name: `trending`\\r\\n- Description: Get trending topics from popular platforms\\r\\n- Parameters:\\r\\n  * `search_service` (required): Specify the platform to get trending topics from (github, hackernews)\\r\\n  * `max_results` (optional, default: 10): Maximum number of trending items to return\\r\\n\\r\\n## Version History\\r\\n\\r\\n- v0.2.0: Added fallback `.env` support for LibreChat integration and updated dependencies.\\r\\n- v0.1.8: Added X(Twitter) and Reddit search services\\r\\n- v0.1.7: Added Trending tool for GitHub and Hacker News\\r\\n- v0.1.6: Added Wikipedia search service\\r\\n- v0.1.5: Added new search parameters (include_sites, exclude_sites, time_range) and new search services (arxiv, wechat, bilibili, imdb)\\r\\n- v0.1.4: Added reasoning tool with deepseek r1 and updated the Cursor and Windsurf configuration guide\\r\\n- v0.1.3: Added news search functionality\\r\\n- v0.1.2: Added sitemap functionality\\r\\n- v0.1.1: Added web crawling functionality\\r\\n- v0.1.0: Initial release with search functionality\\r\\n\\r\\n## License\\r\\n\\r\\nThis project is licensed under the MIT License - see the LICENSE file for deta\"])</script><script>self.__next_f.push([1,\"ils.\\r\\n6f:T577,## what is Search1API? \\nSearch1API is an API that provides integrated functionalities for web search, crawling, and sitemap extraction.\\n\\n## how to use Search1API? \\nTo use Search1API, first register on the website to get your API key. Then, you can utilize various tools to perform searches, crawl web pages, or extract sitemaps by sending requests with the required parameters.\\n\\n## key features of Search1API? \\n- Comprehensive web search functionality\\n- Ability to search news articles\\n- Extracting content from specific URLs\\n- Generating sitemaps from provided URLs\\n- Seamless integration with Claude Desktop\\n\\n## use cases of Search1API? \\n1. Searching for information relevant to a specific topic on the web.\\n2. Extracting news articles for real-time updates.\\n3. Crawling a target URL to gather content for analysis.\\n4. Generating a sitemap to understand web structure for SEO purposes.\\n\\n## FAQ from Search1API? \\n- How do I obtain an API key for Search1API?\\n\\u003e You can obtain an API key by registering on the Search1API website and selecting a pricing plan.\\n\\n- Is there a free trial available?\\n\\u003e Yes! Search1API offers a pricing plan starting from $0.99, which allows users to explore its functionalities.\\n\\n- What programming languages can I use with Search1API?\\n\\u003e Search1API can be accessed through any programming language that supports HTTP requests, making it versatile for various applications.70:Te02,[{\\\"name\\\":\\\"search\\\",\\\"description\\\":\\\"Web search tool\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"crawl_results\\\":{\\\"default\\\":0,\\\"description\\\":\\\"Number of results to crawl for full webpage content, useful when search result summaries are insufficient for complex queries\\\",\\\"type\\\":\\\"number\\\"},\\\"exclude_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to exclude from search. Only use when you need to explicitly filter out specific domains from results\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"include_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to include in search. Only use when you need special results from sites not available in search_service\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"max_results\\\":{\\\"default\\\":10,\\\"description\\\":\\\"Maximum number of results to return\\\",\\\"type\\\":\\\"number\\\"},\\\"query\\\":{\\\"description\\\":\\\"Search query, be simple and concise\\\",\\\"type\\\":\\\"string\\\"},\\\"search_service\\\":{\\\"default\\\":\\\"google\\\",\\\"description\\\":\\\"Specify the search engine to use. Choose based on your specific needs\\\",\\\"enum\\\":[\\\"google\\\",\\\"bing\\\",\\\"duckduckgo\\\",\\\"yahoo\\\",\\\"x\\\",\\\"reddit\\\",\\\"github\\\",\\\"youtube\\\",\\\"arxiv\\\",\\\"wechat\\\",\\\"bilibili\\\",\\\"imdb\\\",\\\"wikipedia\\\"],\\\"type\\\":\\\"string\\\"},\\\"time_range\\\":{\\\"description\\\":\\\"Time range for search results, only use when specific time constraints are required\\\",\\\"enum\\\":[\\\"day\\\",\\\"month\\\",\\\"year\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"news\\\",\\\"description\\\":\\\"News search tool\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"crawl_results\\\":{\\\"default\\\":0,\\\"description\\\":\\\"Number of results to crawl for full webpage content, useful when search result summaries are insufficient for complex queries\\\",\\\"type\\\":\\\"number\\\"},\\\"exclude_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to exclude from search. Only use when you need to explicitly filter out specific domains from results\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"include_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to include in search. Only use when you need special results from sites not available in search_service\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"max_results\\\":{\\\"default\\\":10,\\\"description\\\":\\\"Maximum number of results to return\\\",\\\"type\\\":\\\"number\\\"},\\\"query\\\":{\\\"description\\\":\\\"Search query, be simple and concise\\\",\\\"type\\\":\\\"string\\\"},\\\"search_service\\\":{\\\"default\\\":\\\"bing\\\",\\\"description\\\":\\\"Specify the news engine to use. Choose based on your specific needs\\\",\\\"enum\\\":[\\\"google\\\",\\\"bing\\\",\\\"duckduckgo\\\",\\\"yahoo\\\",\\\"hackernews\\\"],\\\"type\\\":\\\"string\\\"},\\\"time_range\\\":{\\\"description\\\":\\\"Time range for search results, only use when specific time constraints are required\\\",\\\"enum\\\":[\\\"day\\\",\\\"month\\\",\\\"year\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"crawl\\\",\\\"description\\\":\\\"Extract content from URL\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"url\\\":{\\\"d\"])</script><script>self.__next_f.push([1,\"escription\\\":\\\"URL to crawl\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"sitemap\\\",\\\"description\\\":\\\"Get all related links from a URL\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"url\\\":{\\\"description\\\":\\\"URL to get sitemap\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"reasoning\\\",\\\"description\\\":\\\"Deep thinking and complex problem solving\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"content\\\":{\\\"description\\\":\\\"The question or problem that needs deep thinking\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"content\\\"]}},{\\\"name\\\":\\\"trending\\\",\\\"description\\\":\\\"Get trending topics from popular platforms\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"max_results\\\":{\\\"default\\\":10,\\\"description\\\":\\\"Maximum number of trending items to return\\\",\\\"type\\\":\\\"number\\\"},\\\"search_service\\\":{\\\"default\\\":\\\"github\\\",\\\"description\\\":\\\"Specify the platform to get trending topics from\\\",\\\"enum\\\":[\\\"github\\\",\\\"hackernews\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"search_service\\\"]}}]71:Ta37,# AWS Knowledge Base Retrieval MCP Server\\r\\n\\r\\nAn MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.\\r\\n\\r\\n## Features\\r\\n\\r\\n- **RAG (Retrieval-Augmented Generation)**: Retrieve context from the AWS Knowledge Base based on a query and a Knowledge Base ID.\\r\\n- **Supports multiple results retrieval**: Option to retrieve a customizable number of results.\\r\\n\\r\\n## Tools\\r\\n\\r\\n- **retrieve_from_aws_kb**\\r\\n  - Perform retrieval operations using the AWS Knowledge Base.\\r\\n  - Inputs:\\r\\n    - `query` (string): The search query for retrieval.\\r\\n    - `knowledgeBaseId` (string): The ID of the AWS Knowledge Base.\\r\\n    - `n` (number, optional): Number of results to retrieve (default: 3).\\r\\n\\r\\n## Configuration\\r\\n\\r\\n### Setting up AWS Credentials\\r\\n\\r\\n1. Obtain AWS access key ID, secret access key, and region from the AWS Management Console.\\r\\n2. Ensure these credentials have appropriate permissions for Bedrock Agent Runtime operations.\\r\\n\\r\\n### Usage with Claude Desktop\\r\\n\\r\\nAdd this to your `claude_desktop_config.json`:\\r\\n\\r\\n#### Docker\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"aws-kb-retrieval\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [ \\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"-e\\\", \\\"AWS_ACCESS_KEY_ID\\\", \\\"-e\\\", \\\"AWS_SECRET_ACCESS_KEY\\\", \\\"-e\\\", \\\"AWS_REGION\\\", \\\"mcp/aws-kb-retrieval-server\\\" ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"AWS_ACCESS_KEY_ID\\\": \\\"YOUR_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_SECRET_ACCESS_KEY\\\": \\\"YOUR_SECRET_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_REGION\\\": \\\"YOUR_AWS_REGION_HERE\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"aws-kb-retrieval\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-aws-kb-retrieval\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"AWS_ACCESS_KEY_ID\\\": \\\"YOUR_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_SECRET_ACCESS_KEY\\\": \\\"YOUR_SECRET_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_REGION\\\": \\\"YOUR_AWS_REGION_HERE\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Building\\r\\n\\r\\nDocker: \\r\\n\\r\\n```sh\\r\\ndocker build -t mcp/aws-kb-retrieval -f src/aws-kb-retrieval-server/Dockerfile . \\r\\n```\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\\r\\n\\r\\nThis README assumes that your server package is named `@modelcontextprotocol/server-aws-kb-retrieval`. Adjust the package name and installation details if they differ in your setup. Also, ensure that your server script is correctly built and that all dependencies are properly managed in your `package.json`.\\r\\n72:T61a,## what is AWS Knowledge Base Retrieval Server? \\nThe AWS Knowledge Base Retrieval Server is an MCP server implementation designed to retrieve information from the AWS Knowledge Base using the Bedrock Agent Runtime.\\n\\n## how to use AWS Knowledge Base Retrieval Server? \\nTo use the server, set up your AWS credentials and configure the server in your `claude_desktop_config.json`. You can run it using Docker or npx commands with the necessary environment variables for AWS access.\\n\\n## key features of AWS Knowledge Base Retrieval Server? \\n- **RAG (Retrieva\"])</script><script>self.__next_f.push([1,\"l-Augmented Generation)**: Retrieve context from the AWS Knowledge Base based on a query and a Knowledge Base ID.\\n- **Supports multiple results retrieval**: Option to retrieve a customizable number of results.\\n\\n## use cases of AWS Knowledge Base Retrieval Server? \\n1. Retrieving specific information from AWS documentation based on user queries.\\n2. Integrating with applications that require dynamic access to AWS Knowledge Base content.\\n3. Enhancing customer support tools with quick access to AWS resources.\\n\\n## FAQ from AWS Knowledge Base Retrieval Server? \\n- How do I set up AWS credentials?\\n\\u003e Obtain your AWS access key ID, secret access key, and region from the AWS Management Console and ensure they have the necessary permissions.\\n\\n- Can I customize the number of results retrieved?\\n\\u003e Yes! You can specify the number of results to retrieve when making a query.\\n\\n- Is there a license for this server?\\n\\u003e Yes, the server is licensed under the MIT License, allowing you to use, modify, and distribute it.73:T12f8,# Time MCP Server\\r\\n\\r\\nA Model Context Protocol server that provides time and timezone conversion capabilities. This server enables LLMs to get current time information and perform timezone conversions using IANA timezone names, with automatic system timezone detection.\\r\\n\\r\\n### Available Tools\\r\\n\\r\\n- `get_current_time` - Get current time in a specific timezone or system timezone.\\r\\n  - Required arguments:\\r\\n    - `timezone` (string): IANA timezone name (e.g., 'America/New_York', 'Europe/London')\\r\\n\\r\\n- `convert_time` - Convert time between timezones.\\r\\n  - Required arguments:\\r\\n    - `source_timezone` (string): Source IANA timezone name\\r\\n    - `time` (string): Time in 24-hour format (HH:MM)\\r\\n    - `target_timezone` (string): Target IANA timezone name\\r\\n\\r\\n## Installation\\r\\n\\r\\n### Using uv (recommended)\\r\\n\\r\\nWhen using [`uv`](https://docs.astral.sh/uv/) no specific installation is needed. We will\\r\\nuse [`uvx`](https://docs.astral.sh/uv/guides/tools/) to directly run *mcp-server-time*.\\r\\n\\r\\n### Using PIP\\r\\n\\r\\nAlternatively you can install `mcp-server-time` via pip:\\r\\n\\r\\n```bash\\r\\npip install mcp-server-time\\r\\n```\\r\\n\\r\\nAfter installation, you can run it as a script using:\\r\\n\\r\\n```bash\\r\\npython -m mcp_server_time\\r\\n```\\r\\n\\r\\n## Configuration\\r\\n\\r\\n### Configure for Claude.app\\r\\n\\r\\nAdd to your Claude settings:\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing uvx\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"time\\\": {\\r\\n    \\\"command\\\": \\\"uvx\\\",\\r\\n    \\\"args\\\": [\\\"mcp-server-time\\\"]\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing docker\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"time\\\": {\\r\\n    \\\"command\\\": \\\"docker\\\",\\r\\n    \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"mcp/time\\\"]\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing pip installation\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"time\\\": {\\r\\n    \\\"command\\\": \\\"python\\\",\\r\\n    \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_time\\\"]\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n### Configure for Zed\\r\\n\\r\\nAdd to your Zed settings.json:\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing uvx\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"context_servers\\\": [\\r\\n  \\\"mcp-server-time\\\": {\\r\\n    \\\"command\\\": \\\"uvx\\\",\\r\\n    \\\"args\\\": [\\\"mcp-server-time\\\"]\\r\\n  }\\r\\n],\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n\\u003cdetails\\u003e\\r\\n\\u003csummary\\u003eUsing pip installation\\u003c/summary\\u003e\\r\\n\\r\\n```json\\r\\n\\\"context_servers\\\": {\\r\\n  \\\"mcp-server-time\\\": {\\r\\n    \\\"command\\\": \\\"python\\\",\\r\\n    \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_time\\\"]\\r\\n  }\\r\\n},\\r\\n```\\r\\n\\u003c/details\\u003e\\r\\n\\r\\n### Customization - System Timezone\\r\\n\\r\\nBy default, the server automatically detects your system's timezone. You can override this by adding the argument `--local-timezone` to the `args` list in the configuration.\\r\\n\\r\\nExample:\\r\\n```json\\r\\n{\\r\\n  \\\"command\\\": \\\"python\\\",\\r\\n  \\\"args\\\": [\\\"-m\\\", \\\"mcp_server_time\\\", \\\"--local-timezone=America/New_York\\\"]\\r\\n}\\r\\n```\\r\\n\\r\\n## Example Interactions\\r\\n\\r\\n1. Get current time:\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"get_current_time\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"timezone\\\": \\\"Europe/Warsaw\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\nResponse:\\r\\n```json\\r\\n{\\r\\n  \\\"timezone\\\": \\\"Europe/Warsaw\\\",\\r\\n  \\\"datetime\\\": \\\"2024-01-01T13:00:00+01:00\\\",\\r\\n  \\\"is_dst\\\": false\\r\\n}\\r\\n```\\r\\n\\r\\n2. Convert time between timezones:\\r\\n```json\\r\\n{\\r\\n  \\\"name\\\": \\\"convert_time\\\",\\r\\n  \\\"arguments\\\": {\\r\\n    \\\"source_timezone\\\": \\\"America/New_York\\\",\\r\\n    \\\"time\\\": \\\"16:30\\\",\\r\\n    \\\"target_timezo\"])</script><script>self.__next_f.push([1,\"ne\\\": \\\"Asia/Tokyo\\\"\\r\\n  }\\r\\n}\\r\\n```\\r\\nResponse:\\r\\n```json\\r\\n{\\r\\n  \\\"source\\\": {\\r\\n    \\\"timezone\\\": \\\"America/New_York\\\",\\r\\n    \\\"datetime\\\": \\\"2024-01-01T12:30:00-05:00\\\",\\r\\n    \\\"is_dst\\\": false\\r\\n  },\\r\\n  \\\"target\\\": {\\r\\n    \\\"timezone\\\": \\\"Asia/Tokyo\\\",\\r\\n    \\\"datetime\\\": \\\"2024-01-01T12:30:00+09:00\\\",\\r\\n    \\\"is_dst\\\": false\\r\\n  },\\r\\n  \\\"time_difference\\\": \\\"+13.0h\\\",\\r\\n}\\r\\n```\\r\\n\\r\\n## Debugging\\r\\n\\r\\nYou can use the MCP inspector to debug the server. For uvx installations:\\r\\n\\r\\n```bash\\r\\nnpx @modelcontextprotocol/inspector uvx mcp-server-time\\r\\n```\\r\\n\\r\\nOr if you've installed the package in a specific directory or are developing on it:\\r\\n\\r\\n```bash\\r\\ncd path/to/servers/src/time\\r\\nnpx @modelcontextprotocol/inspector uv run mcp-server-time\\r\\n```\\r\\n\\r\\n## Examples of Questions for Claude\\r\\n\\r\\n1. \\\"What time is it now?\\\" (will use system timezone)\\r\\n2. \\\"What time is it in Tokyo?\\\"\\r\\n3. \\\"When it's 4 PM in New York, what time is it in London?\\\"\\r\\n4. \\\"Convert 9:30 AM Tokyo time to New York time\\\"\\r\\n\\r\\n## Build\\r\\n\\r\\nDocker build:\\r\\n\\r\\n```bash\\r\\ncd src/time\\r\\ndocker build -t mcp/time .\\r\\n```\\r\\n\\r\\n## Contributing\\r\\n\\r\\nWe encourage contributions to help expand and improve mcp-server-time. Whether you want to add new time-related tools, enhance existing functionality, or improve documentation, your input is valuable.\\r\\n\\r\\nFor examples of other MCP servers and implementation patterns, see:\\r\\nhttps://github.com/modelcontextprotocol/servers\\r\\n\\r\\nPull requests are welcome! Feel free to contribute new ideas, bug fixes, or enhancements to make mcp-server-time even more powerful and useful.\\r\\n\\r\\n## License\\r\\n\\r\\nmcp-server-time is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\\r\\n74:T638,## what is Time MCP Server?\\nTime MCP Server is a Model Context Protocol server that provides time and timezone conversion capabilities. It enables LLMs to get current time information and perform timezone conversions using IANA timezone names, with automatic system timezone detection.\\n\\n## how to use Time MCP Server?\\nTo use Time MCP Server, you can install it via pip or use uvx for direct execution. After installation, configure it in your Claude or Zed settings. The server provides tools like `get_current_time` and `convert_time` to fetch current time in a specific timezone and convert time between timezones, respectively.\\n\\n## key features of Time MCP Server?\\n- Provides current time information in any IANA timezone.\\n- Converts time between different timezones.\\n- Automatic system timezone detection with the option to override.\\n- Easy integration with Claude and Zed through configuration settings.\\n\\n## use cases of Time MCP Server?\\n1. Getting the current time in a specific timezone.\\n2. Converting time between different timezones for scheduling and coordination.\\n3. Automating time-related queries in applications and services.\\n\\n## FAQ from Time MCP Server?\\n- Can Time MCP Server handle all IANA timezones?\\n\\u003e Yes, Time MCP Server supports all IANA timezones for time and timezone conversion.\\n\\n- Is Time MCP Server free to use?\\n\\u003e Yes, Time MCP Server is open-source and free to use under the MIT License.\\n\\n- How accurate is the time provided by Time MCP Server?\\n\\u003e The time provided by Time MCP Server is highly accurate, relying on system time and IANA timezone data for precision.75:T5947,# Firecrawl MCP Server\\n\\nA Model Context Protocol (MCP) server implementation that integrates with [Firecrawl](https://github.com/mendableai/firecrawl) for web scraping capabilities.\\n\\n\\u003e Big thanks to [@vrknetha](https://github.com/vrknetha), [@knacklabs](https://www.knacklabs.ai) for the initial implementation!\\n\\n\\n## Features\\n\\n- Web scraping, crawling, and discovery\\n- Search and content extraction\\n- Deep research and batch scraping\\n- Automatic retries and rate limiting\\n- Cloud and self-hosted support\\n- SSE support\\n\\n\\u003e Play around with [our MCP Server on MCP.so's playground](https://mcp.so/playground?server=firecrawl-mcp-server) or on [Klavis AI](https://www.klavis.ai/mcp-servers).\\n\\n## Installation\\n\\n### R\"])</script><script>self.__next_f.push([1,\"unning with npx\\n\\n```bash\\nenv FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y firecrawl-mcp\\n```\\n\\n### Manual Installation\\n\\n```bash\\nnpm install -g firecrawl-mcp\\n```\\n\\n### Running on Cursor\\n\\nConfiguring Cursor \ud83d\udda5\ufe0f\\nNote: Requires Cursor version 0.45.6+\\nFor the most up-to-date configuration instructions, please refer to the official Cursor documentation on configuring MCP servers:\\n[Cursor MCP Server Configuration Guide](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers)\\n\\nTo configure Firecrawl MCP in Cursor **v0.48.6**\\n\\n1. Open Cursor Settings\\n2. Go to Features \\u003e MCP Servers\\n3. Click \\\"+ Add new global MCP server\\\"\\n4. Enter the following code:\\n   ```json\\n   {\\n     \\\"mcpServers\\\": {\\n       \\\"firecrawl-mcp\\\": {\\n         \\\"command\\\": \\\"npx\\\",\\n         \\\"args\\\": [\\\"-y\\\", \\\"firecrawl-mcp\\\"],\\n         \\\"env\\\": {\\n           \\\"FIRECRAWL_API_KEY\\\": \\\"YOUR-API-KEY\\\"\\n         }\\n       }\\n     }\\n   }\\n   ```\\n   \\nTo configure Firecrawl MCP in Cursor **v0.45.6**\\n\\n1. Open Cursor Settings\\n2. Go to Features \\u003e MCP Servers\\n3. Click \\\"+ Add New MCP Server\\\"\\n4. Enter the following:\\n   - Name: \\\"firecrawl-mcp\\\" (or your preferred name)\\n   - Type: \\\"command\\\"\\n   - Command: `env FIRECRAWL_API_KEY=your-api-key npx -y firecrawl-mcp`\\n\\n\\n\\n\\u003e If you are using Windows and are running into issues, try `cmd /c \\\"set FIRECRAWL_API_KEY=your-api-key \\u0026\\u0026 npx -y firecrawl-mcp\\\"`\\n\\nReplace `your-api-key` with your Firecrawl API key. If you don't have one yet, you can create an account and get it from https://www.firecrawl.dev/app/api-keys\\n\\nAfter adding, refresh the MCP server list to see the new tools. The Composer Agent will automatically use Firecrawl MCP when appropriate, but you can explicitly request it by describing your web scraping needs. Access the Composer via Command+L (Mac), select \\\"Agent\\\" next to the submit button, and enter your query.\\n\\n### Running on Windsurf\\n\\nAdd this to your `./codeium/windsurf/model_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-server-firecrawl\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"firecrawl-mcp\\\"],\\n      \\\"env\\\": {\\n        \\\"FIRECRAWL_API_KEY\\\": \\\"YOUR_API_KEY\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### Running with SSE Local Mode\\n\\nTo run the server using Server-Sent Events (SSE) locally instead of the default stdio transport:\\n\\n```bash\\nenv SSE_LOCAL=true FIRECRAWL_API_KEY=fc-YOUR_API_KEY npx -y firecrawl-mcp\\n```\\n\\nUse the url: http://localhost:3000/sse\\n\\n### Installing via Smithery (Legacy)\\n\\nTo install Firecrawl for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@mendableai/mcp-server-firecrawl):\\n\\n```bash\\nnpx -y @smithery/cli install @mendableai/mcp-server-firecrawl --client claude\\n```\\n\\n### Running on VS Code\\n\\nFor one-click installation, click one of the install buttons below...\\n\\n[![Install with NPX in VS Code](https://img.shields.io/badge/VS_Code-NPM-0098FF?style=flat-square\\u0026logo=visualstudiocode\\u0026logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl\\u0026inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D\\u0026config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D) [![Install with NPX in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-NPM-24bfa5?style=flat-square\\u0026logo=visualstudiocode\\u0026logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=firecrawl\\u0026inputs=%5B%7B%22type%22%3A%22promptString%22%2C%22id%22%3A%22apiKey%22%2C%22description%22%3A%22Firecrawl%20API%20Key%22%2C%22password%22%3Atrue%7D%5D\\u0026config=%7B%22command%22%3A%22npx%22%2C%22args%22%3A%5B%22-y%22%2C%22firecrawl-mcp%22%5D%2C%22env%22%3A%7B%22FIRECRAWL_API_KEY%22%3A%22%24%7Binput%3AapiKey%7D%22%7D%7D\\u0026quality=insiders)\\n\\nFor manual installation, add the following JSON block to your User Settings (JSON) file in VS Code. You can do this by pressing `Ctrl + Shift + P` and typing `Preferences: Open User Settings (JSON)`.\\n\\n```json\\n{\\n  \\\"mcp\\\": {\\n    \\\"inputs\\\": [\\n      {\\n        \\\"type\\\": \\\"promptString\\\",\\n        \\\"i\"])</script><script>self.__next_f.push([1,\"d\\\": \\\"apiKey\\\",\\n        \\\"description\\\": \\\"Firecrawl API Key\\\",\\n        \\\"password\\\": true\\n      }\\n    ],\\n    \\\"servers\\\": {\\n      \\\"firecrawl\\\": {\\n        \\\"command\\\": \\\"npx\\\",\\n        \\\"args\\\": [\\\"-y\\\", \\\"firecrawl-mcp\\\"],\\n        \\\"env\\\": {\\n          \\\"FIRECRAWL_API_KEY\\\": \\\"${input:apiKey}\\\"\\n        }\\n      }\\n    }\\n  }\\n}\\n```\\n\\nOptionally, you can add it to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with others:\\n\\n```json\\n{\\n  \\\"inputs\\\": [\\n    {\\n      \\\"type\\\": \\\"promptString\\\",\\n      \\\"id\\\": \\\"apiKey\\\",\\n      \\\"description\\\": \\\"Firecrawl API Key\\\",\\n      \\\"password\\\": true\\n    }\\n  ],\\n  \\\"servers\\\": {\\n    \\\"firecrawl\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"firecrawl-mcp\\\"],\\n      \\\"env\\\": {\\n        \\\"FIRECRAWL_API_KEY\\\": \\\"${input:apiKey}\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Configuration\\n\\n### Environment Variables\\n\\n#### Required for Cloud API\\n\\n- `FIRECRAWL_API_KEY`: Your Firecrawl API key\\n  - Required when using cloud API (default)\\n  - Optional when using self-hosted instance with `FIRECRAWL_API_URL`\\n- `FIRECRAWL_API_URL` (Optional): Custom API endpoint for self-hosted instances\\n  - Example: `https://firecrawl.your-domain.com`\\n  - If not provided, the cloud API will be used (requires API key)\\n\\n#### Optional Configuration\\n\\n##### Retry Configuration\\n\\n- `FIRECRAWL_RETRY_MAX_ATTEMPTS`: Maximum number of retry attempts (default: 3)\\n- `FIRECRAWL_RETRY_INITIAL_DELAY`: Initial delay in milliseconds before first retry (default: 1000)\\n- `FIRECRAWL_RETRY_MAX_DELAY`: Maximum delay in milliseconds between retries (default: 10000)\\n- `FIRECRAWL_RETRY_BACKOFF_FACTOR`: Exponential backoff multiplier (default: 2)\\n\\n##### Credit Usage Monitoring\\n\\n- `FIRECRAWL_CREDIT_WARNING_THRESHOLD`: Credit usage warning threshold (default: 1000)\\n- `FIRECRAWL_CREDIT_CRITICAL_THRESHOLD`: Credit usage critical threshold (default: 100)\\n\\n### Configuration Examples\\n\\nFor cloud API usage with custom retry and credit monitoring:\\n\\n```bash\\n# Required for cloud API\\nexport FIRECRAWL_API_KEY=your-api-key\\n\\n# Optional retry configuration\\nexport FIRECRAWL_RETRY_MAX_ATTEMPTS=5        # Increase max retry attempts\\nexport FIRECRAWL_RETRY_INITIAL_DELAY=2000    # Start with 2s delay\\nexport FIRECRAWL_RETRY_MAX_DELAY=30000       # Maximum 30s delay\\nexport FIRECRAWL_RETRY_BACKOFF_FACTOR=3      # More aggressive backoff\\n\\n# Optional credit monitoring\\nexport FIRECRAWL_CREDIT_WARNING_THRESHOLD=2000    # Warning at 2000 credits\\nexport FIRECRAWL_CREDIT_CRITICAL_THRESHOLD=500    # Critical at 500 credits\\n```\\n\\nFor self-hosted instance:\\n\\n```bash\\n# Required for self-hosted\\nexport FIRECRAWL_API_URL=https://firecrawl.your-domain.com\\n\\n# Optional authentication for self-hosted\\nexport FIRECRAWL_API_KEY=your-api-key  # If your instance requires auth\\n\\n# Custom retry configuration\\nexport FIRECRAWL_RETRY_MAX_ATTEMPTS=10\\nexport FIRECRAWL_RETRY_INITIAL_DELAY=500     # Start with faster retries\\n```\\n\\n### Usage with Claude Desktop\\n\\nAdd this to your `claude_desktop_config.json`:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcp-server-firecrawl\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"firecrawl-mcp\\\"],\\n      \\\"env\\\": {\\n        \\\"FIRECRAWL_API_KEY\\\": \\\"YOUR_API_KEY_HERE\\\",\\n\\n        \\\"FIRECRAWL_RETRY_MAX_ATTEMPTS\\\": \\\"5\\\",\\n        \\\"FIRECRAWL_RETRY_INITIAL_DELAY\\\": \\\"2000\\\",\\n        \\\"FIRECRAWL_RETRY_MAX_DELAY\\\": \\\"30000\\\",\\n        \\\"FIRECRAWL_RETRY_BACKOFF_FACTOR\\\": \\\"3\\\",\\n\\n        \\\"FIRECRAWL_CREDIT_WARNING_THRESHOLD\\\": \\\"2000\\\",\\n        \\\"FIRECRAWL_CREDIT_CRITICAL_THRESHOLD\\\": \\\"500\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n### System Configuration\\n\\nThe server includes several configurable parameters that can be set via environment variables. Here are the default values if not configured:\\n\\n```typescript\\nconst CONFIG = {\\n  retry: {\\n    maxAttempts: 3, // Number of retry attempts for rate-limited requests\\n    initialDelay: 1000, // Initial delay before first retry (in milliseconds)\\n    maxDelay: 10000, // Maximum delay between retries (in milliseconds)\\n    backoffFactor: 2, // Multiplier for exponential backoff\\n  },\\n  credit: {\\n    warningThreshold: 1000, // Warn when credit usage reaches this level\\n    criticalThreshold: 100, // Critical alert \"])</script><script>self.__next_f.push([1,\"when credit usage reaches this level\\n  },\\n};\\n```\\n\\nThese configurations control:\\n\\n1. **Retry Behavior**\\n\\n   - Automatically retries failed requests due to rate limits\\n   - Uses exponential backoff to avoid overwhelming the API\\n   - Example: With default settings, retries will be attempted at:\\n     - 1st retry: 1 second delay\\n     - 2nd retry: 2 seconds delay\\n     - 3rd retry: 4 seconds delay (capped at maxDelay)\\n\\n2. **Credit Usage Monitoring**\\n   - Tracks API credit consumption for cloud API usage\\n   - Provides warnings at specified thresholds\\n   - Helps prevent unexpected service interruption\\n   - Example: With default settings:\\n     - Warning at 1000 credits remaining\\n     - Critical alert at 100 credits remaining\\n\\n### Rate Limiting and Batch Processing\\n\\nThe server utilizes Firecrawl's built-in rate limiting and batch processing capabilities:\\n\\n- Automatic rate limit handling with exponential backoff\\n- Efficient parallel processing for batch operations\\n- Smart request queuing and throttling\\n- Automatic retries for transient errors\\n\\n## How to Choose a Tool\\n\\nUse this guide to select the right tool for your task:\\n\\n- **If you know the exact URL(s) you want:**\\n  - For one: use **scrape**\\n  - For many: use **batch_scrape**\\n- **If you need to discover URLs on a site:** use **map**\\n- **If you want to search the web for info:** use **search**\\n- **If you want to extract structured data:** use **extract**\\n- **If you want to analyze a whole site or section:** use **crawl** (with limits!)\\n- **If you want to do in-depth research:** use **deep_research**\\n- **If you want to generate LLMs.txt:** use **generate_llmstxt**\\n\\n### Quick Reference Table\\n\\n| Tool                | Best for                                 | Returns         |\\n|---------------------|------------------------------------------|-----------------|\\n| scrape              | Single page content                      | markdown/html   |\\n| batch_scrape        | Multiple known URLs                      | markdown/html[] |\\n| map                 | Discovering URLs on a site               | URL[]           |\\n| crawl               | Multi-page extraction (with limits)      | markdown/html[] |\\n| search              | Web search for info                      | results[]       |\\n| extract             | Structured data from pages               | JSON            |\\n| deep_research       | In-depth, multi-source research          | summary, sources|\\n| generate_llmstxt    | LLMs.txt for a domain                    | text            |\\n\\n## Available Tools\\n\\n### 1. Scrape Tool (`firecrawl_scrape`)\\n\\nScrape content from a single URL with advanced options.\\n\\n**Best for:**\\n- Single page content extraction, when you know exactly which page contains the information.\\n\\n**Not recommended for:**\\n- Extracting content from multiple pages (use batch_scrape for known URLs, or map + batch_scrape to discover URLs first, or crawl for full page content)\\n- When you're unsure which page contains the information (use search)\\n- When you need structured data (use extract)\\n\\n**Common mistakes:**\\n- Using scrape for a list of URLs (use batch_scrape instead).\\n\\n**Prompt Example:**\\n\\u003e \\\"Get the content of the page at https://example.com.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_scrape\\\",\\n  \\\"arguments\\\": {\\n    \\\"url\\\": \\\"https://example.com\\\",\\n    \\\"formats\\\": [\\\"markdown\\\"],\\n    \\\"onlyMainContent\\\": true,\\n    \\\"waitFor\\\": 1000,\\n    \\\"timeout\\\": 30000,\\n    \\\"mobile\\\": false,\\n    \\\"includeTags\\\": [\\\"article\\\", \\\"main\\\"],\\n    \\\"excludeTags\\\": [\\\"nav\\\", \\\"footer\\\"],\\n    \\\"skipTlsVerification\\\": false\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Markdown, HTML, or other formats as specified.\\n\\n### 2. Batch Scrape Tool (`firecrawl_batch_scrape`)\\n\\nScrape multiple URLs efficiently with built-in rate limiting and parallel processing.\\n\\n**Best for:**\\n- Retrieving content from multiple pages, when you know exactly which pages to scrape.\\n\\n**Not recommended for:**\\n- Discovering URLs (use map first if you don't know the URLs)\\n- Scraping a single page (use scrape)\\n\\n**Common mistakes:**\\n- Using batch_scrape with too many URLs at once (may hit rate limits or token overflow)\\n\\n**Prompt \"])</script><script>self.__next_f.push([1,\"Example:**\\n\\u003e \\\"Get the content of these three blog posts: [url1, url2, url3].\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_batch_scrape\\\",\\n  \\\"arguments\\\": {\\n    \\\"urls\\\": [\\\"https://example1.com\\\", \\\"https://example2.com\\\"],\\n    \\\"options\\\": {\\n      \\\"formats\\\": [\\\"markdown\\\"],\\n      \\\"onlyMainContent\\\": true\\n    }\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Response includes operation ID for status checking:\\n\\n```json\\n{\\n  \\\"content\\\": [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\": \\\"Batch operation queued with ID: batch_1. Use firecrawl_check_batch_status to check progress.\\\"\\n    }\\n  ],\\n  \\\"isError\\\": false\\n}\\n```\\n\\n### 3. Check Batch Status (`firecrawl_check_batch_status`)\\n\\nCheck the status of a batch operation.\\n\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_check_batch_status\\\",\\n  \\\"arguments\\\": {\\n    \\\"id\\\": \\\"batch_1\\\"\\n  }\\n}\\n```\\n\\n### 4. Map Tool (`firecrawl_map`)\\n\\nMap a website to discover all indexed URLs on the site.\\n\\n**Best for:**\\n- Discovering URLs on a website before deciding what to scrape\\n- Finding specific sections of a website\\n\\n**Not recommended for:**\\n- When you already know which specific URL you need (use scrape or batch_scrape)\\n- When you need the content of the pages (use scrape after mapping)\\n\\n**Common mistakes:**\\n- Using crawl to discover URLs instead of map\\n\\n**Prompt Example:**\\n\\u003e \\\"List all URLs on example.com.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_map\\\",\\n  \\\"arguments\\\": {\\n    \\\"url\\\": \\\"https://example.com\\\"\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Array of URLs found on the site\\n\\n### 5. Search Tool (`firecrawl_search`)\\n\\nSearch the web and optionally extract content from search results.\\n\\n**Best for:**\\n- Finding specific information across multiple websites, when you don't know which website has the information.\\n- When you need the most relevant content for a query\\n\\n**Not recommended for:**\\n- When you already know which website to scrape (use scrape)\\n- When you need comprehensive coverage of a single website (use map or crawl)\\n\\n**Common mistakes:**\\n- Using crawl or map for open-ended questions (use search instead)\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_search\\\",\\n  \\\"arguments\\\": {\\n    \\\"query\\\": \\\"latest AI research papers 2023\\\",\\n    \\\"limit\\\": 5,\\n    \\\"lang\\\": \\\"en\\\",\\n    \\\"country\\\": \\\"us\\\",\\n    \\\"scrapeOptions\\\": {\\n      \\\"formats\\\": [\\\"markdown\\\"],\\n      \\\"onlyMainContent\\\": true\\n    }\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Array of search results (with optional scraped content)\\n\\n**Prompt Example:**\\n\\u003e \\\"Find the latest research papers on AI published in 2023.\\\"\\n\\n### 6. Crawl Tool (`firecrawl_crawl`)\\n\\nStarts an asynchronous crawl job on a website and extract content from all pages.\\n\\n**Best for:**\\n- Extracting content from multiple related pages, when you need comprehensive coverage.\\n\\n**Not recommended for:**\\n- Extracting content from a single page (use scrape)\\n- When token limits are a concern (use map + batch_scrape)\\n- When you need fast results (crawling can be slow)\\n\\n**Warning:** Crawl responses can be very large and may exceed token limits. Limit the crawl depth and number of pages, or use map + batch_scrape for better control.\\n\\n**Common mistakes:**\\n- Setting limit or maxDepth too high (causes token overflow)\\n- Using crawl for a single page (use scrape instead)\\n\\n**Prompt Example:**\\n\\u003e \\\"Get all blog posts from the first two levels of example.com/blog.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_crawl\\\",\\n  \\\"arguments\\\": {\\n    \\\"url\\\": \\\"https://example.com/blog/*\\\",\\n    \\\"maxDepth\\\": 2,\\n    \\\"limit\\\": 100,\\n    \\\"allowExternalLinks\\\": false,\\n    \\\"deduplicateSimilarURLs\\\": true\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Response includes operation ID for status checking:\\n\\n```json\\n{\\n  \\\"content\\\": [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\": \\\"Started crawl for: https://example.com/* with job ID: 550e8400-e29b-41d4-a716-446655440000. Use firecrawl_check_crawl_status to check progress.\\\"\\n    }\\n  ],\\n  \\\"isError\\\": false\\n}\\n```\\n\\n### 7. Check Crawl Status (`firecrawl_check_crawl_status`)\\n\\nCheck the status of a crawl job.\\n\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_check_crawl_status\\\",\\n  \\\"arguments\\\": {\\n    \\\"id\\\": \\\"550e8400-e29b-41d4-a716-446655440000\\\"\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Response includes the status of the crawl job:\\n  \\n### 8. Extract\"])</script><script>self.__next_f.push([1,\" Tool (`firecrawl_extract`)\\n\\nExtract structured information from web pages using LLM capabilities. Supports both cloud AI and self-hosted LLM extraction.\\n\\n**Best for:**\\n- Extracting specific structured data like prices, names, details.\\n\\n**Not recommended for:**\\n- When you need the full content of a page (use scrape)\\n- When you're not looking for specific structured data\\n\\n**Arguments:**\\n- `urls`: Array of URLs to extract information from\\n- `prompt`: Custom prompt for the LLM extraction\\n- `systemPrompt`: System prompt to guide the LLM\\n- `schema`: JSON schema for structured data extraction\\n- `allowExternalLinks`: Allow extraction from external links\\n- `enableWebSearch`: Enable web search for additional context\\n- `includeSubdomains`: Include subdomains in extraction\\n\\nWhen using a self-hosted instance, the extraction will use your configured LLM. For cloud API, it uses Firecrawl's managed LLM service.\\n**Prompt Example:**\\n\\u003e \\\"Extract the product name, price, and description from these product pages.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_extract\\\",\\n  \\\"arguments\\\": {\\n    \\\"urls\\\": [\\\"https://example.com/page1\\\", \\\"https://example.com/page2\\\"],\\n    \\\"prompt\\\": \\\"Extract product information including name, price, and description\\\",\\n    \\\"systemPrompt\\\": \\\"You are a helpful assistant that extracts product information\\\",\\n    \\\"schema\\\": {\\n      \\\"type\\\": \\\"object\\\",\\n      \\\"properties\\\": {\\n        \\\"name\\\": { \\\"type\\\": \\\"string\\\" },\\n        \\\"price\\\": { \\\"type\\\": \\\"number\\\" },\\n        \\\"description\\\": { \\\"type\\\": \\\"string\\\" }\\n      },\\n      \\\"required\\\": [\\\"name\\\", \\\"price\\\"]\\n    },\\n    \\\"allowExternalLinks\\\": false,\\n    \\\"enableWebSearch\\\": false,\\n    \\\"includeSubdomains\\\": false\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Extracted structured data as defined by your schema\\n\\n```json\\n{\\n  \\\"content\\\": [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\": {\\n        \\\"name\\\": \\\"Example Product\\\",\\n        \\\"price\\\": 99.99,\\n        \\\"description\\\": \\\"This is an example product description\\\"\\n      }\\n    }\\n  ],\\n  \\\"isError\\\": false\\n}\\n```\\n\\n### 9. Deep Research Tool (`firecrawl_deep_research`)\\n\\nConduct deep web research on a query using intelligent crawling, search, and LLM analysis.\\n\\n**Best for:**\\n- Complex research questions requiring multiple sources, in-depth analysis.\\n\\n**Not recommended for:**\\n- Simple questions that can be answered with a single search\\n- When you need very specific information from a known page (use scrape)\\n- When you need results quickly (deep research can take time)\\n\\n**Arguments:**\\n- query (string, required): The research question or topic to explore.\\n- maxDepth (number, optional): Maximum recursive depth for crawling/search (default: 3).\\n- timeLimit (number, optional): Time limit in seconds for the research session (default: 120).\\n- maxUrls (number, optional): Maximum number of URLs to analyze (default: 50).\\n\\n**Prompt Example:**\\n\\u003e \\\"Research the environmental impact of electric vehicles versus gasoline vehicles.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_deep_research\\\",\\n  \\\"arguments\\\": {\\n    \\\"query\\\": \\\"What are the environmental impacts of electric vehicles compared to gasoline vehicles?\\\",\\n    \\\"maxDepth\\\": 3,\\n    \\\"timeLimit\\\": 120,\\n    \\\"maxUrls\\\": 50\\n  }\\n}\\n```\\n\\n**Returns:**\\n- Final analysis generated by an LLM based on research. (data.finalAnalysis)\\n- May also include structured activities and sources used in the research process.\\n\\n### 10. Generate LLMs.txt Tool (`firecrawl_generate_llmstxt`)\\n\\nGenerate a standardized llms.txt (and optionally llms-full.txt) file for a given domain. This file defines how large language models should interact \\nwith the site.\\n\\n**Best for:**\\n- Creating machine-readable permission guidelines for AI models.\\n\\n**Not recommended for:**\\n- General content extraction or research\\n\\n**Arguments:**\\n- url (string, required): The base URL of the website to analyze.\\n- maxUrls (number, optional): Max number of URLs to include (default: 10).\\n- showFullText (boolean, optional): Whether to include llms-full.txt contents in the response.\\n\\n**Prompt Example:**\\n\\u003e \\\"Generate an LLMs.txt file for example.com.\\\"\\n\\n**Usage Example:**\\n```json\\n{\\n  \\\"name\\\": \\\"firecrawl_generate_llmstxt\\\",\\n  \\\"arguments\"])</script><script>self.__next_f.push([1,\"\\\": {\\n    \\\"url\\\": \\\"https://example.com\\\",\\n    \\\"maxUrls\\\": 20,\\n    \\\"showFullText\\\": true\\n  }\\n}\\n```\\n\\n**Returns:**\\n- LLMs.txt file contents (and optionally llms-full.txt)\\n\\n## Logging System\\n\\nThe server includes comprehensive logging:\\n\\n- Operation status and progress\\n- Performance metrics\\n- Credit usage monitoring\\n- Rate limit tracking\\n- Error conditions\\n\\nExample log messages:\\n\\n```\\n[INFO] Firecrawl MCP Server initialized successfully\\n[INFO] Starting scrape for URL: https://example.com\\n[INFO] Batch operation queued with ID: batch_1\\n[WARNING] Credit usage has reached warning threshold\\n[ERROR] Rate limit exceeded, retrying in 2s...\\n```\\n\\n## Error Handling\\n\\nThe server provides robust error handling:\\n\\n- Automatic retries for transient errors\\n- Rate limit handling with backoff\\n- Detailed error messages\\n- Credit usage warnings\\n- Network resilience\\n\\nExample error response:\\n\\n```json\\n{\\n  \\\"content\\\": [\\n    {\\n      \\\"type\\\": \\\"text\\\",\\n      \\\"text\\\": \\\"Error: Rate limit exceeded. Retrying in 2 seconds...\\\"\\n    }\\n  ],\\n  \\\"isError\\\": true\\n}\\n```\\n\\n## Development\\n\\n```bash\\n# Install dependencies\\nnpm install\\n\\n# Build\\nnpm run build\\n\\n# Run tests\\nnpm test\\n```\\n\\n### Contributing\\n\\n1. Fork the repository\\n2. Create your feature branch\\n3. Run tests: `npm test`\\n4. Submit a pull request\\n\\n### Thanks to contributors\\n\\nThanks to [@vrknetha](https://github.com/vrknetha), [@cawstudios](https://caw.tech) for the initial implementation!\\n\\nThanks to MCP.so and Klavis AI for hosting and [@gstarwd](https://github.com/gstarwd), [@xiangkaiz](https://github.com/xiangkaiz) and [@zihaolin96](https://github.com/zihaolin96) for integrating our server.\\n\\n## License\\n\\nMIT License - see LICENSE file for details76:T59b,## What is Firecrawl MCP Server? \\nFirecrawl MCP Server is an implementation of the Model Context Protocol (MCP) that enhances web scraping capabilities for various LLM clients, including Cursor and Claude.\\n\\n## How to use Firecrawl MCP Server? \\nTo use the Firecrawl MCP Server, you can run it using npx or install it manually via npm. Configuration is required to set up the API key and other environment variables.\\n\\n## Key features of Firecrawl MCP Server? \\n- Powerful web scraping with JavaScript rendering support\\n- Automatic retries with exponential backoff\\n- Efficient batch processing with rate limiting\\n- Comprehensive logging and credit usage monitoring\\n- Support for both cloud and self-hosted instances\\n\\n## Use cases of Firecrawl MCP Server? \\n1. Scraping content from websites for data analysis\\n2. Automating data collection for research purposes\\n3. Extracting structured information from web pages using LLM capabilities\\n\\n## FAQ from Firecrawl MCP Server? \\n- Can I use Firecrawl MCP Server for any website?  \\n\\u003e Yes, as long as the website allows scraping, you can use Firecrawl MCP Server to extract data.\\n\\n- Is there a limit to the number of requests I can make?  \\n\\u003e Yes, there are rate limits in place to prevent overwhelming the server, but you can configure these settings.\\n\\n- How do I monitor my credit usage?  \\n\\u003e The server includes a credit usage monitoring feature that alerts you when you reach specified thresholds.77:T267e,[{\\\"name\\\":\\\"firecrawl_scrape\\\",\\\"description\\\":\\\"Scrape a single webpage with advanced options for content extraction. Supports various formats including markdown, HTML, and screenshots. Can execute custom actions like clicking or scrolling before scraping.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"actions\\\":{\\\"description\\\":\\\"List of actions to perform before scraping\\\",\\\"items\\\":{\\\"properties\\\":{\\\"direction\\\":{\\\"description\\\":\\\"Scroll direction\\\",\\\"enum\\\":[\\\"up\\\",\\\"down\\\"],\\\"type\\\":\\\"string\\\"},\\\"fullPage\\\":{\\\"description\\\":\\\"Take full page screenshot\\\",\\\"type\\\":\\\"boolean\\\"},\\\"key\\\":{\\\"description\\\":\\\"Key to press (for press action)\\\",\\\"type\\\":\\\"string\\\"},\\\"milliseconds\\\":{\\\"description\\\":\\\"Time to wait in milliseconds (for wait action)\\\",\\\"type\\\":\\\"number\\\"},\\\"script\\\":{\\\"description\\\":\\\"JavaScript code to execute\\\",\\\"type\\\":\\\"string\\\"},\\\"selector\\\":{\\\"description\\\":\\\"CSS selector for the target element\\\",\\\"type\\\":\\\"string\\\"},\\\"text\\\":{\\\"description\\\":\\\"Text to write (for write action)\\\",\\\"type\\\":\\\"string\\\"},\\\"type\\\":{\\\"description\\\":\\\"Type of action t\"])</script><script>self.__next_f.push([1,\"o perform\\\",\\\"enum\\\":[\\\"wait\\\",\\\"click\\\",\\\"screenshot\\\",\\\"write\\\",\\\"press\\\",\\\"scroll\\\",\\\"scrape\\\",\\\"executeJavascript\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"type\\\"],\\\"type\\\":\\\"object\\\"},\\\"type\\\":\\\"array\\\"},\\\"excludeTags\\\":{\\\"description\\\":\\\"HTML tags to exclude from extraction\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"extract\\\":{\\\"description\\\":\\\"Configuration for structured data extraction\\\",\\\"properties\\\":{\\\"prompt\\\":{\\\"description\\\":\\\"User prompt for LLM extraction\\\",\\\"type\\\":\\\"string\\\"},\\\"schema\\\":{\\\"description\\\":\\\"Schema for structured data extraction\\\",\\\"type\\\":\\\"object\\\"},\\\"systemPrompt\\\":{\\\"description\\\":\\\"System prompt for LLM extraction\\\",\\\"type\\\":\\\"string\\\"}},\\\"type\\\":\\\"object\\\"},\\\"formats\\\":{\\\"description\\\":\\\"Content formats to extract (default: ['markdown'])\\\",\\\"items\\\":{\\\"enum\\\":[\\\"markdown\\\",\\\"html\\\",\\\"rawHtml\\\",\\\"screenshot\\\",\\\"links\\\",\\\"screenshot@fullPage\\\",\\\"extract\\\"],\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"includeTags\\\":{\\\"description\\\":\\\"HTML tags to specifically include in extraction\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"location\\\":{\\\"description\\\":\\\"Location settings for scraping\\\",\\\"properties\\\":{\\\"country\\\":{\\\"description\\\":\\\"Country code for geolocation\\\",\\\"type\\\":\\\"string\\\"},\\\"languages\\\":{\\\"description\\\":\\\"Language codes for content\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"}},\\\"type\\\":\\\"object\\\"},\\\"mobile\\\":{\\\"description\\\":\\\"Use mobile viewport\\\",\\\"type\\\":\\\"boolean\\\"},\\\"onlyMainContent\\\":{\\\"description\\\":\\\"Extract only the main content, filtering out navigation, footers, etc.\\\",\\\"type\\\":\\\"boolean\\\"},\\\"removeBase64Images\\\":{\\\"description\\\":\\\"Remove base64 encoded images from output\\\",\\\"type\\\":\\\"boolean\\\"},\\\"skipTlsVerification\\\":{\\\"description\\\":\\\"Skip TLS certificate verification\\\",\\\"type\\\":\\\"boolean\\\"},\\\"timeout\\\":{\\\"description\\\":\\\"Maximum time in milliseconds to wait for the page to load\\\",\\\"type\\\":\\\"number\\\"},\\\"url\\\":{\\\"description\\\":\\\"The URL to scrape\\\",\\\"type\\\":\\\"string\\\"},\\\"waitFor\\\":{\\\"description\\\":\\\"Time in milliseconds to wait for dynamic content to load\\\",\\\"type\\\":\\\"number\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"firecrawl_map\\\",\\\"description\\\":\\\"Discover URLs from a starting point. Can use both sitemap.xml and HTML link discovery.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"ignoreSitemap\\\":{\\\"description\\\":\\\"Skip sitemap.xml discovery and only use HTML links\\\",\\\"type\\\":\\\"boolean\\\"},\\\"includeSubdomains\\\":{\\\"description\\\":\\\"Include URLs from subdomains in results\\\",\\\"type\\\":\\\"boolean\\\"},\\\"limit\\\":{\\\"description\\\":\\\"Maximum number of URLs to return\\\",\\\"type\\\":\\\"number\\\"},\\\"search\\\":{\\\"description\\\":\\\"Optional search term to filter URLs\\\",\\\"type\\\":\\\"string\\\"},\\\"sitemapOnly\\\":{\\\"description\\\":\\\"Only use sitemap.xml for discovery, ignore HTML links\\\",\\\"type\\\":\\\"boolean\\\"},\\\"url\\\":{\\\"description\\\":\\\"Starting URL for URL discovery\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"firecrawl_crawl\\\",\\\"description\\\":\\\"Start an asynchronous crawl of multiple pages from a starting URL. Supports depth control, path filtering, and webhook notifications.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"allowBackwardLinks\\\":{\\\"description\\\":\\\"Allow crawling links that point to parent directories\\\",\\\"type\\\":\\\"boolean\\\"},\\\"allowExternalLinks\\\":{\\\"description\\\":\\\"Allow crawling links to external domains\\\",\\\"type\\\":\\\"boolean\\\"},\\\"deduplicateSimilarURLs\\\":{\\\"description\\\":\\\"Remove similar URLs during crawl\\\",\\\"type\\\":\\\"boolean\\\"},\\\"excludePaths\\\":{\\\"description\\\":\\\"URL paths to exclude from crawling\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"ignoreQueryParameters\\\":{\\\"description\\\":\\\"Ignore query parameters when comparing URLs\\\",\\\"type\\\":\\\"boolean\\\"},\\\"ignoreSitemap\\\":{\\\"description\\\":\\\"Skip sitemap.xml discovery\\\",\\\"type\\\":\\\"boolean\\\"},\\\"includePaths\\\":{\\\"description\\\":\\\"Only crawl these URL paths\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"limit\\\":{\\\"description\\\":\\\"Maximum number of pages to crawl\\\",\\\"type\\\":\\\"number\\\"},\\\"maxDepth\\\":{\\\"description\\\":\\\"Maximum link depth to crawl\\\",\\\"type\\\":\\\"number\\\"},\\\"scrapeOptions\\\":{\\\"description\\\":\\\"Options for scraping each page\\\",\\\"properties\\\":{\\\"excludeTags\\\":{\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"formats\\\":{\\\"items\\\":{\\\"enum\\\":[\\\"markdown\\\",\\\"html\\\",\\\"rawHtml\\\",\\\"screenshot\\\",\\\"links\\\",\\\"screenshot@fullPage\\\",\\\"extract\\\"],\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"includeTags\\\":{\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"onlyMainContent\\\":{\\\"type\\\":\\\"boolean\\\"},\\\"waitFor\\\":{\\\"type\\\":\\\"number\\\"}},\\\"type\\\":\\\"object\\\"},\\\"url\\\":{\\\"description\\\":\\\"S\"])</script><script>self.__next_f.push([1,\"tarting URL for the crawl\\\",\\\"type\\\":\\\"string\\\"},\\\"webhook\\\":{\\\"oneOf\\\":[{\\\"description\\\":\\\"Webhook URL to notify when crawl is complete\\\",\\\"type\\\":\\\"string\\\"},{\\\"properties\\\":{\\\"headers\\\":{\\\"description\\\":\\\"Custom headers for webhook requests\\\",\\\"type\\\":\\\"object\\\"},\\\"url\\\":{\\\"description\\\":\\\"Webhook URL\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"],\\\"type\\\":\\\"object\\\"}]}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"firecrawl_batch_scrape\\\",\\\"description\\\":\\\"Scrape multiple URLs in batch mode. Returns a job ID that can be used to check status.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"options\\\":{\\\"properties\\\":{\\\"excludeTags\\\":{\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"formats\\\":{\\\"items\\\":{\\\"enum\\\":[\\\"markdown\\\",\\\"html\\\",\\\"rawHtml\\\",\\\"screenshot\\\",\\\"links\\\",\\\"screenshot@fullPage\\\",\\\"extract\\\"],\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"includeTags\\\":{\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"onlyMainContent\\\":{\\\"type\\\":\\\"boolean\\\"},\\\"waitFor\\\":{\\\"type\\\":\\\"number\\\"}},\\\"type\\\":\\\"object\\\"},\\\"urls\\\":{\\\"description\\\":\\\"List of URLs to scrape\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"urls\\\"]}},{\\\"name\\\":\\\"firecrawl_check_batch_status\\\",\\\"description\\\":\\\"Check the status of a batch scraping job.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"id\\\":{\\\"description\\\":\\\"Batch job ID to check\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"id\\\"]}},{\\\"name\\\":\\\"firecrawl_check_crawl_status\\\",\\\"description\\\":\\\"Check the status of a crawl job.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"id\\\":{\\\"description\\\":\\\"Crawl job ID to check\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"id\\\"]}},{\\\"name\\\":\\\"firecrawl_search\\\",\\\"description\\\":\\\"Search and retrieve content from web pages with optional scraping. Returns SERP results by default (url, title, description) or full page content when scrapeOptions are provided.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"country\\\":{\\\"description\\\":\\\"Country code for search results (default: us)\\\",\\\"type\\\":\\\"string\\\"},\\\"filter\\\":{\\\"description\\\":\\\"Search filter\\\",\\\"type\\\":\\\"string\\\"},\\\"lang\\\":{\\\"description\\\":\\\"Language code for search results (default: en)\\\",\\\"type\\\":\\\"string\\\"},\\\"limit\\\":{\\\"description\\\":\\\"Maximum number of results to return (default: 5)\\\",\\\"type\\\":\\\"number\\\"},\\\"location\\\":{\\\"description\\\":\\\"Location settings for search\\\",\\\"properties\\\":{\\\"country\\\":{\\\"description\\\":\\\"Country code for geolocation\\\",\\\"type\\\":\\\"string\\\"},\\\"languages\\\":{\\\"description\\\":\\\"Language codes for content\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"}},\\\"type\\\":\\\"object\\\"},\\\"query\\\":{\\\"description\\\":\\\"Search query string\\\",\\\"type\\\":\\\"string\\\"},\\\"scrapeOptions\\\":{\\\"description\\\":\\\"Options for scraping search results\\\",\\\"properties\\\":{\\\"formats\\\":{\\\"description\\\":\\\"Content formats to extract from search results\\\",\\\"items\\\":{\\\"enum\\\":[\\\"markdown\\\",\\\"html\\\",\\\"rawHtml\\\"],\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"onlyMainContent\\\":{\\\"description\\\":\\\"Extract only the main content from results\\\",\\\"type\\\":\\\"boolean\\\"},\\\"waitFor\\\":{\\\"description\\\":\\\"Time in milliseconds to wait for dynamic content\\\",\\\"type\\\":\\\"number\\\"}},\\\"type\\\":\\\"object\\\"},\\\"tbs\\\":{\\\"description\\\":\\\"Time-based search filter\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"firecrawl_extract\\\",\\\"description\\\":\\\"Extract structured information from web pages using LLM. Supports both cloud AI and self-hosted LLM extraction.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"allowExternalLinks\\\":{\\\"description\\\":\\\"Allow extraction from external links\\\",\\\"type\\\":\\\"boolean\\\"},\\\"enableWebSearch\\\":{\\\"description\\\":\\\"Enable web search for additional context\\\",\\\"type\\\":\\\"boolean\\\"},\\\"includeSubdomains\\\":{\\\"description\\\":\\\"Include subdomains in extraction\\\",\\\"type\\\":\\\"boolean\\\"},\\\"prompt\\\":{\\\"description\\\":\\\"Prompt for the LLM extraction\\\",\\\"type\\\":\\\"string\\\"},\\\"schema\\\":{\\\"description\\\":\\\"JSON schema for structured data extraction\\\",\\\"type\\\":\\\"object\\\"},\\\"systemPrompt\\\":{\\\"description\\\":\\\"System prompt for LLM extraction\\\",\\\"type\\\":\\\"string\\\"},\\\"urls\\\":{\\\"description\\\":\\\"List of URLs to extract information from\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"urls\\\"]}},{\\\"name\\\":\\\"firecrawl_deep_research\\\",\\\"description\\\":\\\"Conduct deep research on a query using web crawling, search, and AI analysis.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"maxDepth\\\":{\\\"description\\\":\\\"Maximum depth of research iterations (1-10)\\\",\\\"type\\\":\\\"number\\\"},\\\"maxUrls\\\":{\\\"description\\\":\\\"Maximum number of URLs to analyze (1-1000)\\\",\\\"type\\\":\\\"number\\\"},\\\"quer\"])</script><script>self.__next_f.push([1,\"y\\\":{\\\"description\\\":\\\"The query to research\\\",\\\"type\\\":\\\"string\\\"},\\\"timeLimit\\\":{\\\"description\\\":\\\"Time limit in seconds (30-300)\\\",\\\"type\\\":\\\"number\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"firecrawl_generate_llmstxt\\\",\\\"description\\\":\\\"Generate standardized LLMs.txt file for a given URL, which provides context about how LLMs should interact with the website.\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"maxUrls\\\":{\\\"description\\\":\\\"Maximum number of URLs to process (1-100, default: 10)\\\",\\\"type\\\":\\\"number\\\"},\\\"showFullText\\\":{\\\"description\\\":\\\"Whether to show the full LLMs-full.txt in the response\\\",\\\"type\\\":\\\"boolean\\\"},\\\"url\\\":{\\\"description\\\":\\\"The URL to generate LLMs.txt from\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}}]78:Tbb2,# Puppeteer\\r\\n\\r\\nA Model Context Protocol server that provides browser automation capabilities using Puppeteer. This server enables LLMs to interact with web pages, take screenshots, and execute JavaScript in a real browser environment.\\r\\n\\r\\n## Components\\r\\n\\r\\n### Tools\\r\\n\\r\\n- **puppeteer_navigate**\\r\\n  - Navigate to any URL in the browser\\r\\n  - Input: `url` (string)\\r\\n\\r\\n- **puppeteer_screenshot**\\r\\n  - Capture screenshots of the entire page or specific elements\\r\\n  - Inputs:\\r\\n    - `name` (string, required): Name for the screenshot\\r\\n    - `selector` (string, optional): CSS selector for element to screenshot\\r\\n    - `width` (number, optional, default: 800): Screenshot width\\r\\n    - `height` (number, optional, default: 600): Screenshot height\\r\\n\\r\\n- **puppeteer_click**\\r\\n  - Click elements on the page\\r\\n  - Input: `selector` (string): CSS selector for element to click\\r\\n\\r\\n- **puppeteer_hover**\\r\\n  - Hover elements on the page\\r\\n  - Input: `selector` (string): CSS selector for element to hover\\r\\n\\r\\n- **puppeteer_fill**\\r\\n  - Fill out input fields\\r\\n  - Inputs:\\r\\n    - `selector` (string): CSS selector for input field\\r\\n    - `value` (string): Value to fill\\r\\n\\r\\n- **puppeteer_select**\\r\\n  - Select an element with SELECT tag\\r\\n  - Inputs:\\r\\n    - `selector` (string): CSS selector for element to select\\r\\n    - `value` (string): Value to select\\r\\n\\r\\n- **puppeteer_evaluate**\\r\\n  - Execute JavaScript in the browser console\\r\\n  - Input: `script` (string): JavaScript code to execute\\r\\n\\r\\n### Resources\\r\\n\\r\\nThe server provides access to two types of resources:\\r\\n\\r\\n1. **Console Logs** (`console://logs`)\\r\\n   - Browser console output in text format\\r\\n   - Includes all console messages from the browser\\r\\n\\r\\n2. **Screenshots** (`screenshot://\\u003cname\\u003e`)\\r\\n   - PNG images of captured screenshots\\r\\n   - Accessible via the screenshot name specified during capture\\r\\n\\r\\n## Key Features\\r\\n\\r\\n- Browser automation\\r\\n- Console log monitoring\\r\\n- Screenshot capabilities\\r\\n- JavaScript execution\\r\\n- Basic web interaction (navigation, clicking, form filling)\\r\\n\\r\\n## Configuration to use Puppeteer Server\\r\\nHere's the Claude Desktop configuration to use the Puppeter server:\\r\\n\\r\\n### Docker\\r\\n\\r\\n**NOTE** The docker implementation will use headless chromium, where as the NPX version will open a browser window.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"puppeteer\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"--init\\\", \\\"-e\\\", \\\"DOCKER_CONTAINER=true\\\", \\\"mcp/puppeteer\\\"]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"puppeteer\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\\"-y\\\", \\\"@modelcontextprotocol/server-puppeteer\\\"]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Build\\r\\n\\r\\nDocker build:\\r\\n\\r\\n```bash\\r\\ndocker build -t mcp/puppeteer -f src/puppeteer/Dockerfile .\\r\\n```\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.79:T546,## what is Puppeteer? \\nPuppeteer is a Model Context Protocol server that provides browser automation capabilities, allowing LLMs to interact with web pages, take screenshots, and execute JavaScript in a real browser environment.\\n\\n## how to use Puppeteer? \\nTo use Puppeteer, configure your machine as specified in the provided configuration JSON and interact with the server via its various tools for nav\"])</script><script>self.__next_f.push([1,\"igation, screenshots, and web interactions.\\n\\n## key features of Puppeteer? \\n- Browser automation for web scraping and interaction\\n- Capture screenshots of web pages or individual elements\\n- Console log monitoring to track browser activities\\n- Execute JavaScript commands in the browser\\n- Support for basic interactions like clicking and form filling\\n\\n## use cases of Puppeteer? \\n1. Automating data collection from websites for analysis\\n2. Testing web applications by simulating user interactions\\n3. Taking screenshots for documentation and reporting purposes\\n\\n## FAQ from Puppeteer? \\n- What can Puppeteer automate?  \\n\\u003e Puppeteer can automate various web interactions such as navigation, form filling, and element clicks.\\n\\n- Is there any cost to use Puppeteer?  \\n\\u003e No, Puppeteer is free to use under the MIT License.\\n\\n- How do I install Puppeteer?  \\n\\u003e You can install Puppeteer by running the specified command in the project's configuration setup.7a:T758,[{\\\"name\\\":\\\"puppeteer_navigate\\\",\\\"description\\\":\\\"Navigate to a URL\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"url\\\":{\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"puppeteer_screenshot\\\",\\\"description\\\":\\\"Take a screenshot of the current page or a specific element\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"height\\\":{\\\"description\\\":\\\"Height in pixels (default: 600)\\\",\\\"type\\\":\\\"number\\\"},\\\"name\\\":{\\\"description\\\":\\\"Name for the screenshot\\\",\\\"type\\\":\\\"string\\\"},\\\"selector\\\":{\\\"description\\\":\\\"CSS selector for element to screenshot\\\",\\\"type\\\":\\\"string\\\"},\\\"width\\\":{\\\"description\\\":\\\"Width in pixels (default: 800)\\\",\\\"type\\\":\\\"number\\\"}},\\\"required\\\":[\\\"name\\\"]}},{\\\"name\\\":\\\"puppeteer_click\\\",\\\"description\\\":\\\"Click an element on the page\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"selector\\\":{\\\"description\\\":\\\"CSS selector for element to click\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"selector\\\"]}},{\\\"name\\\":\\\"puppeteer_fill\\\",\\\"description\\\":\\\"Fill out an input field\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"selector\\\":{\\\"description\\\":\\\"CSS selector for input field\\\",\\\"type\\\":\\\"string\\\"},\\\"value\\\":{\\\"description\\\":\\\"Value to fill\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"selector\\\",\\\"value\\\"]}},{\\\"name\\\":\\\"puppeteer_select\\\",\\\"description\\\":\\\"Select an element on the page with Select tag\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"selector\\\":{\\\"description\\\":\\\"CSS selector for element to select\\\",\\\"type\\\":\\\"string\\\"},\\\"value\\\":{\\\"description\\\":\\\"Value to select\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"selector\\\",\\\"value\\\"]}},{\\\"name\\\":\\\"puppeteer_hover\\\",\\\"description\\\":\\\"Hover an element on the page\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"selector\\\":{\\\"description\\\":\\\"CSS selector for element to hover\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"selector\\\"]}},{\\\"name\\\":\\\"puppeteer_evaluate\\\",\\\"description\\\":\\\"Execute JavaScript in the browser console\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"script\\\":{\\\"description\\\":\\\"JavaScript code to execute\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"script\\\"]}}]7b:T7dc,# Redis\\r\\n\\r\\nA Model Context Protocol server that provides access to Redis databases. This server enables LLMs to interact with Redis key-value stores through a set of standardized tools.\\r\\n\\r\\n## Components\\r\\n\\r\\n### Tools\\r\\n\\r\\n- **set**\\r\\n  - Set a Redis key-value pair with optional expiration\\r\\n  - Input:\\r\\n    - `key` (string): Redis key\\r\\n    - `value` (string): Value to store\\r\\n    - `expireSeconds` (number, optional): Expiration time in seconds\\r\\n\\r\\n- **get**\\r\\n  - Get value by key from Redis\\r\\n  - Input: `key` (string): Redis key to retrieve\\r\\n\\r\\n- **delete**\\r\\n  - Delete one or more keys from Redis\\r\\n  - Input: `key` (string | string[]): Key or array of keys to delete\\r\\n\\r\\n- **list**\\r\\n  - List Redis keys matching a pattern\\r\\n  - Input: `pattern` (string, optional): Pattern to match keys (default: *)\\r\\n\\r\\n## Usage with Claude Desktop\\r\\n\\r\\nTo use this server with the Claude Desktop app, add the following configuration to the \\\"mcpServers\\\" section of your `claude_desktop_config.json`:\\r\\n\\r\\n### Docker\\r\\n\\r\\n* when running docker on macos, use host.docker.internal if the server is running on the host network (eg localhost)\\r\\n* Redis URL can be specified as an argument, defaults to \\\"redis://localhost:6379\\\"\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"redis\\\": {\\r\\n      \\\"comm\"])</script><script>self.__next_f.push([1,\"and\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"run\\\", \\r\\n        \\\"-i\\\", \\r\\n        \\\"--rm\\\", \\r\\n        \\\"mcp/redis\\\", \\r\\n        \\\"redis://host.docker.internal:6379\\\"]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"redis\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-redis\\\",\\r\\n        \\\"redis://localhost:6379\\\"\\r\\n      ]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Building\\r\\n\\r\\nDocker:\\r\\n\\r\\n```sh\\r\\ndocker build -t mcp/redis -f src/redis/Dockerfile . \\r\\n```\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.7c:T432,## what is Redis? \\nRedis is a Model Context Protocol server that provides access to Redis databases, enabling LLMs to interact with Redis key-value stores through standardized tools.\\n\\n## how to use Redis? \\nTo use Redis, configure it in the \\\"mcpServers\\\" section of your `claude_desktop_config.json` or run it using Docker or NPX commands as specified in the documentation.\\n\\n## key features of Redis? \\n- Set, get, delete, and list operations for Redis key-value pairs.\\n- Supports optional expiration for keys.\\n- Easy integration with Claude Desktop and Docker.\\n\\n## use cases of Redis? \\n1. Storing and retrieving user session data.\\n2. Caching frequently accessed data for faster retrieval.\\n3. Managing real-time data feeds in applications.\\n\\n## FAQ from Redis? \\n- What is the default Redis URL?\\n\\u003e The default Redis URL is \\\"redis://localhost:6379\\\".\\n\\n- Can I run Redis in a Docker container?\\n\\u003e Yes! You can run Redis using Docker with the provided command.\\n\\n- Is Redis open source?\\n\\u003e Yes! Redis is licensed under the MIT License, allowing free use, modification, and distribution.7d:Tf77,[{\\\"name\\\":\\\"hmset\\\",\\\"description\\\":\\\"Set multiple hash fields to multiple values\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"fields\\\":{\\\"additionalProperties\\\":{\\\"type\\\":\\\"string\\\"},\\\"description\\\":\\\"Field-value pairs to set\\\",\\\"type\\\":\\\"object\\\"},\\\"key\\\":{\\\"description\\\":\\\"Hash key\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\",\\\"fields\\\"]}},{\\\"name\\\":\\\"hget\\\",\\\"description\\\":\\\"Get the value of a hash field\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"field\\\":{\\\"description\\\":\\\"Field to get\\\",\\\"type\\\":\\\"string\\\"},\\\"key\\\":{\\\"description\\\":\\\"Hash key\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\",\\\"field\\\"]}},{\\\"name\\\":\\\"hgetall\\\",\\\"description\\\":\\\"Get all the fields and values in a hash\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Hash key\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\"]}},{\\\"name\\\":\\\"scan\\\",\\\"description\\\":\\\"Scan Redis keys matching a pattern\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"count\\\":{\\\"description\\\":\\\"Number of keys to return per iteration (optional)\\\",\\\"minimum\\\":1,\\\"type\\\":\\\"number\\\"},\\\"pattern\\\":{\\\"description\\\":\\\"Pattern to match (e.g., \\\\\\\"user:*\\\\\\\" or \\\\\\\"schedule:*\\\\\\\")\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"pattern\\\"]}},{\\\"name\\\":\\\"set\\\",\\\"description\\\":\\\"Set string value with optional NX (only if not exists) and PX (expiry in milliseconds) options\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Key to set\\\",\\\"type\\\":\\\"string\\\"},\\\"nx\\\":{\\\"description\\\":\\\"Only set if key does not exist\\\",\\\"type\\\":\\\"boolean\\\"},\\\"px\\\":{\\\"description\\\":\\\"Set expiry in milliseconds\\\",\\\"type\\\":\\\"number\\\"},\\\"value\\\":{\\\"description\\\":\\\"Value to set\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\",\\\"value\\\"]}},{\\\"name\\\":\\\"get\\\",\\\"description\\\":\\\"Get string value\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Key to get\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\"]}},{\\\"name\\\":\\\"del\\\",\\\"description\\\":\\\"Delete a key\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Key to delete\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\"]}},{\\\"name\\\":\\\"zadd\\\",\\\"description\\\":\\\"Add one or more members to a sorted set\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Sorted set key\\\",\\\"type\\\":\\\"string\\\"},\\\"members\\\":{\\\"description\\\":\\\"Array of score-value pairs to add\\\",\\\"items\\\":{\\\"properties\\\":{\\\"score\\\":{\\\"description\\\":\\\"Score for the member\\\",\\\"type\\\":\\\"number\\\"},\\\"value\\\":{\\\"description\\\":\\\"Member value\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"score\\\",\\\"\"])</script><script>self.__next_f.push([1,\"value\\\"],\\\"type\\\":\\\"object\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"key\\\",\\\"members\\\"]}},{\\\"name\\\":\\\"zrange\\\",\\\"description\\\":\\\"Return a range of members from a sorted set by index\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Sorted set key\\\",\\\"type\\\":\\\"string\\\"},\\\"start\\\":{\\\"description\\\":\\\"Start index (0-based)\\\",\\\"type\\\":\\\"number\\\"},\\\"stop\\\":{\\\"description\\\":\\\"Stop index (inclusive)\\\",\\\"type\\\":\\\"number\\\"},\\\"withScores\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Include scores in output\\\",\\\"type\\\":\\\"boolean\\\"}},\\\"required\\\":[\\\"key\\\",\\\"start\\\",\\\"stop\\\"]}},{\\\"name\\\":\\\"zrangebyscore\\\",\\\"description\\\":\\\"Return members from a sorted set with scores between min and max\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Sorted set key\\\",\\\"type\\\":\\\"string\\\"},\\\"max\\\":{\\\"description\\\":\\\"Maximum score\\\",\\\"type\\\":\\\"number\\\"},\\\"min\\\":{\\\"description\\\":\\\"Minimum score\\\",\\\"type\\\":\\\"number\\\"},\\\"withScores\\\":{\\\"default\\\":false,\\\"description\\\":\\\"Include scores in output\\\",\\\"type\\\":\\\"boolean\\\"}},\\\"required\\\":[\\\"key\\\",\\\"min\\\",\\\"max\\\"]}},{\\\"name\\\":\\\"zrem\\\",\\\"description\\\":\\\"Remove one or more members from a sorted set\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Sorted set key\\\",\\\"type\\\":\\\"string\\\"},\\\"members\\\":{\\\"description\\\":\\\"Array of members to remove\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"key\\\",\\\"members\\\"]}},{\\\"name\\\":\\\"sadd\\\",\\\"description\\\":\\\"Add one or more members to a set\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Set key\\\",\\\"type\\\":\\\"string\\\"},\\\"members\\\":{\\\"description\\\":\\\"Members to add to the set\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"}},\\\"required\\\":[\\\"key\\\",\\\"members\\\"]}},{\\\"name\\\":\\\"smembers\\\",\\\"description\\\":\\\"Get all members in a set\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"key\\\":{\\\"description\\\":\\\"Set key\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"key\\\"]}}]7e:T1018,\\\\# Filesystem MCP Server\\r\\n\\r\\nNode.js server implementing Model Context Protocol (MCP) for filesystem operations.\\r\\n\\r\\n## Features\\r\\n\\r\\n- Read/write files\\r\\n- Create/list/delete directories\\r\\n- Move files/directories\\r\\n- Search files\\r\\n- Get file metadata\\r\\n\\r\\n\\\\*\\\\*Note\\\\*\\\\*: The server will only allow operations within directories specified via \\\\`args\\\\`.\\r\\n\\r\\n## API\\r\\n\\r\\n### Resources\\r\\n\\r\\n- \\\\`file://system\\\\`: File system operations interface\\r\\n\\r\\n### Tools\\r\\n\\r\\n- \\\\*\\\\*read\\\\_file\\\\*\\\\*\\r\\n  - Read complete contents of a file\\r\\n  - Input: \\\\`path\\\\` (string)\\r\\n  - Reads complete file contents with UTF-8 encoding\\r\\n\\r\\n- \\\\*\\\\*read\\\\_multiple\\\\_files\\\\*\\\\*\\r\\n  - Read multiple files simultaneously\\r\\n  - Input: \\\\`paths\\\\` (string\\\\[\\\\])\\r\\n  - Failed reads won't stop the entire operation\\r\\n\\r\\n- \\\\*\\\\*write\\\\_file\\\\*\\\\*\\r\\n  - Create new file or overwrite existing (exercise caution with this)\\r\\n  - Inputs:\\r\\n    - \\\\`path\\\\` (string): File location\\r\\n    - \\\\`content\\\\` (string): File content\\r\\n\\r\\n- \\\\*\\\\*edit\\\\_file\\\\*\\\\*\\r\\n  - Make selective edits using advanced pattern matching and formatting\\r\\n  - Features:\\r\\n    - Line-based and multi-line content matching\\r\\n    - Whitespace normalization with indentation preservation\\r\\n    - Fuzzy matching with confidence scoring\\r\\n    - Multiple simultaneous edits with correct positioning\\r\\n    - Indentation style detection and preservation\\r\\n    - Git-style diff output with context\\r\\n    - Preview changes with dry run mode\\r\\n    - Failed match debugging with confidence scores\\r\\n  - Inputs:\\r\\n    - \\\\`path\\\\` (string): File to edit\\r\\n    - \\\\`edits\\\\` (array): List of edit operations\\r\\n      - \\\\`oldText\\\\` (string): Text to search for (can be substring)\\r\\n      - \\\\`newText\\\\` (string): Text to replace with\\r\\n    - \\\\`dryRun\\\\` (boolean): Preview changes without applying (default: false)\\r\\n    - \\\\`options\\\\` (object): Optional formatting settings\\r\\n      - \\\\`preserveIndentation\\\\` (boolean): Keep existing indentation (default: true)\\r\\n      - \\\\`normalizeWhitespace\\\\` (boolean): Normalize spaces while preserving structure (default: true)\\r\\n      - \\\\`partialMatch\\\\` (boolean): Enable fuzzy matching (default: true)\\r\\n  - Returns detailed diff and match information for dry runs, otherwise applies changes\\r\\n  - Best Practice: Always use dryRun first to preview changes before applying them\\r\\n\\r\\n- \\\\*\\\\*create\\\\_directory\\\\*\\\\*\\r\\n  - Create new directory or ensure it exists\\r\\n  - Input: \\\\`path\\\\` (string)\\r\\n  - Creates \"])</script><script>self.__next_f.push([1,\"parent directories if needed\\r\\n  - Succeeds silently if directory exists\\r\\n\\r\\n- \\\\*\\\\*list\\\\_directory\\\\*\\\\*\\r\\n  - List directory contents with \\\\[FILE\\\\] or \\\\[DIR\\\\] prefixes\\r\\n  - Input: \\\\`path\\\\` (string)\\r\\n\\r\\n- \\\\*\\\\*move\\\\_file\\\\*\\\\*\\r\\n  - Move or rename files and directories\\r\\n  - Inputs:\\r\\n    - \\\\`source\\\\` (string)\\r\\n    - \\\\`destination\\\\` (string)\\r\\n  - Fails if destination exists\\r\\n\\r\\n- \\\\*\\\\*search\\\\_files\\\\*\\\\*\\r\\n  - Recursively search for files/directories\\r\\n  - Inputs:\\r\\n    - \\\\`path\\\\` (string): Starting directory\\r\\n    - \\\\`pattern\\\\` (string): Search pattern\\r\\n    - \\\\`excludePatterns\\\\` (string\\\\[\\\\]): Exclude any patterns. Glob formats are supported.\\r\\n  - Case-insensitive matching\\r\\n  - Returns full paths to matches\\r\\n\\r\\n- \\\\*\\\\*get\\\\_file\\\\_info\\\\*\\\\*\\r\\n  - Get detailed file/directory metadata\\r\\n  - Input: \\\\`path\\\\` (string)\\r\\n  - Returns:\\r\\n    - Size\\r\\n    - Creation time\\r\\n    - Modified time\\r\\n    - Access time\\r\\n    - Type (file/directory)\\r\\n    - Permissions\\r\\n\\r\\n- \\\\*\\\\*list\\\\_allowed\\\\_directories\\\\*\\\\*\\r\\n  - List all directories the server is allowed to access\\r\\n  - No input required\\r\\n  - Returns:\\r\\n    - Directories that this server can read/write from\\r\\n\\r\\n## Usage with Claude Desktop\\r\\nAdd this to your \\\\`claude\\\\_desktop\\\\_config.json\\\\`:\\r\\n\\\\`\\\\`\\\\`json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"filesystem\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": \\\\[\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-filesystem\\\",\\r\\n        \\\"/Users/username/Desktop\\\",\\r\\n        \\\"/path/to/other/allowed/dir\\\"\\r\\n      \\\\]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n\\\\`\\\\`\\\\`\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.7f:T4ab,## What is Filesystem? \\nFilesystem is a Node.js server implementing the Model Context Protocol (MCP) for secure file operations with configurable access controls. \\n\\n## How to use Filesystem? \\nTo use Filesystem, configure your server settings in the `claude_desktop_config.json` file to specify the command and allowed directories for operations. \\n\\n## Key features of Filesystem? \\n- Read/write files and directories\\n- Create, list, delete, or move directories\\n- Search for files with pattern matching\\n- Retrieve detailed file metadata\\n- Access control to limit operations to specified directories \\n\\n## Use cases of Filesystem? \\n1. Managing files and directories in a secure environment.\\n2. Implementing custom file operations in applications.\\n3. Conducting bulk file edits and operations using advanced patterns.\\n\\n## FAQ from Filesystem? \\n- Is Filesystem secure? \\n\\u003e Yes, it has configurable access controls that restrict file operations to specified directories.\\n\\n- Can multiple files be read at once? \\n\\u003e Yes, you can read multiple files simultaneously without halting on errors.\\n\\n- What happens if I try to move a file to an existing destination? \\n\\u003e The operation will fail to prevent data loss.80:T2770,# Search1API MCP Server\\r\\n\\r\\n[\u4e2d\u6587\u6587\u6863](./README_zh.md)\\r\\n\\r\\nA Model Context Protocol (MCP) server that provides search and crawl functionality using Search1API.\\r\\n\\r\\n## Prerequisites\\r\\n\\r\\n- Node.js \\u003e= 18.0.0\\r\\n- A valid Search1API API key (See **Setup Guide** below on how to obtain and configure)\\r\\n\\r\\n## Installation (Standalone / General)\\r\\n\\r\\n1.  **Clone the repository:**\\r\\n    ```bash\\r\\n    git clone https://github.com/fatwang2/search1api-mcp.git\\r\\n    cd search1api-mcp\\r\\n    ```\\r\\n\\r\\n2.  **Configure API Key:** Before building, you need to provide your Search1API key. See the **Setup Guide** section below for different methods (e.g., using a `.env` file or environment variables).\\r\\n\\r\\n3.  **Install dependencies and build:**\\r\\n    ```bash\\r\\n    npm install\\r\\n    npm run build\\r\\n    ```\\r\\n    *Note: If using the project's `.env` file method for the API key, ensure it exists before this step.*\\r\\n\\r\\n## Usage (Standalone / General)\\r\\n\\r\\nEnsure your API key is configured (see **Setup Guide**).\\r\\n\\r\\nStart the server:\\r\\n```bash\\r\\nnpm start\\r\\n```\\r\\n\\r\\nThe server will then be ready to accept connections from MCP clients.\\r\\n\\r\\n## Setup Guide\\r\\n\\r\\n### 1. Get Search1\"])</script><script>self.__next_f.push([1,\"API Key\\r\\n\\r\\n1.  Register at [Search1API](https://www.search1api.com/?utm_source=mcp)\\r\\n2.  Get your API key from your dashboard.\\r\\n\\r\\n### 2. Configure API Key\\r\\n\\r\\nYou need to make your API key available to the server. Choose **one** of the following methods:\\r\\n\\r\\n**Method A: Project `.env` File (Recommended for Standalone or LibreChat)**\\r\\n\\r\\nThis method is required if integrating with the current version of LibreChat (see specific section below).\\r\\n\\r\\n1.  In the `search1api-mcp` project root directory, create a file named `.env`:\\r\\n    ```bash\\r\\n    # In the search1api-mcp directory\\r\\n    echo \\\"SEARCH1API_KEY=your_api_key_here\\\" \\u003e .env\\r\\n    ```\\r\\n2.  Replace `your_api_key_here` with your actual key.\\r\\n3.  Make sure this file exists **before** running `npm install \\u0026\\u0026 npm run build`.\\r\\n\\r\\n**Method B: Environment Variable (Standalone Only)**\\r\\n\\r\\nSet the `SEARCH1API_KEY` environment variable before starting the server.\\r\\n\\r\\n```bash\\r\\nexport SEARCH1API_KEY=\\\"your_api_key_here\\\"\\r\\nnpm start\\r\\n```\\r\\n\\r\\n**Method C: MCP Client Configuration (Advanced)**\\r\\n\\r\\nSome MCP clients allow specifying environment variables directly in their configuration. This is useful for clients like Cursor, VS Code extensions, etc.\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"search1api\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"search1api-mcp\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"SEARCH1API_KEY\\\": \\\"YOUR_SEARCH1API_KEY\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n**Note for LibreChat Users:** Due to current limitations in LibreChat, Method A (Project `.env` File) is the **required** method. See the dedicated integration section below for full instructions.\\r\\n\\r\\n## Integration with LibreChat (Docker)\\r\\n\\r\\nThis section details the required steps for integrating with LibreChat via Docker.\\r\\n\\r\\n**Overview:**\\r\\n\\r\\n1.  Clone this server's repository into a location accessible by your LibreChat `docker-compose.yml`.\\r\\n2.  Configure the required API key using the **Project `.env` File method** within this server's directory.\\r\\n3.  Build this server.\\r\\n4.  Tell LibreChat how to run this server by editing `librechat.yaml`.\\r\\n5.  Make sure the built server code is available inside the LibreChat container via a Docker volume bind.\\r\\n6.  Restart LibreChat.\\r\\n\\r\\n**Step-by-Step:**\\r\\n\\r\\n1.  **Clone the Repository:**\\r\\n    Navigate to the directory on your host machine where you manage external services for LibreChat (this is often alongside your `docker-compose.yml`). A common location is a dedicated `mcp-server` directory.\\r\\n    ```bash\\r\\n    # Example: Navigate to where docker-compose.yml lives, then into mcp-server\\r\\n    cd /path/to/your/librechat/setup/mcp-server\\r\\n    git clone https://github.com/fatwang2/search1api-mcp.git\\r\\n    ```\\r\\n\\r\\n2.  **Navigate into the Server Directory:**\\r\\n    ```bash\\r\\n    cd search1api-mcp\\r\\n    ```\\r\\n\\r\\n3.  **Configure API Key (Project `.env` File Method - Required for LibreChat):**\\r\\n    ```bash\\r\\n    # Create the .env file\\r\\n    echo \\\"SEARCH1API_KEY=your_api_key_here\\\" \\u003e .env\\r\\n    # IMPORTANT: Replace 'your_api_key_here' with your actual Search1API key\\r\\n    ```\\r\\n\\r\\n4.  **Install Dependencies and Build:**\\r\\n    This step compiles the server code into the `build` directory.\\r\\n    ```bash\\r\\n    npm install\\r\\n    npm run build\\r\\n    ```\\r\\n\\r\\n5.  **Configure `librechat.yaml`:**\\r\\n    Edit your main `librechat.yaml` file to tell LibreChat how to execute this MCP server. Add an entry under `mcp_servers`:\\r\\n    ```yaml\\r\\n    # In your main librechat.yaml\\r\\n    mcp_servers:\\r\\n      # You can add other MCP servers here too\\r\\n      search1api:\\r\\n        # Optional: Display name for the server in LibreChat UI\\r\\n        # name: Search1API Tools\\r\\n\\r\\n        # Command tells LibreChat to use 'node'\\r\\n        command: node\\r\\n\\r\\n        # Args specify the script for 'node' to run *inside the container*\\r\\n        args:\\r\\n          - /app/mcp-server/search1api-mcp/build/index.js\\r\\n    ```\\r\\n    *   The `args` path (`/app/...`) is the location *inside* the LibreChat API container where the built server will be accessed (thanks to the volume bind in the next step).\\r\\n\\r\\n6.  **Configure Docker Volume Bind:**\\r\\n    Edit your `docker-co\"])</script><script>self.__next_f.push([1,\"mpose.yml` (or more likely, your `docker-compose.override.yml`) to map the `search1api-mcp` directory from your host machine into the LibreChat API container. Find the `volumes:` section for the `api:` service:\\r\\n    ```yaml\\r\\n    # In your docker-compose.yml or docker-compose.override.yml\\r\\n    services:\\r\\n      api:\\r\\n        # ... other service config ...\\r\\n        volumes:\\r\\n          # ... other volumes likely exist here ...\\r\\n\\r\\n          # Add this volume bind:\\r\\n          - ./mcp-server/search1api-mcp:/app/mcp-server/search1api-mcp\\r\\n    ```\\r\\n    *   **Host Path (`./mcp-server/search1api-mcp`):** This is the path on your host machine *relative* to where your `docker-compose.yml` file is located. Adjust it if you cloned the repo elsewhere.\\r\\n    *   **Container Path (`:/app/mcp-server/search1api-mcp`):** This is the path *inside* the container. It **must match** the directory structure used in the `librechat.yaml` `args` path.\\r\\n\\r\\n7.  **Restart LibreChat:**\\r\\n    Apply the changes by rebuilding (if you modified `docker-compose.yml`) and restarting your LibreChat stack.\\r\\n    ```bash\\r\\n    docker compose down \\u0026\\u0026 docker compose up -d --build\\r\\n    # Or: docker compose restart api (if only librechat.yaml changed)\\r\\n    ```\\r\\n\\r\\nNow, the Search1API server should be available as a tool provider within LibreChat.\\r\\n\\r\\n## Features\\r\\n\\r\\n- Web search functionality\\r\\n- News search functionality\\r\\n- Web page content extraction\\r\\n- Website sitemap extraction\\r\\n- Deep thinking and complex problem solving with DeepSeek R1\\r\\n- Seamless integration with Claude Desktop, Cursor, Windsurf, Cline and other MCP clients\\r\\n\\r\\n## Tools\\r\\n\\r\\n### 1. Search Tool\\r\\n- Name: `search`\\r\\n- Description: Search the web using Search1API\\r\\n- Parameters:\\r\\n  * `query` (required): Search query in natural language. Be specific and concise for better results\\r\\n  * `max_results` (optional, default: 10): Number of results to return\\r\\n  * `search_service` (optional, default: \\\"google\\\"): Search service to use (google, bing, duckduckgo, yahoo, x, reddit, github, youtube, arxiv, wechat, bilibili, imdb, wikipedia)\\r\\n  * `crawl_results` (optional, default: 0): Number of results to crawl for full webpage content\\r\\n  * `include_sites` (optional): List of sites to include in search\\r\\n  * `exclude_sites` (optional): List of sites to exclude from search\\r\\n  * `time_range` (optional): Time range for search results (\\\"day\\\", \\\"month\\\", \\\"year\\\")\\r\\n\\r\\n### 2. News Tool\\r\\n- Name: `news`\\r\\n- Description: Search for news articles using Search1API\\r\\n- Parameters:\\r\\n  * `query` (required): Search query in natural language. Be specific and concise for better results\\r\\n  * `max_results` (optional, default: 10): Number of results to return\\r\\n  * `search_service` (optional, default: \\\"bing\\\"): Search service to use (google, bing, duckduckgo, yahoo, hackernews)\\r\\n  * `crawl_results` (optional, default: 0): Number of results to crawl for full webpage content\\r\\n  * `include_sites` (optional): List of sites to include in search\\r\\n  * `exclude_sites` (optional): List of sites to exclude from search\\r\\n  * `time_range` (optional): Time range for search results (\\\"day\\\", \\\"month\\\", \\\"year\\\")\\r\\n\\r\\n### 3. Crawl Tool\\r\\n- Name: `crawl`\\r\\n- Description: Extract content from a URL using Search1API\\r\\n- Parameters:\\r\\n  * `url` (required): URL to crawl\\r\\n\\r\\n### 4. Sitemap Tool\\r\\n- Name: `sitemap`\\r\\n- Description: Get all related links from a URL\\r\\n- Parameters:\\r\\n  * `url` (required): URL to get sitemap\\r\\n\\r\\n### 5. Reasoning Tool\\r\\n- Name: `reasoning`\\r\\n- Description: A tool for deep thinking and complex problem solving with fast deepseek r1 model and web search ability(You can change to any other model in search1api website but the speed is not guaranteed)\\r\\n- Parameters:\\r\\n  * `content` (required): The question or problem that needs deep thinking\\r\\n\\r\\n### 6. Trending Tool\\r\\n- Name: `trending`\\r\\n- Description: Get trending topics from popular platforms\\r\\n- Parameters:\\r\\n  * `search_service` (required): Specify the platform to get trending topics from (github, hackernews)\\r\\n  * `max_results` (optional, default: 10): Maximum number of trending items to return\\r\\n\\r\\n## Version History\\r\\n\\r\\n- v0.\"])</script><script>self.__next_f.push([1,\"2.0: Added fallback `.env` support for LibreChat integration and updated dependencies.\\r\\n- v0.1.8: Added X(Twitter) and Reddit search services\\r\\n- v0.1.7: Added Trending tool for GitHub and Hacker News\\r\\n- v0.1.6: Added Wikipedia search service\\r\\n- v0.1.5: Added new search parameters (include_sites, exclude_sites, time_range) and new search services (arxiv, wechat, bilibili, imdb)\\r\\n- v0.1.4: Added reasoning tool with deepseek r1 and updated the Cursor and Windsurf configuration guide\\r\\n- v0.1.3: Added news search functionality\\r\\n- v0.1.2: Added sitemap functionality\\r\\n- v0.1.1: Added web crawling functionality\\r\\n- v0.1.0: Initial release with search functionality\\r\\n\\r\\n## License\\r\\n\\r\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\r\\n81:T577,## what is Search1API? \\nSearch1API is an API that provides integrated functionalities for web search, crawling, and sitemap extraction.\\n\\n## how to use Search1API? \\nTo use Search1API, first register on the website to get your API key. Then, you can utilize various tools to perform searches, crawl web pages, or extract sitemaps by sending requests with the required parameters.\\n\\n## key features of Search1API? \\n- Comprehensive web search functionality\\n- Ability to search news articles\\n- Extracting content from specific URLs\\n- Generating sitemaps from provided URLs\\n- Seamless integration with Claude Desktop\\n\\n## use cases of Search1API? \\n1. Searching for information relevant to a specific topic on the web.\\n2. Extracting news articles for real-time updates.\\n3. Crawling a target URL to gather content for analysis.\\n4. Generating a sitemap to understand web structure for SEO purposes.\\n\\n## FAQ from Search1API? \\n- How do I obtain an API key for Search1API?\\n\\u003e You can obtain an API key by registering on the Search1API website and selecting a pricing plan.\\n\\n- Is there a free trial available?\\n\\u003e Yes! Search1API offers a pricing plan starting from $0.99, which allows users to explore its functionalities.\\n\\n- What programming languages can I use with Search1API?\\n\\u003e Search1API can be accessed through any programming language that supports HTTP requests, making it versatile for various applications.82:Te02,[{\\\"name\\\":\\\"search\\\",\\\"description\\\":\\\"Web search tool\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"crawl_results\\\":{\\\"default\\\":0,\\\"description\\\":\\\"Number of results to crawl for full webpage content, useful when search result summaries are insufficient for complex queries\\\",\\\"type\\\":\\\"number\\\"},\\\"exclude_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to exclude from search. Only use when you need to explicitly filter out specific domains from results\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"include_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to include in search. Only use when you need special results from sites not available in search_service\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"max_results\\\":{\\\"default\\\":10,\\\"description\\\":\\\"Maximum number of results to return\\\",\\\"type\\\":\\\"number\\\"},\\\"query\\\":{\\\"description\\\":\\\"Search query, be simple and concise\\\",\\\"type\\\":\\\"string\\\"},\\\"search_service\\\":{\\\"default\\\":\\\"google\\\",\\\"description\\\":\\\"Specify the search engine to use. Choose based on your specific needs\\\",\\\"enum\\\":[\\\"google\\\",\\\"bing\\\",\\\"duckduckgo\\\",\\\"yahoo\\\",\\\"x\\\",\\\"reddit\\\",\\\"github\\\",\\\"youtube\\\",\\\"arxiv\\\",\\\"wechat\\\",\\\"bilibili\\\",\\\"imdb\\\",\\\"wikipedia\\\"],\\\"type\\\":\\\"string\\\"},\\\"time_range\\\":{\\\"description\\\":\\\"Time range for search results, only use when specific time constraints are required\\\",\\\"enum\\\":[\\\"day\\\",\\\"month\\\",\\\"year\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"news\\\",\\\"description\\\":\\\"News search tool\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"crawl_results\\\":{\\\"default\\\":0,\\\"description\\\":\\\"Number of results to crawl for full webpage content, useful when search result summaries are insufficient for complex queries\\\",\\\"type\\\":\\\"number\\\"},\\\"exclude_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to exclude from search. Only use when you need to explicitly filter out specific domains from results\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"include_sites\\\":{\\\"default\\\":[],\\\"description\\\":\\\"List of sites to include in search. Only use when you need special r\"])</script><script>self.__next_f.push([1,\"esults from sites not available in search_service\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"max_results\\\":{\\\"default\\\":10,\\\"description\\\":\\\"Maximum number of results to return\\\",\\\"type\\\":\\\"number\\\"},\\\"query\\\":{\\\"description\\\":\\\"Search query, be simple and concise\\\",\\\"type\\\":\\\"string\\\"},\\\"search_service\\\":{\\\"default\\\":\\\"bing\\\",\\\"description\\\":\\\"Specify the news engine to use. Choose based on your specific needs\\\",\\\"enum\\\":[\\\"google\\\",\\\"bing\\\",\\\"duckduckgo\\\",\\\"yahoo\\\",\\\"hackernews\\\"],\\\"type\\\":\\\"string\\\"},\\\"time_range\\\":{\\\"description\\\":\\\"Time range for search results, only use when specific time constraints are required\\\",\\\"enum\\\":[\\\"day\\\",\\\"month\\\",\\\"year\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"crawl\\\",\\\"description\\\":\\\"Extract content from URL\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"url\\\":{\\\"description\\\":\\\"URL to crawl\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"sitemap\\\",\\\"description\\\":\\\"Get all related links from a URL\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"url\\\":{\\\"description\\\":\\\"URL to get sitemap\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"url\\\"]}},{\\\"name\\\":\\\"reasoning\\\",\\\"description\\\":\\\"Deep thinking and complex problem solving\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"content\\\":{\\\"description\\\":\\\"The question or problem that needs deep thinking\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"content\\\"]}},{\\\"name\\\":\\\"trending\\\",\\\"description\\\":\\\"Get trending topics from popular platforms\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"max_results\\\":{\\\"default\\\":10,\\\"description\\\":\\\"Maximum number of trending items to return\\\",\\\"type\\\":\\\"number\\\"},\\\"search_service\\\":{\\\"default\\\":\\\"github\\\",\\\"description\\\":\\\"Specify the platform to get trending topics from\\\",\\\"enum\\\":[\\\"github\\\",\\\"hackernews\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"search_service\\\"]}}]83:T711,# EverArt MCP Server\\r\\n\\r\\nImage generation server for Claude Desktop using EverArt's API.\\r\\n\\r\\n## Install\\r\\n```bash\\r\\nnpm install\\r\\nexport EVERART_API_KEY=your_key_here\\r\\n```\\r\\n\\r\\n## Config\\r\\nAdd to Claude Desktop config:\\r\\n\\r\\n### Docker\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"everart\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"-e\\\", \\\"EVERART_API_KEY\\\", \\\"mcp/everart\\\"],\\r\\n      \\\"env\\\": {\\r\\n        \\\"EVERART_API_KEY\\\": \\\"your_key_here\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"everart\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\\"-y\\\", \\\"@modelcontextprotocol/server-everart\\\"],\\r\\n      \\\"env\\\": {\\r\\n        \\\"EVERART_API_KEY\\\": \\\"your_key_here\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Tools\\r\\n\\r\\n### generate_image\\r\\nGenerates images with multiple model options. Opens result in browser and returns URL.\\r\\n\\r\\nParameters:\\r\\n```typescript\\r\\n{\\r\\n  prompt: string,       // Image description\\r\\n  model?: string,       // Model ID (default: \\\"207910310772879360\\\")\\r\\n  image_count?: number  // Number of images (default: 1)\\r\\n}\\r\\n```\\r\\n\\r\\nModels:\\r\\n- 5000: FLUX1.1 (standard)\\r\\n- 9000: FLUX1.1-ultra\\r\\n- 6000: SD3.5\\r\\n- 7000: Recraft-Real\\r\\n- 8000: Recraft-Vector\\r\\n\\r\\nAll images generated at 1024x1024.\\r\\n\\r\\nSample usage:\\r\\n```javascript\\r\\nconst result = await client.callTool({\\r\\n  name: \\\"generate_image\\\",\\r\\n  arguments: {\\r\\n    prompt: \\\"A cat sitting elegantly\\\",\\r\\n    model: \\\"7000\\\",\\r\\n    image_count: 1\\r\\n  }\\r\\n});\\r\\n```\\r\\n\\r\\nResponse format:\\r\\n```\\r\\nImage generated successfully!\\r\\nThe image has been opened in your default browser.\\r\\n\\r\\nGeneration details:\\r\\n- Model: 7000\\r\\n- Prompt: \\\"A cat sitting elegantly\\\"\\r\\n- Image URL: https://storage.googleapis.com/...\\r\\n\\r\\nYou can also click the URL above to view the image again.\\r\\n```\\r\\n\\r\\n## Building w/ Docker\\r\\n\\r\\n```sh\\r\\ndocker build -t mcp/everart -f src/everart/Dockerfile . \\r\\n```84:T4c3,## What is EverArt? \\nEverArt is an AI image generation tool that allows users to create images using various models through an API. \\n\\n## How to use EverArt? \\nTo use EverArt, install the necessary dependencies, set up your API key, and configure Claude Desktop to utilize EverArt for image generation. Use the provided commands to generate images based on prompts. \\n\\n## Key features of EverArt? \\n- Generates images using multiple AI models \\n- Returns generated image URLs for easy access \\n- Configurable image generation parameters (prompt, model, image count) \\n\\n## Use cases of EverArt? \\n1. Creating u\"])</script><script>self.__next_f.push([1,\"nique art pieces based on descriptive prompts \\n2. Generating visual content for marketing and social media \\n3. Prototyping design concepts using AI-generated visuals \\n\\n## FAQ from EverArt? \\n- What image models does EverArt support? \\n\\u003e EverArt supports multiple models such as FLUX1.1, SD3.5, and Recraft, offering various styles and qualities. \\n\\n- Can I customize the number of images generated? \\n\\u003e Yes! You can specify the number of images you want in your requests. \\n\\n- Is there a limitation on the image prompt length? \\n\\u003e The prompt can be of reasonable length, but it's best to keep it concise for optimal results.85:T1692,# GitLab MCP Server\\r\\n\\r\\nMCP Server for the GitLab API, enabling project management, file operations, and more.\\r\\n\\r\\n### Features\\r\\n\\r\\n- **Automatic Branch Creation**: When creating/updating files or pushing changes, branches are automatically created if they don't exist\\r\\n- **Comprehensive Error Handling**: Clear error messages for common issues\\r\\n- **Git History Preservation**: Operations maintain proper Git history without force pushing\\r\\n- **Batch Operations**: Support for both single-file and multi-file operations\\r\\n\\r\\n\\r\\n## Tools\\r\\n\\r\\n1. `create_or_update_file`\\r\\n   - Create or update a single file in a project\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `file_path` (string): Path where to create/update the file\\r\\n     - `content` (string): Content of the file\\r\\n     - `commit_message` (string): Commit message\\r\\n     - `branch` (string): Branch to create/update the file in\\r\\n     - `previous_path` (optional string): Path of the file to move/rename\\r\\n   - Returns: File content and commit details\\r\\n\\r\\n2. `push_files`\\r\\n   - Push multiple files in a single commit\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `branch` (string): Branch to push to\\r\\n     - `files` (array): Files to push, each with `file_path` and `content`\\r\\n     - `commit_message` (string): Commit message\\r\\n   - Returns: Updated branch reference\\r\\n\\r\\n3. `search_repositories`\\r\\n   - Search for GitLab projects\\r\\n   - Inputs:\\r\\n     - `search` (string): Search query\\r\\n     - `page` (optional number): Page number for pagination\\r\\n     - `per_page` (optional number): Results per page (default 20)\\r\\n   - Returns: Project search results\\r\\n\\r\\n4. `create_repository`\\r\\n   - Create a new GitLab project\\r\\n   - Inputs:\\r\\n     - `name` (string): Project name\\r\\n     - `description` (optional string): Project description\\r\\n     - `visibility` (optional string): 'private', 'internal', or 'public'\\r\\n     - `initialize_with_readme` (optional boolean): Initialize with README\\r\\n   - Returns: Created project details\\r\\n\\r\\n5. `get_file_contents`\\r\\n   - Get contents of a file or directory\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `file_path` (string): Path to file/directory\\r\\n     - `ref` (optional string): Branch/tag/commit to get contents from\\r\\n   - Returns: File/directory contents\\r\\n\\r\\n6. `create_issue`\\r\\n   - Create a new issue\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `title` (string): Issue title\\r\\n     - `description` (optional string): Issue description\\r\\n     - `assignee_ids` (optional number[]): User IDs to assign\\r\\n     - `labels` (optional string[]): Labels to add\\r\\n     - `milestone_id` (optional number): Milestone ID\\r\\n   - Returns: Created issue details\\r\\n\\r\\n7. `create_merge_request`\\r\\n   - Create a new merge request\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `title` (string): MR title\\r\\n     - `description` (optional string): MR description\\r\\n     - `source_branch` (string): Branch containing changes\\r\\n     - `target_branch` (string): Branch to merge into\\r\\n     - `draft` (optional boolean): Create as draft MR\\r\\n     - `allow_collaboration` (optional boolean): Allow commits from upstream members\\r\\n   - Returns: Created merge request details\\r\\n\\r\\n8. `fork_repository`\\r\\n   - Fork a project\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `namespace` (optional string): Namespace to \"])</script><script>self.__next_f.push([1,\"fork to\\r\\n   - Returns: Forked project details\\r\\n\\r\\n9. `create_branch`\\r\\n   - Create a new branch\\r\\n   - Inputs:\\r\\n     - `project_id` (string): Project ID or URL-encoded path\\r\\n     - `branch` (string): Name for new branch\\r\\n     - `ref` (optional string): Source branch/commit for new branch\\r\\n   - Returns: Created branch reference\\r\\n\\r\\n## Setup\\r\\n\\r\\n### Personal Access Token\\r\\n[Create a GitLab Personal Access Token](https://docs.gitlab.com/ee/user/profile/personal_access_tokens.html) with appropriate permissions:\\r\\n   - Go to User Settings \\u003e Access Tokens in GitLab\\r\\n   - Select the required scopes:\\r\\n     - `api` for full API access\\r\\n     - `read_api` for read-only access\\r\\n     - `read_repository` and `write_repository` for repository operations\\r\\n   - Create the token and save it securely\\r\\n\\r\\n### Usage with Claude Desktop\\r\\nAdd the following to your `claude_desktop_config.json`:\\r\\n\\r\\n#### Docker\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": { \\r\\n    \\\"gitlab\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"run\\\",\\r\\n        \\\"--rm\\\",\\r\\n        \\\"-i\\\",\\r\\n        \\\"-e\\\",\\r\\n        \\\"GITLAB_PERSONAL_ACCESS_TOKEN\\\",\\r\\n        \\\"-e\\\",\\r\\n        \\\"GITLAB_API_URL\\\",\\r\\n        \\\"mcp/gitlab\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"GITLAB_PERSONAL_ACCESS_TOKEN\\\": \\\"\\u003cYOUR_TOKEN\\u003e\\\",\\r\\n        \\\"GITLAB_API_URL\\\": \\\"https://gitlab.com/api/v4\\\" // Optional, for self-hosted instances\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"gitlab\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-gitlab\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"GITLAB_PERSONAL_ACCESS_TOKEN\\\": \\\"\\u003cYOUR_TOKEN\\u003e\\\",\\r\\n        \\\"GITLAB_API_URL\\\": \\\"https://gitlab.com/api/v4\\\" // Optional, for self-hosted instances\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Build\\r\\n\\r\\nDocker build:\\r\\n\\r\\n```bash\\r\\ndocker build -t vonwig/gitlab:mcp -f src/gitlab/Dockerfile .\\r\\n```\\r\\n\\r\\n## Environment Variables\\r\\n\\r\\n- `GITLAB_PERSONAL_ACCESS_TOKEN`: Your GitLab personal access token (required)\\r\\n- `GITLAB_API_URL`: Base URL for GitLab API (optional, defaults to `https://gitlab.com/api/v4`)\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.86:T6a7,## what is GitLab MCP Server? \\nGitLab MCP Server is an API that enables project management and file operations through the GitLab platform. It facilitates various Git-related tasks using a user-friendly interface.\\n\\n## how to use GitLab MCP Server? \\nTo use the GitLab MCP Server, create a Personal Access Token on GitLab, configure your Claude Desktop application to include your token and GitLab API URL, and employ the various API endpoints for specific tasks like creating projects and managing files.\\n\\n## key features of GitLab MCP Server? \\n- **Automatic Branch Creation**: Automatically creates branches if they do not exist during file operations.\\n- **Comprehensive Error Handling**: Provides clear error messages for common issues encountered.\\n- **Git History Preservation**: Maintains Git history accurately without the need for force pushing.\\n- **Batch Operations Support**: Allows both single-file and multi-file operations.\\n\\n## use cases of GitLab MCP Server? \\n1. Managing GitLab project repositories programmatically.\\n2. Automating file creation and updates across multiple GitLab projects.\\n3. Facilitating team collaboration through issue and merge request management.\\n\\n## FAQ from GitLab MCP Server? \\n- How do I create a Personal Access Token?  \\n\\u003e Visit User Settings \\u003e Access Tokens in GitLab to generate a token with the necessary scopes.\\n\\n- Is there a limit on the number of operations I can perform?  \\n\\u003e There may be rate limits based on your GitLab account type. Monitor your API usage to avoid exceeding limits.\\n\\n- Can I use GitLab MCP Server for self-hosted GitLab instances?  \\n\\u003e Yes! You can configure the `GITLAB_API_URL` environment variable to point to your self-hosted instance.87:T1275,[{\\\"name\\\":\\\"create_or_update_file\\\",\\\"description\\\":\\\"Create or update a \"])</script><script>self.__next_f.push([1,\"single file in a GitLab project\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"branch\\\":{\\\"description\\\":\\\"Branch to create/update the file in\\\",\\\"type\\\":\\\"string\\\"},\\\"commit_message\\\":{\\\"description\\\":\\\"Commit message\\\",\\\"type\\\":\\\"string\\\"},\\\"content\\\":{\\\"description\\\":\\\"Content of the file\\\",\\\"type\\\":\\\"string\\\"},\\\"file_path\\\":{\\\"description\\\":\\\"Path where to create/update the file\\\",\\\"type\\\":\\\"string\\\"},\\\"previous_path\\\":{\\\"description\\\":\\\"Path of the file to move/rename\\\",\\\"type\\\":\\\"string\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\",\\\"file_path\\\",\\\"content\\\",\\\"commit_message\\\",\\\"branch\\\"]}},{\\\"name\\\":\\\"search_repositories\\\",\\\"description\\\":\\\"Search for GitLab projects\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"page\\\":{\\\"description\\\":\\\"Page number for pagination (default: 1)\\\",\\\"type\\\":\\\"number\\\"},\\\"per_page\\\":{\\\"description\\\":\\\"Number of results per page (default: 20)\\\",\\\"type\\\":\\\"number\\\"},\\\"search\\\":{\\\"description\\\":\\\"Search query\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"search\\\"]}},{\\\"name\\\":\\\"create_repository\\\",\\\"description\\\":\\\"Create a new GitLab project\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"description\\\":{\\\"description\\\":\\\"Repository description\\\",\\\"type\\\":\\\"string\\\"},\\\"initialize_with_readme\\\":{\\\"description\\\":\\\"Initialize with README.md\\\",\\\"type\\\":\\\"boolean\\\"},\\\"name\\\":{\\\"description\\\":\\\"Repository name\\\",\\\"type\\\":\\\"string\\\"},\\\"visibility\\\":{\\\"description\\\":\\\"Repository visibility level\\\",\\\"enum\\\":[\\\"private\\\",\\\"internal\\\",\\\"public\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"name\\\"]}},{\\\"name\\\":\\\"get_file_contents\\\",\\\"description\\\":\\\"Get the contents of a file or directory from a GitLab project\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"file_path\\\":{\\\"description\\\":\\\"Path to the file or directory\\\",\\\"type\\\":\\\"string\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"},\\\"ref\\\":{\\\"description\\\":\\\"Branch/tag/commit to get contents from\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\",\\\"file_path\\\"]}},{\\\"name\\\":\\\"push_files\\\",\\\"description\\\":\\\"Push multiple files to a GitLab project in a single commit\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"branch\\\":{\\\"description\\\":\\\"Branch to push to\\\",\\\"type\\\":\\\"string\\\"},\\\"commit_message\\\":{\\\"description\\\":\\\"Commit message\\\",\\\"type\\\":\\\"string\\\"},\\\"files\\\":{\\\"description\\\":\\\"Array of files to push\\\",\\\"items\\\":{\\\"additionalProperties\\\":false,\\\"properties\\\":{\\\"content\\\":{\\\"description\\\":\\\"Content of the file\\\",\\\"type\\\":\\\"string\\\"},\\\"file_path\\\":{\\\"description\\\":\\\"Path where to create the file\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"file_path\\\",\\\"content\\\"],\\\"type\\\":\\\"object\\\"},\\\"type\\\":\\\"array\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\",\\\"branch\\\",\\\"files\\\",\\\"commit_message\\\"]}},{\\\"name\\\":\\\"create_issue\\\",\\\"description\\\":\\\"Create a new issue in a GitLab project\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"assignee_ids\\\":{\\\"description\\\":\\\"Array of user IDs to assign\\\",\\\"items\\\":{\\\"type\\\":\\\"number\\\"},\\\"type\\\":\\\"array\\\"},\\\"description\\\":{\\\"description\\\":\\\"Issue description\\\",\\\"type\\\":\\\"string\\\"},\\\"labels\\\":{\\\"description\\\":\\\"Array of label names\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"milestone_id\\\":{\\\"description\\\":\\\"Milestone ID to assign\\\",\\\"type\\\":\\\"number\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"},\\\"title\\\":{\\\"description\\\":\\\"Issue title\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\",\\\"title\\\"]}},{\\\"name\\\":\\\"create_merge_request\\\",\\\"description\\\":\\\"Create a new merge request in a GitLab project\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"allow_collaboration\\\":{\\\"description\\\":\\\"Allow commits from upstream members\\\",\\\"type\\\":\\\"boolean\\\"},\\\"description\\\":{\\\"description\\\":\\\"Merge request description\\\",\\\"type\\\":\\\"string\\\"},\\\"draft\\\":{\\\"description\\\":\\\"Create as draft merge request\\\",\\\"type\\\":\\\"boolean\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"},\\\"source_branch\\\":{\\\"description\\\":\\\"Branch containing changes\\\",\\\"type\\\":\\\"string\\\"},\\\"target_branch\\\":{\\\"description\\\":\\\"Branch to merge into\\\",\\\"type\\\":\\\"string\\\"},\\\"title\\\":{\\\"description\\\":\\\"Merge request title\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\",\\\"title\\\",\\\"source_branch\\\",\\\"target_branch\\\"]}},{\\\"name\\\":\\\"fork_repository\\\",\\\"description\\\":\\\"Fork a GitLab project to your account or specified namespace\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"namespa\"])</script><script>self.__next_f.push([1,\"ce\\\":{\\\"description\\\":\\\"Namespace to fork to (full path)\\\",\\\"type\\\":\\\"string\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\"]}},{\\\"name\\\":\\\"create_branch\\\",\\\"description\\\":\\\"Create a new branch in a GitLab project\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"branch\\\":{\\\"description\\\":\\\"Name for the new branch\\\",\\\"type\\\":\\\"string\\\"},\\\"project_id\\\":{\\\"description\\\":\\\"Project ID or URL-encoded path\\\",\\\"type\\\":\\\"string\\\"},\\\"ref\\\":{\\\"description\\\":\\\"Source branch/commit for new branch\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"project_id\\\",\\\"branch\\\"]}}]88:Tcb1,\\\\# mcp-server-sentry: A Sentry MCP server\\r\\n\\r\\n## Overview\\r\\n\\r\\nA Model Context Protocol server for retrieving and analyzing issues from Sentry.io. This server provides tools to inspect error reports, stacktraces, and other debugging information from your Sentry account.\\r\\n\\r\\n### Tools\\r\\n\\r\\n1. \\\\`get\\\\_sentry\\\\_issue\\\\`\\r\\n   - Retrieve and analyze a Sentry issue by ID or URL\\r\\n   - Input:\\r\\n     - \\\\`issue\\\\_id\\\\_or\\\\_url\\\\` (string): Sentry issue ID or URL to analyze\\r\\n   - Returns: Issue details including:\\r\\n     - Title\\r\\n     - Issue ID\\r\\n     - Status\\r\\n     - Level\\r\\n     - First seen timestamp\\r\\n     - Last seen timestamp\\r\\n     - Event count\\r\\n     - Full stacktrace\\r\\n\\r\\n### Prompts\\r\\n\\r\\n1. \\\\`sentry-issue\\\\`\\r\\n   - Retrieve issue details from Sentry\\r\\n   - Input:\\r\\n     - \\\\`issue\\\\_id\\\\_or\\\\_url\\\\` (string): Sentry issue ID or URL\\r\\n   - Returns: Formatted issue details as conversation context\\r\\n\\r\\n## Installation\\r\\n\\r\\n### Using uv (recommended)\\r\\n\\r\\nWhen using \\\\[\\\\`uv\\\\`\\\\](https://docs.astral.sh/uv/) no specific installation is needed. We will\\r\\nuse \\\\[\\\\`uvx\\\\`\\\\](https://docs.astral.sh/uv/guides/tools/) to directly run \\\\*mcp-server-sentry\\\\*.\\r\\n\\r\\n### Using PIP\\r\\n\\r\\nAlternatively you can install \\\\`mcp-server-sentry\\\\` via pip:\\r\\n\\r\\n\\\\`\\\\`\\\\`\\r\\npip install mcp-server-sentry\\r\\n\\\\`\\\\`\\\\`\\r\\n\\r\\nAfter installation, you can run it as a script using:\\r\\n\\r\\n\\\\`\\\\`\\\\`\\r\\npython -m mcp\\\\_server\\\\_sentry\\r\\n\\\\`\\\\`\\\\`\\r\\n\\r\\n## Configuration\\r\\n\\r\\n### Usage with Claude Desktop\\r\\n\\r\\nAdd this to your \\\\`claude\\\\_desktop\\\\_config.json\\\\`:\\r\\n\\r\\n\\u003cdetails\\\\\\u003e\\r\\n\\u003csummary\\\\\\u003eUsing uvx\\u003c/summary\\\\\\u003e\\r\\n\\r\\n\\\\`\\\\`\\\\`json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"sentry\\\": {\\r\\n    \\\"command\\\": \\\"uvx\\\",\\r\\n    \\\"args\\\": \\\\[\\\"mcp-server-sentry\\\", \\\"--auth-token\\\", \\\"YOUR\\\\_SENTRY\\\\_TOKEN\\\"\\\\]\\r\\n  }\\r\\n}\\r\\n\\\\`\\\\`\\\\`\\r\\n\\u003c/details\\\\\\u003e\\r\\n\\r\\n\\u003cdetails\\\\\\u003e\\r\\n\\u003csummary\\\\\\u003eUsing pip installation\\u003c/summary\\\\\\u003e\\r\\n\\r\\n\\\\`\\\\`\\\\`json\\r\\n\\\"mcpServers\\\": {\\r\\n  \\\"sentry\\\": {\\r\\n    \\\"command\\\": \\\"python\\\",\\r\\n    \\\"args\\\": \\\\[\\\"-m\\\", \\\"mcp\\\\_server\\\\_sentry\\\", \\\"--auth-token\\\", \\\"YOUR\\\\_SENTRY\\\\_TOKEN\\\"\\\\]\\r\\n  }\\r\\n}\\r\\n\\\\`\\\\`\\\\`\\r\\n\\u003c/details\\\\\\u003e\\r\\n\\r\\n### Usage with \\\\[Zed\\\\](https://github.com/zed-industries/zed)\\r\\n\\r\\nAdd to your Zed settings.json:\\r\\n\\r\\n\\u003cdetails\\\\\\u003e\\r\\n\\u003csummary\\\\\\u003eUsing uvx\\u003c/summary\\\\\\u003e\\r\\n\\r\\n\\\\`\\\\`\\\\`json\\r\\n\\\"context\\\\_servers\\\": \\\\[\\r\\n  \\\"mcp-server-sentry\\\": {\\r\\n    \\\"command\\\": {\\r\\n      \\\"path\\\": \\\"uvx\\\",\\r\\n      \\\"args\\\": \\\\[\\\"mcp-server-sentry\\\", \\\"--auth-token\\\", \\\"YOUR\\\\_SENTRY\\\\_TOKEN\\\"\\\\]\\r\\n    }\\r\\n  }\\r\\n\\\\],\\r\\n\\\\`\\\\`\\\\`\\r\\n\\u003c/details\\\\\\u003e\\r\\n\\r\\n\\u003cdetails\\\\\\u003e\\r\\n\\u003csummary\\\\\\u003eUsing pip installation\\u003c/summary\\\\\\u003e\\r\\n\\r\\n\\\\`\\\\`\\\\`json\\r\\n\\\"context\\\\_servers\\\": {\\r\\n  \\\"mcp-server-sentry\\\": {\\r\\n    \\\"command\\\": \\\"python\\\",\\r\\n    \\\"args\\\": \\\\[\\\"-m\\\", \\\"mcp\\\\_server\\\\_sentry\\\", \\\"--auth-token\\\", \\\"YOUR\\\\_SENTRY\\\\_TOKEN\\\"\\\\]\\r\\n  }\\r\\n},\\r\\n\\\\`\\\\`\\\\`\\r\\n\\u003c/details\\\\\\u003e\\r\\n\\r\\n## Debugging\\r\\n\\r\\nYou can use the MCP inspector to debug the server. For uvx installations:\\r\\n\\r\\n\\\\`\\\\`\\\\`\\r\\nnpx @modelcontextprotocol/inspector uvx mcp-server-sentry --auth-token YOUR\\\\_SENTRY\\\\_TOKEN\\r\\n\\\\`\\\\`\\\\`\\r\\n\\r\\nOr if you've installed the package in a specific directory or are developing on it:\\r\\n\\r\\n\\\\`\\\\`\\\\`\\r\\ncd path/to/servers/src/sentry\\r\\nnpx @modelcontextprotocol/inspector uv run mcp-server-sentry --auth-token YOUR\\\\_SENTRY\\\\_TOKEN\\r\\n\\\\`\\\\`\\\\`\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.89:T579,## what is Sentry? \\nSentry is a Model Context Protocol server designed for retrieving and analyzing issues from Sentry.io. It enables developers to inspect error reports, stack traces, and debugging information efficiently.\\n\\n## how to use Sentry? \\nTo use Sentry, instal\"])</script><script>self.__next_f.push([1,\"l it via pip or the recommended uv tool, set your Sentry authentication token, and invoke it through command line or integration in development environments like Claude Desktop or Zed.\\n\\n## key features of Sentry? \\n- Retrieve and analyze Sentry issues by ID or URL.\\n- Detailed insights into issue including title, status, timestamps, and stack traces.\\n- Support for debugging with the MCP inspector.\\n\\n## use cases of Sentry? \\n1. Analyzing application errors in real-time.\\n2. Retrieving historical error reports for diagnostics.\\n3. Debugging and improving application reliability by inspecting stack traces.\\n\\n## FAQ from Sentry? \\n- How do I install Sentry?  \\n\\u003e You can install Sentry via pip using the command 'pip install mcp-server-sentry' or by using the uv tool.\\n\\n- What programming languages does Sentry support?  \\n\\u003e Sentry can be used with any programming language that can communicate with Sentry.io, as it primarily retrieves data from the Sentry API.\\n\\n- Is there support for multiple Sentry projects?  \\n\\u003e Yes, Sentry can handle multiple projects as long as you provide the corresponding authentication token for each project.8a:T7e7,# PostgreSQL\\r\\n\\r\\nA Model Context Protocol server that provides read-only access to PostgreSQL databases. This server enables LLMs to inspect database schemas and execute read-only queries.\\r\\n\\r\\n## Components\\r\\n\\r\\n### Tools\\r\\n\\r\\n- **query**\\r\\n  - Execute read-only SQL queries against the connected database\\r\\n  - Input: `sql` (string): The SQL query to execute\\r\\n  - All queries are executed within a READ ONLY transaction\\r\\n\\r\\n### Resources\\r\\n\\r\\nThe server provides schema information for each table in the database:\\r\\n\\r\\n- **Table Schemas** (`postgres://\\u003chost\\u003e/\\u003ctable\\u003e/schema`)\\r\\n  - JSON schema information for each table\\r\\n  - Includes column names and data types\\r\\n  - Automatically discovered from database metadata\\r\\n\\r\\n## Usage with Claude Desktop\\r\\n\\r\\nTo use this server with the Claude Desktop app, add the following configuration to the \\\"mcpServers\\\" section of your `claude_desktop_config.json`:\\r\\n\\r\\n### Docker\\r\\n\\r\\n* when running docker on macos, use host.docker.internal if the server is running on the host network (eg localhost)\\r\\n* username/password can be added to the postgresql url with `postgresql://user:password@host:port/db-name`\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"postgres\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"run\\\", \\r\\n        \\\"-i\\\", \\r\\n        \\\"--rm\\\", \\r\\n        \\\"mcp/postgres\\\", \\r\\n        \\\"postgresql://host.docker.internal:5432/mydb\\\"]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n### NPX\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"postgres\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-postgres\\\",\\r\\n        \\\"postgresql://localhost/mydb\\\"\\r\\n      ]\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\nReplace `/mydb` with your database name.\\r\\n\\r\\n## Building\\r\\n\\r\\nDocker:\\r\\n\\r\\n```sh\\r\\ndocker build -t mcp/postgres -f src/postgres/Dockerfile . \\r\\n```\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.8b:T5ba,## what is PostgreSQL? \\nPostgreSQL is a Model Context Protocol server providing read-only access to PostgreSQL databases, allowing for schema inspection and execution of read-only queries. \\n\\n## how to use PostgreSQL? \\nTo use PostgreSQL, configure it within the Claude Desktop app by adding the necessary parameters to the \\\"mcpServers\\\" section of the \\\\`claude_desktop_config.json\\\\` file. Replace the database name in the configuration with your specific database.\\n\\n## key features of PostgreSQL? \\n- Execute read-only SQL queries within a read-only transaction. \\n- Access detailed schema information for each table, including column names and data types. \\n- Automatically discovers schemas from database metadata. \\n\\n## use cases of PostgreSQL? \\n1. Inspecting database schemas before performing extensive data analysis. \\n2. Running read-only queries to generate reports without altering database states. \\n3. Integration with LLM\"])</script><script>self.__next_f.push([1,\"s for database-related tasks in applications. \\n\\n## FAQ from PostgreSQL? \\n- Is PostgreSQL suitable for writing data? \\n\\u003e No! PostgreSQL provides read-only access, which means data cannot be modified through this server. \\n\\n- Can I use PostgreSQL with other apps? \\n\\u003e Yes! While designed for Claude Desktop, PostgreSQL can be integrated into other applications that can call its endpoints. \\n\\n- How do I get schema information for a table? \\n\\u003e Schema information is automatically discovered and can be accessed via the provided schema URL endpoint.8c:Ta37,# AWS Knowledge Base Retrieval MCP Server\\r\\n\\r\\nAn MCP server implementation for retrieving information from the AWS Knowledge Base using the Bedrock Agent Runtime.\\r\\n\\r\\n## Features\\r\\n\\r\\n- **RAG (Retrieval-Augmented Generation)**: Retrieve context from the AWS Knowledge Base based on a query and a Knowledge Base ID.\\r\\n- **Supports multiple results retrieval**: Option to retrieve a customizable number of results.\\r\\n\\r\\n## Tools\\r\\n\\r\\n- **retrieve_from_aws_kb**\\r\\n  - Perform retrieval operations using the AWS Knowledge Base.\\r\\n  - Inputs:\\r\\n    - `query` (string): The search query for retrieval.\\r\\n    - `knowledgeBaseId` (string): The ID of the AWS Knowledge Base.\\r\\n    - `n` (number, optional): Number of results to retrieve (default: 3).\\r\\n\\r\\n## Configuration\\r\\n\\r\\n### Setting up AWS Credentials\\r\\n\\r\\n1. Obtain AWS access key ID, secret access key, and region from the AWS Management Console.\\r\\n2. Ensure these credentials have appropriate permissions for Bedrock Agent Runtime operations.\\r\\n\\r\\n### Usage with Claude Desktop\\r\\n\\r\\nAdd this to your `claude_desktop_config.json`:\\r\\n\\r\\n#### Docker\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"aws-kb-retrieval\\\": {\\r\\n      \\\"command\\\": \\\"docker\\\",\\r\\n      \\\"args\\\": [ \\\"run\\\", \\\"-i\\\", \\\"--rm\\\", \\\"-e\\\", \\\"AWS_ACCESS_KEY_ID\\\", \\\"-e\\\", \\\"AWS_SECRET_ACCESS_KEY\\\", \\\"-e\\\", \\\"AWS_REGION\\\", \\\"mcp/aws-kb-retrieval-server\\\" ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"AWS_ACCESS_KEY_ID\\\": \\\"YOUR_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_SECRET_ACCESS_KEY\\\": \\\"YOUR_SECRET_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_REGION\\\": \\\"YOUR_AWS_REGION_HERE\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n```json\\r\\n{\\r\\n  \\\"mcpServers\\\": {\\r\\n    \\\"aws-kb-retrieval\\\": {\\r\\n      \\\"command\\\": \\\"npx\\\",\\r\\n      \\\"args\\\": [\\r\\n        \\\"-y\\\",\\r\\n        \\\"@modelcontextprotocol/server-aws-kb-retrieval\\\"\\r\\n      ],\\r\\n      \\\"env\\\": {\\r\\n        \\\"AWS_ACCESS_KEY_ID\\\": \\\"YOUR_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_SECRET_ACCESS_KEY\\\": \\\"YOUR_SECRET_ACCESS_KEY_HERE\\\",\\r\\n        \\\"AWS_REGION\\\": \\\"YOUR_AWS_REGION_HERE\\\"\\r\\n      }\\r\\n    }\\r\\n  }\\r\\n}\\r\\n```\\r\\n\\r\\n## Building\\r\\n\\r\\nDocker: \\r\\n\\r\\n```sh\\r\\ndocker build -t mcp/aws-kb-retrieval -f src/aws-kb-retrieval-server/Dockerfile . \\r\\n```\\r\\n\\r\\n## License\\r\\n\\r\\nThis MCP server is licensed under the MIT License. This means you are free to use, modify, and distribute the software, subject to the terms and conditions of the MIT License. For more details, please see the LICENSE file in the project repository.\\r\\n\\r\\nThis README assumes that your server package is named `@modelcontextprotocol/server-aws-kb-retrieval`. Adjust the package name and installation details if they differ in your setup. Also, ensure that your server script is correctly built and that all dependencies are properly managed in your `package.json`.\\r\\n8d:T61a,## what is AWS Knowledge Base Retrieval Server? \\nThe AWS Knowledge Base Retrieval Server is an MCP server implementation designed to retrieve information from the AWS Knowledge Base using the Bedrock Agent Runtime.\\n\\n## how to use AWS Knowledge Base Retrieval Server? \\nTo use the server, set up your AWS credentials and configure the server in your `claude_desktop_config.json`. You can run it using Docker or npx commands with the necessary environment variables for AWS access.\\n\\n## key features of AWS Knowledge Base Retrieval Server? \\n- **RAG (Retrieval-Augmented Generation)**: Retrieve context from the AWS Knowledge Base based on a query and a Knowledge Base ID.\\n- **Supports multiple results retrieval**: Option to retrieve a customizable number of results.\\n\\n## use cases of AWS Knowledge Base Retrieval Server? \\n1. Retrieving specific information from AWS documentation based on user queries.\\n2. Integrating with appl\"])</script><script>self.__next_f.push([1,\"ications that require dynamic access to AWS Knowledge Base content.\\n3. Enhancing customer support tools with quick access to AWS resources.\\n\\n## FAQ from AWS Knowledge Base Retrieval Server? \\n- How do I set up AWS credentials?\\n\\u003e Obtain your AWS access key ID, secret access key, and region from the AWS Management Console and ensure they have the necessary permissions.\\n\\n- Can I customize the number of results retrieved?\\n\\u003e Yes! You can specify the number of results to retrieve when making a query.\\n\\n- Is there a license for this server?\\n\\u003e Yes, the server is licensed under the MIT License, allowing you to use, modify, and distribute it.8e:T62e,[{\\\"name\\\":\\\"mcp_howtocook_getAllRecipes\\\",\\\"description\\\":\\\"\u83b7\u53d6\u6240\u6709\u83dc\u8c31\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"no_param\\\":{\\\"description\\\":\\\"\u65e0\u53c2\u6570\\\",\\\"type\\\":\\\"string\\\"}}}},{\\\"name\\\":\\\"mcp_howtocook_getRecipesByCategory\\\",\\\"description\\\":\\\"\u6839\u636e\u5206\u7c7b\u67e5\u8be2\u83dc\u8c31\uff0c\u53ef\u9009\u5206\u7c7b\u6709: \u6c34\u4ea7, \u65e9\u9910, \u8c03\u5473\u6599, \u751c\u54c1, \u996e\u54c1, \u8364\u83dc, \u534a\u6210\u54c1, \u6c64\u7fb9, \u4e3b\u98df, \u7d20\u83dc\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"category\\\":{\\\"description\\\":\\\"\u83dc\u8c31\u5206\u7c7b\u540d\u79f0\uff0c\u5982\u6c34\u4ea7\u3001\u65e9\u9910\u3001\u8364\u83dc\u3001\u4e3b\u98df\u7b49\\\",\\\"enum\\\":[\\\"\u6c34\u4ea7\\\",\\\"\u65e9\u9910\\\",\\\"\u8c03\u5473\u6599\\\",\\\"\u751c\u54c1\\\",\\\"\u996e\u54c1\\\",\\\"\u8364\u83dc\\\",\\\"\u534a\u6210\u54c1\\\",\\\"\u6c64\u7fb9\\\",\\\"\u4e3b\u98df\\\",\\\"\u7d20\u83dc\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"category\\\"]}},{\\\"name\\\":\\\"mcp_howtocook_recommendMeals\\\",\\\"description\\\":\\\"\u6839\u636e\u7528\u6237\u7684\u5fcc\u53e3\u3001\u8fc7\u654f\u539f\u3001\u4eba\u6570\u667a\u80fd\u63a8\u8350\u83dc\u8c31\uff0c\u521b\u5efa\u4e00\u5468\u7684\u81b3\u98df\u8ba1\u5212\u4ee5\u53ca\u5927\u81f4\u7684\u8d2d\u7269\u6e05\u5355\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"allergies\\\":{\\\"description\\\":\\\"\u8fc7\u654f\u539f\u5217\u8868\uff0c\u5982[\\\\\\\"\u5927\u849c\\\\\\\", \\\\\\\"\u867e\\\\\\\"]\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"avoidItems\\\":{\\\"description\\\":\\\"\u5fcc\u53e3\u98df\u6750\u5217\u8868\uff0c\u5982[\\\\\\\"\u8471\\\\\\\", \\\\\\\"\u59dc\\\\\\\"]\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"peopleCount\\\":{\\\"description\\\":\\\"\u7528\u9910\u4eba\u6570\uff0c1-10\u4e4b\u95f4\u7684\u6574\u6570\\\",\\\"maximum\\\":10,\\\"minimum\\\":1,\\\"type\\\":\\\"integer\\\"}},\\\"required\\\":[\\\"peopleCount\\\"]}},{\\\"name\\\":\\\"mcp_howtocook_whatToEat\\\",\\\"description\\\":\\\"\u4e0d\u77e5\u9053\u5403\u4ec0\u4e48\uff1f\u6839\u636e\u4eba\u6570\u76f4\u63a5\u63a8\u8350\u9002\u5408\u7684\u83dc\u54c1\u7ec4\u5408\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"peopleCount\\\":{\\\"description\\\":\\\"\u7528\u9910\u4eba\u6570\uff0c1-10\u4e4b\u95f4\u7684\u6574\u6570\uff0c\u4f1a\u6839\u636e\u4eba\u6570\u63a8\u8350\u5408\u9002\u6570\u91cf\u7684\u83dc\u54c1\\\",\\\"maximum\\\":10,\\\"minimum\\\":1,\\\"type\\\":\\\"integer\\\"}},\\\"required\\\":[\\\"peopleCount\\\"]}}]8f:T62e,[{\\\"name\\\":\\\"mcp_howtocook_getAllRecipes\\\",\\\"description\\\":\\\"\u83b7\u53d6\u6240\u6709\u83dc\u8c31\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"no_param\\\":{\\\"description\\\":\\\"\u65e0\u53c2\u6570\\\",\\\"type\\\":\\\"string\\\"}}}},{\\\"name\\\":\\\"mcp_howtocook_getRecipesByCategory\\\",\\\"description\\\":\\\"\u6839\u636e\u5206\u7c7b\u67e5\u8be2\u83dc\u8c31\uff0c\u53ef\u9009\u5206\u7c7b\u6709: \u6c34\u4ea7, \u65e9\u9910, \u8c03\u5473\u6599, \u751c\u54c1, \u996e\u54c1, \u8364\u83dc, \u534a\u6210\u54c1, \u6c64\u7fb9, \u4e3b\u98df, \u7d20\u83dc\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"category\\\":{\\\"description\\\":\\\"\u83dc\u8c31\u5206\u7c7b\u540d\u79f0\uff0c\u5982\u6c34\u4ea7\u3001\u65e9\u9910\u3001\u8364\u83dc\u3001\u4e3b\u98df\u7b49\\\",\\\"enum\\\":[\\\"\u6c34\u4ea7\\\",\\\"\u65e9\u9910\\\",\\\"\u8c03\u5473\u6599\\\",\\\"\u751c\u54c1\\\",\\\"\u996e\u54c1\\\",\\\"\u8364\u83dc\\\",\\\"\u534a\u6210\u54c1\\\",\\\"\u6c64\u7fb9\\\",\\\"\u4e3b\u98df\\\",\\\"\u7d20\u83dc\\\"],\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"category\\\"]}},{\\\"name\\\":\\\"mcp_howtocook_recommendMeals\\\",\\\"description\\\":\\\"\u6839\u636e\u7528\u6237\u7684\u5fcc\u53e3\u3001\u8fc7\u654f\u539f\u3001\u4eba\u6570\u667a\u80fd\u63a8\u8350\u83dc\u8c31\uff0c\u521b\u5efa\u4e00\u5468\u7684\u81b3\u98df\u8ba1\u5212\u4ee5\u53ca\u5927\u81f4\u7684\u8d2d\u7269\u6e05\u5355\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"allergies\\\":{\\\"description\\\":\\\"\u8fc7\u654f\u539f\u5217\u8868\uff0c\u5982[\\\\\\\"\u5927\u849c\\\\\\\", \\\\\\\"\u867e\\\\\\\"]\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"avoidItems\\\":{\\\"description\\\":\\\"\u5fcc\u53e3\u98df\u6750\u5217\u8868\uff0c\u5982[\\\\\\\"\u8471\\\\\\\", \\\\\\\"\u59dc\\\\\\\"]\\\",\\\"items\\\":{\\\"type\\\":\\\"string\\\"},\\\"type\\\":\\\"array\\\"},\\\"peopleCount\\\":{\\\"description\\\":\\\"\u7528\u9910\u4eba\u6570\uff0c1-10\u4e4b\u95f4\u7684\u6574\u6570\\\",\\\"maximum\\\":10,\\\"minimum\\\":1,\\\"type\\\":\\\"integer\\\"}},\\\"required\\\":[\\\"peopleCount\\\"]}},{\\\"name\\\":\\\"mcp_howtocook_whatToEat\\\",\\\"description\\\":\\\"\u4e0d\u77e5\u9053\u5403\u4ec0\u4e48\uff1f\u6839\u636e\u4eba\u6570\u76f4\u63a5\u63a8\u8350\u9002\u5408\u7684\u83dc\u54c1\u7ec4\u5408\\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"peopleCount\\\":{\\\"description\\\":\\\"\u7528\u9910\u4eba\u6570\uff0c1-10\u4e4b\u95f4\u7684\u6574\u6570\uff0c\u4f1a\u6839\u636e\u4eba\u6570\u63a8\u8350\u5408\u9002\u6570\u91cf\u7684\u83dc\u54c1\\\",\\\"maximum\\\":10,\\\"minimum\\\":1,\\\"type\\\":\\\"integer\\\"}},\\\"required\\\":[\\\"peopleCount\\\"]}}]90:T337b,# MCP Advisor\\n\\n[![Model Context Protocol](https://img.shields.io/badge/Model%20Context%20Protocol-purple)](https://modelcontextprotocol.org)\\n[![npm version](https://img.shields.io/npm/v/@xiaohui-wang/mcpadvisor.svg)](https://www.npmjs.com/package/@xiaohui-wang/mcpadvis\"])</script><script>self.__next_f.push([1,\"or)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\\n\\n[![DeepWiki](https://img.shields.io/badge/DeepWiki-istarwyh%2Fmcpadvisor-blue.svg?logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACwAAAAyCAYAAAAnWDnqAAAAAXNSR0IArs4c6QAAA05JREFUaEPtmUtyEzEQhtWTQyQLHNak2AB7ZnyXZMEjXMGeK/AIi+QuHrMnbChYY7MIh8g01fJoopFb0uhhEqqcbWTp06/uv1saEDv4O3n3dV60RfP947Mm9/SQc0ICFQgzfc4CYZoTPAswgSJCCUJUnAAoRHOAUOcATwbmVLWdGoH//PB8mnKqScAhsD0kYP3j/Yt5LPQe2KvcXmGvRHcDnpxfL2zOYJ1mFwrryWTz0advv1Ut4CJgf5uhDuDj5eUcAUoahrdY/56ebRWeraTjMt/00Sh3UDtjgHtQNHwcRGOC98BJEAEymycmYcWwOprTgcB6VZ5JK5TAJ+fXGLBm3FDAmn6oPPjR4rKCAoJCal2eAiQp2x0vxTPB3ALO2CRkwmDy5WohzBDwSEFKRwPbknEggCPB/imwrycgxX2NzoMCHhPkDwqYMr9tRcP5qNrMZHkVnOjRMWwLCcr8ohBVb1OMjxLwGCvjTikrsBOiA6fNyCrm8V1rP93iVPpwaE+gO0SsWmPiXB+jikdf6SizrT5qKasx5j8ABbHpFTx+vFXp9EnYQmLx02h1QTTrl6eDqxLnGjporxl3NL3agEvXdT0WmEost648sQOYAeJS9Q7bfUVoMGnjo4AZdUMQku50McDcMWcBPvr0SzbTAFDfvJqwLzgxwATnCgnp4wDl6Aa+Ax283gghmj+vj7feE2KBBRMW3FzOpLOADl0Isb5587h/U4gGvkt5v60Z1VLG8BhYjbzRwyQZemwAd6cCR5/XFWLYZRIMpX39AR0tjaGGiGzLVyhse5C9RKC6ai42ppWPKiBagOvaYk8lO7DajerabOZP46Lby5wKjw1HCRx7p9sVMOWGzb/vA1hwiWc6jm3MvQDTogQkiqIhJV0nBQBTU+3okKCFDy9WwferkHjtxib7t3xIUQtHxnIwtx4mpg26/HfwVNVDb4oI9RHmx5WGelRVlrtiw43zboCLaxv46AZeB3IlTkwouebTr1y2NjSpHz68WNFjHvupy3q8TFn3Hos2IAk4Ju5dCo8B3wP7VPr/FGaKiG+T+v+TQqIrOqMTL1VdWV1DdmcbO8KXBz6esmYWYKPwDL5b5FA1a0hwapHiom0r/cKaoqr+27/XcrS5UwSMbQAAAABJRU5ErkJggg==)](https://deepwiki.com/istarwyh/mcpadvisor)\\n\\u003c!-- DeepWiki badge generated by https://deepwiki.ryoppippi.com/ --\\u003e\\n\\n\\u003ca href=\\\"https://glama.ai/mcp/servers/@istarwyh/mcpadvisor\\\"\\u003e\\n  \\u003cimg width=\\\"380\\\" height=\\\"200\\\" src=\\\"https://glama.ai/mcp/servers/@istarwyh/mcpadvisor/badge\\\" alt=\\\"Advisor MCP server\\\" /\\u003e\\n\\u003c/a\\u003e\\n\\n\\n\\n[English](./README.md) | [\u7b80\u4f53\u4e2d\u6587](./README_zh.md) \\n\\n## Introduction\\n\\nMCP Advisor is a discovery and recommendation service that helps AI assistants explore Model Context Protocol (MCP) servers using natural language queries. It makes it easier for users to find and leverage MCP tools suitable for specific tasks.\\n\\n## Features\\n\\n- **Natural Language Search**: Find MCP services using conversational queries\\n- **Rich Metadata**: Get detailed information about each service\\n- **Real-time Updates**: Always in sync with the latest MCP services [![MCP Servers](https://img.shields.io/badge/MCP-Servers-red?logo=github)](https://github.com/modelcontextprotocol/servers)\\n- **Easy Integration**: Simple configuration for any MCP-compatible AI assistant\\n- **Hybrid Search Engine**: Advanced search capabilities combining vector search and text matching\\n- **Multi-provider Support**: Support for multiple search providers executing in parallel\\n\\n## Documentation Navigation\\n\\n- [Installation Guide](docs/INSTALLATION.md) - Detailed installation and configuration instructions\\n- [User Guide](docs/USER_GUIDE.md) - How to use MCP Advisor\\n- [Architecture Documentation](docs/ARCHITECTURE.md) - System architecture details\\n- [Technical Details](docs/TECHNICAL_DETAILS.md) - Advanced technical features\\n- [Developer Guide](docs/DEVELOPER_GUIDE.md) - Development environment setup and code contribution\\n- [Best Practices](docs/BEST_PRACTICES.md) - Coding standards and best practices for contributors\\n- [Troubleshooting](docs/TROUBLESHOOTING.md) - Common issues and solutions\\n- [Search Providers](docs/SEARCH_PROVIDERS.md) - Search provider details\\n- [API Reference](docs/API_REFERENCE.md) - API documentation\\n- [Roadmap](ROADMAP.md) - Future development plans\\n- [Contribution Guidelines](CONTRIBUTING.md) - How to contribute code\\n\\n## Quick Start\\n\\n### Installation\\n\\nThe fastest way is to integrate MCP Advisor through MCP configuration:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"mcpadvisor\\\": {\\n      \\\"command\\\": \\\"npx\\\",\\n      \\\"args\\\": [\\\"-y\\\", \\\"@xiaohui-wang/mcpadvisor\\\"]\\n    }\\n  }\\n}\\n```\\n\\nAdd this configuration to your AI assistant's MCP settings file:\\n\\n- MacOS/Linux: `~/Library/Application Support/Claude/claude_desktop_config.json`\\n- Windows: `%AppData%\\\\Claude\\\\claude_desktop_config.json`\\n\\nFor more installation methods, see the [Installation Guide](docs/INSTALLATI\"])</script><script>self.__next_f.push([1,\"ON.md).\\n\\n### Demo\\n\\n\\u003cdiv align=\\\"center\\\"\\u003e\\n  \\u003ca href=\\\"https://www.bilibili.com/video/BV17tJuz9Eci\\\"\\u003e\\n    \\u003cimg src=\\\"https://xiaohui-zhangjiakou.oss-cn-zhangjiakou.aliyuncs.com/image/202505181400161.png\\\" alt=\\\"MCP Advisor Demo\\\" width=\\\"640\\\"\\u003e\\n  \\u003c/a\\u003e\\n  \\u003cp\\u003eClick the image to watch the demo video\\u003c/p\\u003e\\n\\u003c/div\\u003e\\n\\n## Developer Guide\\n\\n### Architecture Overview\\n\\nMCP Advisor adopts a modular architecture with clear separation of concerns and functional programming principles:\\n\\n```mermaid\\ngraph TD\\n    Client[\\\"Client Application\\\"] --\\u003e |\\\"MCP Protocol\\\"| Transport[\\\"Transport Layer\\\"]\\n    \\n    subgraph \\\"MCP Advisor Server\\\"\\n        Transport --\\u003e |\\\"Request\\\"| SearchService[\\\"Search Service\\\"]\\n        SearchService --\\u003e |\\\"Query\\\"| Providers[\\\"Search Providers\\\"]\\n        \\n        subgraph \\\"Search Providers\\\"\\n            Providers --\\u003e MeilisearchProvider[\\\"Meilisearch Provider\\\"]\\n            Providers --\\u003e GetMcpProvider[\\\"GetMCP Provider\\\"]\\n            Providers --\\u003e CompassProvider[\\\"Compass Provider\\\"]\\n            Providers --\\u003e OfflineProvider[\\\"Offline Provider\\\"]\\n        end\\n        \\n        OfflineProvider --\\u003e |\\\"Hybrid Search\\\"| HybridSearch[\\\"Hybrid Search Engine\\\"]\\n        HybridSearch --\\u003e TextMatching[\\\"Text Matching\\\"]\\n        HybridSearch --\\u003e VectorSearch[\\\"Vector Search\\\"]\\n        \\n        SearchService --\\u003e |\\\"Merge \\u0026 Filter\\\"| ResultProcessor[\\\"Result Processor\\\"]\\n        \\n        SearchService --\\u003e Logger[\\\"Logging System\\\"]\\n    end\\n```\\n\\n### Core Components\\n\\n1. **Search Service Layer**\\n   - Unified search interface and provider aggregation\\n   - Support for multiple search providers executing in parallel\\n   - Configurable search options (limit, minSimilarity)\\n\\n2. **Search Providers**\\n   - **Meilisearch Provider**: Vector search using Meilisearch\\n   - **GetMCP Provider**: API search from the GetMCP registry\\n   - **Compass Provider**: API search from the Compass registry\\n   - **Offline Provider**: Hybrid search combining text and vectors\\n\\n3. **Hybrid Search Strategy**\\n   - Intelligent combination of text matching and vector search\\n   - Configurable weight balancing\\n   - Smart adaptive filtering mechanisms\\n\\n4. **Transport Layer**\\n   - Stdio (CLI default)\\n   - SSE (Web integration)\\n   - REST API endpoints\\n\\nFor more detailed architecture documentation, see [ARCHITECTURE.md](docs/ARCHITECTURE.md).\\n\\n## Technical Highlights\\n\\n### Advanced Search Techniques\\n\\n1. **Vector Normalization**\\n   - All vectors are normalized to unit length (magnitude = 1)\\n   - Ensures consistent cosine similarity calculations\\n   - Improves search precision by focusing on direction rather than magnitude\\n\\n2. **Parallel Search Execution**\\n   - Vector search and text search run in parallel\\n   - Leverages Promise.all for optimal performance\\n   - Fallback mechanisms enabled if either search fails\\n\\n3. **Weighted Result Merging**\\n   - Configurable weights between vector and text results\\n   - Default: vector similarity (70%), text matching (30%)\\n\\n### Error Handling and Logging System\\n\\nMCP Advisor implements robust error handling and logging systems:\\n\\n1. **Contextual Error Formatting**\\n   - Standardized error object enrichment\\n   - Stack trace preservation and formatting\\n   - Error type categorization and standardization\\n\\n2. **Graceful Degradation**\\n   - Multi-provider fallback strategies\\n   - Partial result processing\\n   - Default responses for critical failures\\n\\nFor more technical details, see [TECHNICAL_DETAILS.md](docs/TECHNICAL_DETAILS.md).\\n\\n## Developer Quick Start\\n\\n### Development Environment Setup\\n\\n1. Clone the repository\\n2. Install dependencies:\\n   ```bash\\n   npm install\\n   ```\\n3. Configure environment variables (see [INSTALLATION.md](docs/INSTALLATION.md))\\n\\n### Library Usage\\n\\n```typescript\\nimport { SearchService } from '@xiaohui-wang/mcpadvisor';\\n\\n// Initialize search service\\nconst searchService = new SearchService();\\n\\n// Search for MCP servers\\nconst results = await searchService.search('vector database integration');\\nconsole.log(results);\\n```\\n\\n### Transport Options\\n\\nMCP Advisor supports multiple transport methods:\\n\\n1. **Stdio Transport** (default) - Suitable for command-line tools\\n2. **SSE Transport** - S\"])</script><script>self.__next_f.push([1,\"uitable for web integration\\n3. **REST Transport** - Provides REST API endpoints\\n\\nFor more development details, see [DEVELOPER_GUIDE.md](docs/DEVELOPER_GUIDE.md).\\n\\n## Contribution Guidelines\\n\\n1. Follow commit message conventions:\\n   - Use lowercase types (feat, fix, docs, etc.)\\n   - Write descriptive messages in sentence format\\n\\n2. Ensure code quality:\\n   - Run tests: `npm test`\\n   - Check types: `npm run type-check`\\n   - Lint code: `npm run lint`\\n\\nFor detailed contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md).\\n\\n## Usage Examples\\n\\n### Example Queries\\n\\nHere are some example queries you can use with MCP Advisor:\\n\\n```\\n\\\"Find MCP servers for natural language processing\\\"\\n\\\"MCP servers for financial data analysis\\\"\\n\\\"E-commerce recommendation engine MCP servers\\\"\\n\\\"MCP servers with image recognition capabilities\\\"\\n\\\"Weather data processing MCP servers\\\"\\n\\\"Document summarization MCP servers\\\"\\n```\\n\\n### Example Response\\n\\n```json\\n[\\n  {\\n    \\\"title\\\": \\\"NLP Toolkit\\\",\\n    \\\"description\\\": \\\"Comprehensive natural language processing toolkit with sentiment analysis, entity recognition, and text summarization capabilities.\\\",\\n    \\\"github_url\\\": \\\"https://github.com/example/nlp-toolkit\\\",\\n    \\\"similarity\\\": 0.92\\n  },\\n  {\\n    \\\"title\\\": \\\"Text Processor\\\",\\n    \\\"description\\\": \\\"Efficient text processing MCP server with multi-language support.\\\",\\n    \\\"github_url\\\": \\\"https://github.com/example/text-processor\\\",\\n    \\\"similarity\\\": 0.85\\n  }\\n]\\n```\\n\\nFor more examples, see [EXAMPLES.md](docs/EXAMPLES.md).\\n\\n## Troubleshooting\\n\\n### Common Issues\\n\\n1. **Connection Refused**\\n   - Ensure the server is running on the specified port\\n   - Check firewall settings\\n\\n2. **No Results Returned**\\n   - Try a more general query\\n   - Check network connection to registry APIs\\n\\n3. **Performance Issues**\\n   - Consider adding more specific search terms\\n   - Check server resources (CPU/memory)\\n\\nFor more troubleshooting information, see [TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md).\\n\\n## Search Providers\\n\\nMCP Advisor supports multiple search providers that can be used simultaneously:\\n\\n1. **Compass Search Provider**: Retrieves MCP server information using the Compass API\\n2. **GetMCP Search Provider**: Uses the GetMCP API and vector search for semantic matching\\n3. **Meilisearch Search Provider**: Uses Meilisearch for fast, fault-tolerant text search\\n\\nFor detailed information about search providers, see [SEARCH_PROVIDERS.md](docs/SEARCH_PROVIDERS.md).\\n\\n## API Documentation\\n\\nFor detailed API documentation, see [API_REFERENCE.md](docs/API_REFERENCE.md).\\n\\n## Roadmap\\n\\nMCP Advisor is evolving from a simple recommendation system to an intelligent agent orchestration platform. Our vision is to create a system that not only recommends the right MCP servers but also learns from interactions and helps agents dynamically plan and execute complex tasks.\\n\\n```mermaid\\ngantt\\n    title MCP Advisor Evolution Roadmap\\n    dateFormat  YYYY-MM-DD\\n    axisFormat  %Y-%m\\n    \\n    section Foundation\\n    Enhanced Search \\u0026 Recommendation \u2713       :done, 2025-01-01, 90d\\n    Hybrid Search Engine \u2713                   :done, 2025-01-01, 90d\\n    Provider Priority System \u2713               :done, 2025-04-01, 60d\\n    \\n    section Intelligence Layer\\n    Feedback Collection System               :active, 2025-04-01, 90d\\n    Agent Interaction Analytics             :2025-07-01, 120d\\n    Usage Pattern Recognition               :2025-07-01, 90d\\n    \\n    section Learning Systems\\n    Reinforcement Learning Framework         :2025-10-01, 180d\\n    Contextual Bandit Implementation         :2025-10-01, 120d\\n    Multi-Agent Reward Modeling             :2026-01-01, 90d\\n    \\n    section Advanced Features\\n    Task Decomposition Engine               :2026-01-01, 120d\\n    Dynamic Planning System                 :2026-04-01, 150d\\n    Adaptive MCP Orchestration              :2026-04-01, 120d\\n    \\n    section Ecosystem\\n    Developer SDK \\u0026 API                     :2026-07-01, 90d\\n    Custom MCP Training Tools               :2026-07-01, 120d\\n    Enterprise Integration Framework        :2026-10-01, 150d\\n```\\n\\n### Major Development Phases\\n\\n1. **Recomm\"])</script><script>self.__next_f.push([1,\"endation Capability Optimization** (2025 Q2-Q3)\\n   - Accept user feedback\\n   - Refine recommendation effectiveness\\n   - Introduce more indices\\n\\nFor a detailed roadmap, see [ROADMAP.md](ROADMAP.md).\\n\\nTo Implement the above features, we need to:\\n\\n- [ ] Full-Text Index Search\\n- [ ] Utilize Professional Rerank Module like https://github.com/PrithivirajDamodaran/FlashRank \\n\\n## Testing\\n\\nUse [inspector](https://github.com/modelcontextprotocol/inspector) for testing:\\n\\n```bash \\nnpx @modelcontextprotocol/inspector\\n```\\n\\n\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.91:T66f,## What is MCP Advisor? \\nMCP Advisor is a discovery and recommendation service designed to help users explore Model Context Protocol (MCP) servers. It acts as a smart guide for AI assistants, enabling them to find and understand available MCP services through natural language queries.\\n\\n## How to use MCP Advisor? \\nTo use MCP Advisor, clone the repository or utilize `npx`. Configure your AI assistant to integrate with MCP Advisor by editing the appropriate configuration files based on your operating system.\\n\\n## Key features of MCP Advisor? \\n- **Smart Search**: Allows users to find MCP services using natural language queries.\\n- **Rich Metadata**: Provides detailed information about each service.\\n- **Real-time Updates**: Ensures users have access to the latest MCP services.\\n- **Easy Integration**: Simple integration with any MCP-compatible AI assistant.\\n\\n## Use cases of MCP Advisor? \\n1. Discovering MCP servers for natural language processing tasks.\\n2. Finding MCP servers for financial data analysis.\\n3. Identifying recommendation engine MCP servers for e-commerce applications.\\n4. Locating MCP servers with image recognition capabilities.\\n\\n## FAQ from MCP Advisor? \\n- **What is the purpose of MCP Advisor?**  \\n\\u003e MCP Advisor helps users discover and utilize the right MCP services for their specific tasks through natural language queries.\\n\\n- **Is MCP Advisor free to use?**  \\n\\u003e Yes! MCP Advisor is open-source and free to use.\\n\\n- **How can I troubleshoot common issues?**  \\n\\u003e Common issues include connection problems, no results returned, and performance issues. Refer to the troubleshooting section in the documentation for solutions.92:T727,[{\\\"name\\\":\\\"recommend-mcp-servers\\\",\\\"description\\\":\\\"\\\\n              \u6b64\u5de5\u5177\u7528\u4e8e\u5bfb\u627e\u5408\u9002\u4e14\u4e13\u4e1aMCP\u670d\u52a1\u5668\u3002\\\\n              \u57fa\u4e8e\u60a8\u7684\u5177\u4f53\u9700\u6c42\uff0c\u4ece\u4e92\u8054\u7f51\u8d44\u6e90\u5e93\u4ee5\u53ca\u5185\u90e8MCP\u5e93\u4e2d\u7b5b\u9009\u5e76\u63a8\u8350\u6700\u9002\u5408\u7684MCP\u670d\u52a1\u5668\u89e3\u51b3\u65b9\u6848\u3002\\\\n              \u8fd4\u56de\u7ed3\u679c\u5305\u542b\u670d\u52a1\u5668\u540d\u79f0\u3001\u529f\u80fd\u63cf\u8ff0\u3001\u6240\u5c5e\u7c7b\u522b\uff0c\u4e3a\u60a8\u7684\u4e1a\u52a1\u6210\u529f\u63d0\u4f9b\u7cbe\u51c6\u6280\u672f\u652f\u6301\u3002\\\\n              \\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"query\\\":{\\\"description\\\":\\\"\\\\n                    \u8bf7\u63d0\u4f9b\u6240\u9700MCP\u670d\u52a1\u5668\u7684\u7cbe\u786e\u63cf\u8ff0\u3002\\\\n                    \\\\n                    \u6709\u6548\u67e5\u8be2\u793a\u4f8b\uff1a\\\\n                    - '\u7528\u4e8e\u98ce\u63a7\u7b56\u7565\u90e8\u7f72\u7684MCP\u670d\u52a1\u5668'\\\\n                    - '\u4fdd\u9669\u4ea7\u54c1\u7cbe\u7b97\u5b9a\u4ef7\u7684MCP\u670d\u52a1\u5668'\\\\n                    \\\\n                    \u65e0\u6548\u67e5\u8be2\u793a\u4f8b\uff1a\\\\n                    - '\u4fdd\u9669MCP\u670d\u52a1\u5668'\uff08\u8fc7\u4e8e\u5bbd\u6cdb\uff09\\\\n                    - '\u98ce\u63a7\u7cfb\u7edf'\uff08\u7f3a\u4e4f\u5177\u4f53\u4fdd\u9669\u573a\u666f\uff09\\\\n                    - '\u7cbe\u7b97\u5de5\u5177'\uff08\u672a\u6307\u660e\u5177\u4f53\u529f\u80fd\u9700\u6c42\uff09\\\\n                    \\\\n                    \u67e5\u8be2\u5e94\u660e\u786e\u6307\u5b9a\uff1a\\\\n                    1. \u4e1a\u52a1\u6d41\u7a0b\uff08\u5982\u4ea7\u54c1\u5b9a\u4ef7\u3001\u6838\u4fdd\u3001\u7406\u8d54\u3001\u51c6\u5907\u91d1\u8ba1\u7b97\u7b49\uff09\\\\n                    2. \u5177\u4f53\u529f\u80fd\u9700\u6c42\uff08\u5982\u98ce\u9669\u5206\u6790\u3001\u7b56\u7565\u90e8\u7f72\u3001\u7b56\u7565\u7814\u53d1\u3001\u7279\u5f81\u7814\u53d1\u7b49\uff09\\\\n                    \\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"query\\\"]}},{\\\"name\\\":\\\"install-mcp-server\\\",\\\"description\\\":\\\"\\\\n              \u6b64\u5de5\u5177\u7528\u4e8e\u5b89\u88c5MCP\u670d\u52a1\u5668\u3002\\\\n              \u8bf7\u544a\u8bc9\u6211\u60a8\u60f3\u8981\u5b89\u88c5\u54ea\u4e2a MCP \u4ee5\u53ca\u5176 githubUrl,\u6211\u5c06\u4f1a\u544a\u8bc9\u60a8\u5982\u4f55\u5b89\u88c5\u5bf9\u5e94\u7684 MCP\\\\n              \\\",\\\"inputSchema\\\":{\\\"type\\\":\\\"object\\\",\\\"properties\\\":{\\\"githubUrl\\\":{\\\"description\\\":\\\"\u8bf7\u8f93\u5165\u60a8\u60f3\u8981\u5b89\u88c5\u7684MCP\u7684githubUrl\u3002\\\",\\\"type\\\":\\\"string\\\"},\\\"mcpName\\\":{\\\"description\\\":\\\"\u8bf7\u8f93\u5165\u60a8\u60f3\u8981\u5b89\u88c5\u7684MCP\u540d\u79f0\u3002\\\",\\\"type\\\":\\\"string\\\"}},\\\"required\\\":[\\\"mcpN\"])</script><script>self.__next_f.push([1,\"ame\\\",\\\"githubUrl\\\"]}}]93:Tdb1,\\n\\n\\u003cdiv class=\\\"title-block\\\" style=\\\"text-align: center;\\\" align=\\\"center\\\"\\u003e\\n\\n![export](https://raw.githubusercontent.com/SkyworkAI/Mureka-mcp/refs/heads/master/assets/mureka_mcp.png)\\n\\n[![Discord Community](https://raw.githubusercontent.com/SkyworkAI/Mureka-mcp/refs/heads/master/assets/discord_mureka.svg)](https://discord.com/invite/nwu9ANqAf5)\\n[![Twitter](https://raw.githubusercontent.com/SkyworkAI/Mureka-mcp/refs/heads/master/assets/x_mureka.svg)](https://x.com/Mureka_AI)\\n[![PyPI](https://raw.githubusercontent.com/SkyworkAI/Mureka-mcp/refs/heads/master/assets/pypi_mureka.svg)](https://pypi.org/project/mureka-mcp)\\n\\n\\u003c/div\\u003e\\n\\u003cp align=\\\"center\\\"\\u003e\\n  Official Mureka Model Context Protocol (MCP) server that enables interaction with powerful lyrics, song and bgm generating APIs. This server allows MCP clients like \\u003ca href=\\\"https://www.anthropic.com/claude\\\"\\u003eClaude Desktop\\u003c/a\\u003e, \\u003ca href=\\\"https://github.com/openai/openai-agents-python\\\"\\u003eOpenAI Agents\\u003c/a\\u003e and others to generate lyrics, song and background music(instrumental).\\n\\u003c/p\\u003e\\n\\n## Quickstart with Claude Desktop\\n\\n1. Get your API key from [Mureka](https://platform.mureka.ai/apiKeys).\\n2. Install `uv` (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh` or see the `uv` [repo](https://github.com/astral-sh/uv) for additional install methods.\\n3. Go to Claude \\u003e Settings \\u003e Developer \\u003e Edit Config \\u003e claude_desktop_config.json to include the following:\\n\\n```\\n{\\n    \\\"mcpServers\\\": {\\n        \\\"Mureka\\\": {\\n            \\\"command\\\": \\\"uvx\\\",\\n            \\\"args\\\": [\\n                \\\"mureka-mcp\\\"\\n            ],\\n            \\\"env\\\": {\\n                \\\"MUREKA_API_KEY\\\": \\\"\\u003cinsert-your-api-key-here\\u003e\\\",\\n                \\\"MUREKA_API_URL\\\": \\\"https://api.mureka.ai\\\",\\n                \\\"TIME_OUT_SECONDS\\\":\\\"300\\\"\\n            }\\n        }\\n    }\\n}\\n```\\n\\nThen restart the Claude app and see 4 MCP tools available in the window, indicating successful loading\\n\\u003cdiv class=\\\"title-block\\\" style=\\\"text-align: left;\\\"\\u003e\\n\\u003cimg src=\\\"https://raw.githubusercontent.com/SkyworkAI/Mureka-mcp/refs/heads/master/assets/img.png\\\" width=\\\"400\\\"\\u003e\\n\\u003c/div\\u003e\\n\\n## Optional features\\nYou can add the `TIME_OUT_SECONDS` environment variable to the `claude_desktop_config.json` to set the timeout period for song or bgm generation waiting(Default 60s).\\n\\n## Example usage\\n\\n\u26a0\ufe0f Warning: Mureka credits are needed to use these tools.\\nTry asking Claude:\\n- \\\"Please create a song for my daughter Jessica to wish her a happy birthday and play it\\\"\\n\\u003cdiv class=\\\"title-block\\\" style=\\\"text-align: left;\\\"\\u003e\\n\\u003cimg src=\\\"https://github.com/SkyworkAI/Mureka-mcp/blob/master/assets/demo.jpeg?raw=true\\\" width=\\\"400\\\"\\u003e\\n\\u003c/div\\u003e\\n\\n- \\\"Please generate lyrics about Christmas\\\"\\n- \\\"Please generate a song based on the lyrics just now\\\"\\n- \\\"Please generate background music suitable for playing in the coffee shop\\\"\\n\\u003cdiv class=\\\"title-block\\\" style=\\\"text-align: left;\\\"\\u003e\\n\\u003cimg src=\\\"https://github.com/SkyworkAI/Mureka-mcp/blob/master/assets/demo1.jpeg?raw=true\\\" width=\\\"400\\\"\\u003e\\n\\u003c/div\\u003e\\n\\n[bgm 1 download](https://github.com/SkyworkAI/Mureka-mcp/raw/407ad955ab29c61e81b5d374e492ef8b1353c2f3/assets/16567807049729-9pi6MDiVqTavVUdjf54fmW.mp3)\\n\\n[bgm 2 download](https://github.com/SkyworkAI/Mureka-mcp/raw/407ad955ab29c61e81b5d374e492ef8b1353c2f3/assets/16567807049729-D7WVCcxp77Prm8b15HSX1G.mp3)\\n\\n## Troubleshooting\\n\\nLogs when running with Claude Desktop can be found at:\\n\\n- **Windows**: `%APPDATA%\\\\Claude\\\\logs\\\\mcp-server-Mureka.log`\\n- **macOS**: `~/Library/Logs/Claude/mcp-server-Mureka.log`\\n\\n## Quickstart with Openai agents sdk\\n\\nComing soon94:T4f3,# Scenext MCP Server\\n\\nAn MCP server that integrates with [Scenext](https://scenext.cn) AI video generation platform to create educational explanation videos based on topics.\\n\\n## Configuration\\n\\nAdd the following to your Claude Desktop configuration file:\\n\\nLocal access(UVX mode):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"scenext\\\": {\\n      \\\"command\\\": \\\"uvx\\\", \\n      \\\"args\\\": [\\\"scenext-mcp\\\"],\\n      \\\"env\\\": {\\n        \\\"SCENEXT_API_KEY\\\": \\\"your_actual_api_key_here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\nRemote access(SSE):\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"scenext\\\": {\\n      \\\"type\\\":\\\"\"])</script><script>self.__next_f.push([1,\"sse\\\",\\n      \\\"url\\\":\\\"https://mcp.scenext.cn/sse?api_key=your_actual_api_key_here\\\"\\n    }\\n  }\\n}\\n```\\n\\nor:\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"scenext\\\": {\\n      \\\"type\\\": \\\"sse\\\",\\n      \\\"url\\\": \\\"https://mcp.scenext.cn/sse\\\",\\n      \\\"headers\\\": {\\n        \\\"Authorization\\\": \\\"Bearer your_actual_api_key_here\\\"\\n      }\\n    }\\n  }\\n}\\n```\\n\\n## Getting API Key\\n\\n### Step 1: Register Account\\n\\nVisit [scenext.cn](https://scenext.cn) to register your account.\\n\\n### Step 2: Obtain API Key\\n\\n1. After logging in, go to the user center\\n2. Find \\\"API Keys Management\\\"\\n3. Click \\\"Create API Key\\\"\\n4. Save your API key (please keep it safe)\\n\\n## Features\\n\\n- `gen_video` - Generate educational videos\\n- `query_video_status` - Query video generation status95:T497,## what is Scenext? \\nScenext is an AI video generation platform that automatically creates high-quality instructional videos based on provided questions and reference answers.\\n\\n## how to use Scenext? \\nTo use Scenext, install the MCP server using `pip install scenext-mcp`, configure it with your API key, and then use the `gen_video` function to generate teaching videos.\\n\\n## key features of Scenext? \\n- Automatic generation of instructional videos from text inputs.\\n- Ability to check the status of video generation with `query_video_status`.\\n\\n## use cases of Scenext? \\n1. Creating educational videos for online courses.\\n2. Generating video content for tutoring sessions.\\n3. Producing instructional materials for schools and universities.\\n\\n## FAQ from Scenext? \\n- How do I get an API key?  \\n\\u003e Register at scenext.cn, log in, and create an API key in your personal center.\\n\\n- What programming language is required to use Scenext?  \\n\\u003e Scenext is implemented in Python, and you need to use Python to interact with the MCP server.\\n\\n- Can I customize the videos generated?  \\n\\u003e Yes, you can provide different questions and reference answers to customize the content of the videos.96:T8bc,# FastDomainCheck MCP Server (Python)\\n\\nThis is a domain availability check server implemented using Python and the Model Context Protocol (MCP).\\nIt provides MCP Tools to check if single or multiple domain names are already registered.\\n\\n\\n## Features\\n\\n- Bulk domain registration status checking\\n- Dual verification using WHOIS and DNS\\n- Support for IDN (Internationalized Domain Names)\\n- Concise output format\\n- Built-in input validation and error handling\\n\\n## Tool Documentation\\n\\n### check_domains\\n\\nCheck registration status for multiple domain names.\\n\\n#### Input Format\\n\\n```json\\n{\\n  \\\"domains\\\": [\\\"example.com\\\", \\\"test.com\\\"]\\n}\\n```\\n\\nParameters:\\n- `domains`: Array of strings containing domain names to check\\n  - Maximum length of 255 characters per domain\\n  - Maximum 50 domains per request\\n  - No empty domain names allowed\\n\\n#### Output Format\\n\\n```json\\n{\\n  \\\"results\\\": {\\n    \\\"example.com\\\": {\\n      \\\"registered\\\": true\\n    },\\n    \\\"test.com\\\": {\\n      \\\"registered\\\": false\\n    }\\n  }\\n}\\n```\\n\\nResponse Fields:\\n- `results`: Object with domain names as keys and check results as values\\n  - `registered`: Boolean\\n    - `true`: Domain is registered\\n    - `false`: Domain is available\\n\\n#### Error Handling\\n\\nThe tool will return an error in the following cases:\\n1. Empty domains list\\n2. More than 50 domains in request\\n3. Empty domain name\\n4. Domain name exceeding 255 characters\\n5. Result serialization failure\\n\\nError Response Format:\\n```json\\n{\\n  \\\"error\\\": \\\"Error: domains list cannot be empty\\\"\\n}\\n```\\n\\n#### Usage Examples\\n\\nCheck multiple domains:\\n\\u003e Request\\n```json\\n{\\n  \\\"domains\\\": [\\\"example.com\\\", \\\"test123456.com\\\"]\\n}\\n```\\n\\n\\u003e Response\\n```json\\n{\\n  \\\"results\\\": {\\n    \\\"example.com\\\": {\\n      \\\"registered\\\": true\\n    },\\n    \\\"test123456.com\\\": {\\n      \\\"registered\\\": false\\n    }\\n  }\\n}\\n```\\n\\n\\n## MCP Server Settings\\n\\n#### Configuring FastDomainCheck MCP in Claude Deskto\\nModify your claude-desktop-config.json file as shown below\\n\\n```json\\n{\\n  \\\"mcpServers\\\": {\\n    \\\"fastdomaincheck\\\": {\\n      \\\"command\\\": \\\"uvx\\\",\\n      \\\"args\\\": [\\n        \\\"fastdomaincheck-mcp-server\\\"\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n\\n\\n## Go Version Reference\\n\\n\\n[go version](https://github.com/bingal/FastDomainCheck-MCP-Server)\\n\\n## Website\\n[Home Page](https://fastdomainche\"])</script><script>self.__next_f.push([1,\"ck.com/)\\n\\n[Author](https://www.bingal.com/)97:T4ff,## what is FastDomainCheck? \\nFastDomainCheck is a domain availability check server implemented in Python, designed to provide fast and efficient checks for single or multiple domain names using the Model Context Protocol (MCP).\\n\\n## how to use FastDomainCheck? \\nTo use FastDomainCheck, send a request with an array of domain names to check their registration status. The server will respond with the availability of each domain.\\n\\n## key features of FastDomainCheck? \\n- Bulk domain registration status checking\\n- Dual verification using WHOIS and DNS\\n- Support for Internationalized Domain Names (IDN)\\n- Concise output format\\n- Built-in input validation and error handling\\n\\n## use cases of FastDomainCheck? \\n1. Checking the availability of domain names for new websites.\\n2. Verifying domain registration status in bulk for domain resellers.\\n3. Supporting developers in domain management applications.\\n\\n## FAQ from FastDomainCheck? \\n- How many domains can I check at once?\\n\\u003e You can check up to 50 domains in a single request.\\n\\n- What happens if I exceed the domain limit?\\n\\u003e The server will return an error indicating that the request exceeds the maximum allowed domains.\\n\\n- Is there a limit on the length of domain names?\\n\\u003e Yes, each domain name can be a maximum of 255 characters.98:T12d3,# Reddit MCP Server\\n\\nThis repository contains a Model Context Protocol server implementation for Reddit that allows AI assistants to access and interact with Reddit content through PRAW (Python Reddit API Wrapper).\\n\\n![image](./Demo.png)\\n\\n## What is MCP?\\n\\nThe Model Context Protocol (MCP) is a standard for enabling AI assistants to interface with external services, tools, and data sources. This server implements the MCP specification to provide access to Reddit content. \\n\\nTo know more about MCP, Check this [video](https://www.youtube.com/watch?v=BwB1Jcw8Z-8)\\n\\n## Features\\n\\n- Get detailed user information with engagement analysis\\n- Fetch and analyze top posts from any subreddit\\n- Get comprehensive subreddit statistics and health metrics\\n- View trending subreddits with growth patterns\\n- Create strategic posts with timing recommendations\\n- Reply to posts and comments with engagement optimization\\n- AI-driven insights and recommendations\\n- Smart response formatting with engagement metrics\\n\\n## Installation\\n\\n1. Clone this repository\\n\\n```bash\\ngit clone https://github.com/Arindam200/reddit-mcp.git\\ncd reddit-mcp\\n```\\n\\n2. **Connect to the MCP server**\\n\\n   Copy the below json with the appropriate {{PATH}} values:\\n\\n   ```json\\n   {\\n     \\\"mcpServers\\\": {\\n       \\\"reddit\\\": {\\n         \\\"command\\\": \\\"{{PATH_TO_UV}}\\\", // Run `which uv` and place the output here\\n         \\\"args\\\": [\\n           \\\"--directory\\\",\\n           \\\"{{PATH_TO_SRC}}\\\", // cd into the repo, run `pwd` and enter the output here\\n           \\\"run\\\",\\n           \\\"server.py\\\"\\n         ],\\n         \\\"env\\\": {\\n           \\\"REDDIT_CLIENT_ID\\\": \\\"your_client_id\\\",\\n           \\\"REDDIT_CLIENT_SECRET\\\": \\\"your_client_secret\\\",\\n           \\\"REDDIT_USERNAME\\\": \\\"your_username\\\", // Optional for authenticated operations\\n           \\\"REDDIT_PASSWORD\\\": \\\"your_password\\\" // Optional for authenticated operations\\n         }\\n       }\\n     }\\n   }\\n   ```\\n\\n   You can obtain Reddit API credentials by creating an app at [Reddit's app preferences page](https://www.reddit.com/prefs/apps).\\n\\n   For **Claude**, save this as `claude_desktop_config.json` in your Claude Desktop configuration directory at:\\n\\n   ```\\n   ~/Library/Application Support/Claude/claude_desktop_config.json\\n   ```\\n\\n   For **Cursor**, save this as `mcp.json` in your Cursor configuration directory at:\\n\\n   ```\\n   ~/.cursor/mcp.json\\n   ```\\n\\n3. **Restart Claude Desktop / Cursor**\\n\\n   Open Claude Desktop and you should now see Reddit as an available integration.\\n\\n   Or restart Cursor.\\n\\n### Available Tools\\n\\nThe server provides the following tools:\\n\\n#### Read-only Tools (require only client credentials):\\n\\n- `get_user_info(username)` - Get detailed user analysis with engagement insights\\n- `get_top_posts(subreddit, time_filter, limit)` - Get and analyze top posts\\n-\"])</script><script>self.__next_f.push([1,\" `get_subreddit_stats(subreddit)` - Get comprehensive subreddit analysis\\n- `get_trending_subreddits()` - Get list of trending subreddits\\n\\n#### Authenticated Tools (require user credentials):\\n\\n- `create_post(subreddit, title, content, flair, is_self)` - Create an optimized post\\n- `reply_to_post(post_id, content, subreddit)` - Add a reply with engagement insights\\n- `reply_to_comment(comment_id, content, subreddit)` - Add a strategic reply\\n\\n## Example Queries\\n\\nHere are some examples of what you can ask an AI assistant connected to this server:\\n\\n- \\\"Analyze u/spez's Reddit activity\\\"\\n- \\\"Show me the top posts from r/Python this week\\\"\\n- \\\"Get statistics about r/AskReddit\\\"\\n- \\\"What are the trending subreddits right now?\\\"\\n- \\\"Create a post in r/Python about a new project\\\"\\n- \\\"Reply to this post with an insightful comment\\\"\\n- \\\"What's the best time to post in this subreddit?\\\"\\n\\n## Advanced Features\\n\\n### AI-Driven Analysis\\n\\nThe server provides intelligent analysis in several areas:\\n\\n1. **User Analysis**\\n\\n   - Engagement patterns\\n   - Activity trends\\n   - Community influence\\n   - Personalized recommendations\\n\\n2. **Post Analysis**\\n\\n   - Performance metrics\\n   - Engagement quality\\n   - Timing optimization\\n   - Content impact assessment\\n\\n3. **Community Analysis**\\n   - Health indicators\\n   - Growth patterns\\n   - Activity metrics\\n   - Engagement opportunities\\n\\n### Smart Response Formatting\\n\\n- Organized bullet points\\n- Engagement statistics\\n- AI-driven insights\\n- Strategic recommendations\\n- Performance metrics\\n\\n## Authentication\\n\\nThe server supports two levels of authentication:\\n\\n1. **Read-only Access**\\n\\n   - Requires: `client_id` and `client_secret`\\n   - Allows: Fetching public data, reading posts/comments\\n\\n2. **Authenticated Access**\\n   - Requires: All read-only credentials PLUS `username` and `password`\\n   - Allows: All read-only operations PLUS posting and commenting\\n\\n## Contributing\\n\\nContributions are welcome! Please feel free to submit a Pull Request.\\n\\n## License\\n\\nThis project is licensed under the MIT License - see the LICENSE file for details.\\n99:T5de,## What is Reddit MCP Server? \\nReddit MCP Server is a Model Context Protocol server implementation that allows AI assistants to access and interact with Reddit content through the Python Reddit API Wrapper (PRAW).\\n\\n## How to use Reddit MCP Server? \\nTo use the Reddit MCP Server, clone the repository, connect to the MCP server by configuring the necessary JSON with your Reddit API credentials, and restart your AI assistant application to integrate Reddit functionalities.\\n\\n## Key features of Reddit MCP Server? \\n- Detailed user information with engagement analysis\\n- Fetch and analyze top posts from any subreddit\\n- Comprehensive subreddit statistics and health metrics\\n- Trending subreddits with growth patterns\\n- Strategic post creation with timing recommendations\\n- AI-driven insight"
      },
      {
        "name": "Sentry",
        "type": "error_tracking",
        "evidence": "Sentry.io"
      }
    ],
    "social_links": [
      {
        "type": "github",
        "url": "https://github.com/chatmcp/mcpso/issues"
      },
      {
        "type": "github",
        "url": "https://github.com/modelcontextprotocol/servers"
      },
      {
        "type": "github",
        "url": "https://github.com/example/nlp-toolkit"
      },
      {
        "type": "github",
        "url": "https://github.com/example/text-processor"
      },
      {
        "type": "github",
        "url": "https://github.com/PrithivirajDamodaran/FlashRank"
      },
      {
        "type": "github",
        "url": "https://github.com/modelcontextprotocol/inspector"
      },
      {
        "type": "github",
        "url": "https://github.com/MiniMax-AI/MiniMax-01/raw/main/figures/MiniMaxLogo-Light.png"
      },
      {
        "type": "github",
        "url": "https://github.com/MiniMax-AI/MiniMax-01/blob/main/figures/wechat-qrcode.jpeg"
      },
      {
        "type": "github",
        "url": "https://github.com/MiniMax-AI/MiniMax-MCP/blob/main/LICENSE"
      },
      {
        "type": "github",
        "url": "https://github.com/openai/openai-agents-python"
      },
      {
        "type": "github",
        "url": "https://github.com/MiniMax-AI/MiniMax-MCP-JS"
      },
      {
        "type": "github",
        "url": "https://github.com/astral-sh/uv"
      },
      {
        "type": "github",
        "url": "https://github.com/PsychArch"
      },
      {
        "type": "github",
        "url": "https://github.com/PsychArch/jina-mcp-tools"
      },
      {
        "type": "github",
        "url": "https://github.com/PsychArch/jina-mcp-tools/issues"
      },
      {
        "type": "github",
        "url": "https://github.com/BigSweetPotatoStudio/HyperChat/actions/workflows/build.yml/badge.svg"
      },
      {
        "type": "github",
        "url": "https://github.com/BigSweetPotatoStudio/HyperChat/actions/workflows/build.yml"
      },
      {
        "type": "github",
        "url": "https://github.com/user-attachments/assets/b1ec72d9-be05-4f9a-bed1-16f4ed72de61"
      },
      {
        "type": "github",
        "url": "https://github.com/user-attachments/assets/e8691cd7-0518-4da8-90f2-7dfd8b864a09"
      },
      {
        "type": "github",
        "url": "https://github.com/user-attachments/assets/c9cd15c8-9bce-4df9-b2b2-5fc4e9224ea6"
      }
    ],
    "cookies": [
      {
        "name": "NEXT_LOCALE",
        "secure": false,
        "httponly": false,
        "samesite": "lax"
      }
    ],
    "server_info": {
      "server": "cloudflare",
      "cdn": "Cloudflare"
    },
    "errors": []
  },
  "source_repo": {
    "repo_info": {
      "platform": "github",
      "owner": "chatmcp",
      "repo": "mcpso",
      "url": "https://github.com/chatmcp/mcpso",
      "is_org": false
    },
    "security_files": {
      "security_md": false,
      "security_md_url": null,
      "security_policy": false,
      "code_of_conduct": false,
      "contributing_md": false,
      "license": null,
      "license_url": null
    },
    "org_verification": {
      "is_org": false,
      "org_name": null,
      "verified": false,
      "verified_domains": []
    },
    "activity": {
      "stars": 0,
      "forks": 0,
      "watchers": 0,
      "open_issues": 0,
      "open_prs": 0,
      "last_commit": null,
      "last_release": null,
      "created_at": null,
      "updated_at": null,
      "archived": false
    },
    "security_features": {
      "dependabot_enabled": true,
      "code_scanning_enabled": true,
      "secret_scanning_enabled": true,
      "branch_protection": false,
      "signed_commits": true,
      "security_advisories": []
    },
    "topics": [
      "mcp",
      "mcp-servers",
      "awesome-mcp-servers",
      "mcp-server-store",
      "mcp-servers-directory"
    ],
    "errors": []
  },
  "success": true
}